{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99777474-4e12-4c65-82c8-97313f21d22e",
   "metadata": {},
   "source": [
    "# User Story Breakdown Model Development Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c1c2e-7f10-4904-a098-578a42acae2f",
   "metadata": {},
   "source": [
    "**Project:** Automated User Story Task Breakdown with Dependency Analysis and Skill Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455a31cb-ad8f-4132-931b-703d335acc89",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Project Overview](#1-project-overview)\n",
    "2. [Input Form Strategy](#2-input-form-strategy)\n",
    "3. [Treatment Architecture & Implementation](#3-treatment-architecture--implementation)\n",
    "4. [Output Form & Results](#4-output-form--results)\n",
    "5. [Evaluation & Performance Analysis](#5-evaluation--performance-analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d236fe40-7495-41d1-ba7f-0cbc1c515ef7",
   "metadata": {},
   "source": [
    "## 1. Project Overview\n",
    "\n",
    "### 1.1 Problem Statement\n",
    "The goal of this project is to develop a model that can automatically break down user stories into tasks, identify dependencies between tasks, and extract the required skills needed for each task. \n",
    "\n",
    "### 1.2 Key Objectives\n",
    "- **Task Decomposition**: Break user stories into granular, actionable tasks\n",
    "- **Dependency Identification**: Detect relationships and dependencies between tasks\n",
    "- **Skill Extraction**: Identify required technical and non-technical skills\n",
    "- **Effort Estimation**: Provide realistic time estimates for each task\n",
    "\n",
    "### 1.3 Success Metrics\n",
    "- Task breakdown accuracy\n",
    "- Dependency detection precision\n",
    "- Skill extraction completeness\n",
    "- Processing time and cost efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990aa736-c3fb-4379-b39b-eb006daccf8a",
   "metadata": {},
   "source": [
    "## 2. Input Form Strategy\n",
    "\n",
    "### 2.1 Input Structure Design\n",
    "\n",
    "The input strategy focuses on handling various formats and quantities of user stories to optimize processing efficiency and accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8324ae-b601-48dd-9ce8-fea30155783a",
   "metadata": {},
   "source": [
    "#### 2.1.1 Strategy 1: Individual Processing\n",
    "\n",
    "**Approach**: Process each user story separately\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3193a7e-e207-447d-a3b0-4bce291e7a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the scripts directory to Python path\n",
    "scripts_dir = os.path.join(os.getcwd(), 'scripts')\n",
    "sys.path.append(scripts_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a86cb07-9e82-4264-9e44-acf8af4eeb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_USER_STORIES = [\n",
    "    \"As a user, I want to click on the address so that it takes me to a new tab with Google Maps.\",\n",
    "    \"As a user, I want to be able to anonymously view public information so that I know about recycling centers near me before creating an account.\",\n",
    "    \"As a user, I want to create an account so that I can save my favorite recycling centers.\",\n",
    "    \"As a user, I want to search for recycling centers by material type so that I can find where to recycle specific items.\",\n",
    "    \"As a user, I want to rate and review recycling centers so that other users can benefit from my experience.\",\n",
    "    \"As a user, I want to receive notifications about new recycling centers in my area so that I stay informed.\",\n",
    "    \"As an admin, I want to manage recycling center information so that the database stays up-to-date.\",\n",
    "    \"As a user, I want to filter search results by distance so that I can find the closest recycling centers.\",\n",
    "    \"As a user, I want to view operating hours for each recycling center so that I know when to visit.\",\n",
    "    \"As a user, I want to get directions to a recycling center so that I can navigate there easily.\",\n",
    "    \"As a user, I want to upload photos of recycling centers so that others can see what the facilities look like.\",\n",
    "    \"As a user, I want to report incorrect information about recycling centers so that the database stays accurate.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d173c5d1-d200-43ec-ba0b-97d7bd1e37d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè¢ PARTY A: INDIVIDUAL PROCESSING WITH FULL DETAILS\n",
      "============================================================\n",
      "Philosophy: 'One story at a time, done right'\n",
      "\n",
      "Processing 12 sample user stories...\n",
      "üè¢ TRADITIONALISTS: Processing 12 stories individually...\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 270, Output: 25, Total: 295\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 274, Output: 81, Total: 355\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 266, Output: 104, Total: 370\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 271, Output: 84, Total: 355\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 268, Output: 99, Total: 367\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 268, Output: 83, Total: 351\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 266, Output: 123, Total: 389\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 268, Output: 80, Total: 348\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 268, Output: 85, Total: 353\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 267, Output: 101, Total: 368\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 269, Output: 115, Total: 384\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 266, Output: 128, Total: 394\n",
      "[DEPENDENCY_ANALYSIS] Tokens - Input: 1471, Output: 1939, Total: 3410\n",
      "[SKILL_MAPPING] Tokens - Input: 164, Output: 26, Total: 190\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 10, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 10, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 143, Output: 10, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 12, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 23, Total: 172\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 16, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 10, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 16, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 7, Total: 151\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 11, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 6, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 11, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 8, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 12, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 10, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 13, Total: 162\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 7, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 10, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 10, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 10, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 10, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 7, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 19, Total: 167\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 13, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 10, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 12, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 11, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 10, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 16, Total: 162\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 7, Total: 151\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 7, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 14, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 21, Total: 169\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 10, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 8, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 13, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 7, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 10, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 8, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 7, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 7, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 10, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 28, Total: 176\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 11, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 16, Total: 163\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 13, Total: 162\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 7, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 13, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 13, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 16, Total: 163\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 14, Total: 162\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 13, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 7, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 7, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 10, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 11, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 12, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 8, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 7, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 7, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 12, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 13, Total: 163\n",
      "[SKILL_MAPPING] Tokens - Input: 155, Output: 12, Total: 167\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 15, Total: 162\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 19, Total: 165\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 15, Total: 164\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 7, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 13, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 12, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 10, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 10, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 12, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 13, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 7, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 10, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 13, Total: 162\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 11, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 8, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 151, Output: 13, Total: 164\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 13, Total: 163\n",
      "[SKILL_MAPPING] Tokens - Input: 152, Output: 16, Total: 168\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 11, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 11, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 7, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 10, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 151, Output: 10, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 153, Output: 11, Total: 164\n",
      "‚úÖ SUCCESS: Processed 12 stories with 121 API calls\n",
      "\n",
      "================================================================================\n",
      "üè¢ PARTY A: TRADITIONALISTS - COMPLETE DETAILED RESULTS\n",
      "================================================================================\n",
      "\n",
      "üìä PERFORMANCE SUMMARY:\n",
      "--------------------------------------------------\n",
      "‚è±Ô∏è  Execution Time: 255.95 seconds\n",
      "üîå API Calls: 121\n",
      "üìã Total Tasks Generated: 108\n",
      "üîó Dependencies Found: 84\n",
      "üéØ Skills Identified: 311\n",
      "‚ö° Efficiency: 0.89 tasks per API call\n",
      "\n",
      "üìã ALL 108 DECOMPOSED TASKS:\n",
      "--------------------------------------------------\n",
      " 1. Please provide the user story you'd like me to break down into tasks. I'll respond with the numbered list of tasks.\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      " 2. Design public landing page layout\n",
      "    ‚îî‚îÄ From: As a user, I want to be able to anonymously view public info...\n",
      "\n",
      " 3. Create anonymous user session handling\n",
      "    ‚îî‚îÄ From: As a user, I want to be able to anonymously view public info...\n",
      "\n",
      " 4. Implement facility search without authentication\n",
      "    ‚îî‚îÄ From: As a user, I want to be able to anonymously view public info...\n",
      "\n",
      " 5. Display basic facility information publicly\n",
      "    ‚îî‚îÄ From: As a user, I want to be able to anonymously view public info...\n",
      "\n",
      " 6. Design facility component\n",
      "    ‚îî‚îÄ From: As a user, I want to be able to anonymously view public info...\n",
      "\n",
      " 7. Detect user's location via browser API or IP\n",
      "    ‚îî‚îÄ From: As a user, I want to be able to anonymously view public info...\n",
      "\n",
      " 8. Show recycling centers within a radius of the user\n",
      "    ‚îî‚îÄ From: As a user, I want to be able to anonymously view public info...\n",
      "\n",
      " 9. Design facility list display component\n",
      "    ‚îî‚îÄ From: As a user, I want to be able to anonymously view public info...\n",
      "\n",
      "10. Add \"Sign up for more features\" prompt\n",
      "    ‚îî‚îÄ From: As a user, I want to be able to anonymously view public info...\n",
      "\n",
      "11. Design registration form layout\n",
      "    ‚îî‚îÄ From: As a user, I want to create an account so that I can save my...\n",
      "\n",
      "12. Create user database schema\n",
      "    ‚îî‚îÄ From: As a user, I want to create an account so that I can save my...\n",
      "\n",
      "13. Implement user registration API endpoint\n",
      "    ‚îî‚îÄ From: As a user, I want to create an account so that I can save my...\n",
      "\n",
      "14. Validate user input on client-side\n",
      "    ‚îî‚îÄ From: As a user, I want to create an account so that I can save my...\n",
      "\n",
      "15. Validate user input on server-side\n",
      "    ‚îî‚îÄ From: As a user, I want to create an account so that I can save my...\n",
      "\n",
      "16. Hash and store user password securely\n",
      "    ‚îî‚îÄ From: As a user, I want to create an account so that I can save my...\n",
      "\n",
      "17. Generate and send account verification email\n",
      "    ‚îî‚îÄ From: As a user, I want to create an account so that I can save my...\n",
      "\n",
      "18. Implement email verification API endpoint\n",
      "    ‚îî‚îÄ From: As a user, I want to create an account so that I can save my...\n",
      "\n",
      "19. Update user account status upon verification\n",
      "    ‚îî‚îÄ From: As a user, I want to create an account so that I can save my...\n",
      "\n",
      "20. Design account creation success page\n",
      "    ‚îî‚îÄ From: As a user, I want to create an account so that I can save my...\n",
      "\n",
      "21. Add \"Log in\" functionality after account creation\n",
      "    ‚îî‚îÄ From: As a user, I want to create an account so that I can save my...\n",
      "\n",
      "22. Store user preferences for favorite recycling centers\n",
      "    ‚îî‚îÄ From: As a user, I want to create an account so that I can save my...\n",
      "\n",
      "23. Design material type search input component\n",
      "    ‚îî‚îÄ From: As a user, I want to search for recycling centers by materia...\n",
      "\n",
      "24. Create material type database schema\n",
      "    ‚îî‚îÄ From: As a user, I want to search for recycling centers by materia...\n",
      "\n",
      "25. Populate material type database with initial data\n",
      "    ‚îî‚îÄ From: As a user, I want to search for recycling centers by materia...\n",
      "\n",
      "26. Implement material type search query logic\n",
      "    ‚îî‚îÄ From: As a user, I want to search for recycling centers by materia...\n",
      "\n",
      "27. Integrate search query with facility database\n",
      "    ‚îî‚îÄ From: As a user, I want to search for recycling centers by materia...\n",
      "\n",
      "28. Filter facility search results by material type\n",
      "    ‚îî‚îÄ From: As a user, I want to search for recycling centers by materia...\n",
      "\n",
      "29. Display material type search results with facility information\n",
      "    ‚îî‚îÄ From: As a user, I want to search for recycling centers by materia...\n",
      "\n",
      "30. Add material type search input validation\n",
      "    ‚îî‚îÄ From: As a user, I want to search for recycling centers by materia...\n",
      "\n",
      "31. Design rating and review form component\n",
      "    ‚îî‚îÄ From: As a user, I want to rate and review recycling centers so th...\n",
      "\n",
      "32. Create rating and review database schema\n",
      "    ‚îî‚îÄ From: As a user, I want to rate and review recycling centers so th...\n",
      "\n",
      "33. Implement rating and review submission handling\n",
      "    ‚îî‚îÄ From: As a user, I want to rate and review recycling centers so th...\n",
      "\n",
      "34. Validate user authentication for rating and review submission\n",
      "    ‚îî‚îÄ From: As a user, I want to rate and review recycling centers so th...\n",
      "\n",
      "35. Associate rating and review with user and facility\n",
      "    ‚îî‚îÄ From: As a user, I want to rate and review recycling centers so th...\n",
      "\n",
      "36. Calculate and display average rating for each facility\n",
      "    ‚îî‚îÄ From: As a user, I want to rate and review recycling centers so th...\n",
      "\n",
      "37. Display individual ratings and reviews for each facility\n",
      "    ‚îî‚îÄ From: As a user, I want to rate and review recycling centers so th...\n",
      "\n",
      "38. Implement sorting and filtering for ratings and reviews\n",
      "    ‚îî‚îÄ From: As a user, I want to rate and review recycling centers so th...\n",
      "\n",
      "39. Add rating and review moderation functionality\n",
      "    ‚îî‚îÄ From: As a user, I want to rate and review recycling centers so th...\n",
      "\n",
      "40. Design rating and review display component\n",
      "    ‚îî‚îÄ From: As a user, I want to rate and review recycling centers so th...\n",
      "\n",
      "41. Design notification system architecture\n",
      "    ‚îî‚îÄ From: As a user, I want to receive notifications about new recycli...\n",
      "\n",
      "42. Create notification preference storage in user profile\n",
      "    ‚îî‚îÄ From: As a user, I want to receive notifications about new recycli...\n",
      "\n",
      "43. Implement geolocation-based notification filtering\n",
      "    ‚îî‚îÄ From: As a user, I want to receive notifications about new recycli...\n",
      "\n",
      "44. Develop notification content generation for new recycling centers\n",
      "    ‚îî‚îÄ From: As a user, I want to receive notifications about new recycli...\n",
      "\n",
      "45. Integrate notification system with facility creation event\n",
      "    ‚îî‚îÄ From: As a user, I want to receive notifications about new recycli...\n",
      "\n",
      "46. Design notification email template\n",
      "    ‚îî‚îÄ From: As a user, I want to receive notifications about new recycli...\n",
      "\n",
      "47. Implement email sending service for notifications\n",
      "    ‚îî‚îÄ From: As a user, I want to receive notifications about new recycli...\n",
      "\n",
      "48. Add notification toggle in user profile settings\n",
      "    ‚îî‚îÄ From: As a user, I want to receive notifications about new recycli...\n",
      "\n",
      "49. Update user profile to store notification preferences\n",
      "    ‚îî‚îÄ From: As a user, I want to receive notifications about new recycli...\n",
      "\n",
      "50. Design admin dashboard layout for recycling center management\n",
      "    ‚îî‚îÄ From: As an admin, I want to manage recycling center information s...\n",
      "\n",
      "51. Create admin user authentication and authorization\n",
      "    ‚îî‚îÄ From: As an admin, I want to manage recycling center information s...\n",
      "\n",
      "52. Implement CRUD operations for recycling center data\n",
      "    ‚îî‚îÄ From: As an admin, I want to manage recycling center information s...\n",
      "\n",
      "53. Design data model for recycling center information\n",
      "    ‚îî‚îÄ From: As an admin, I want to manage recycling center information s...\n",
      "\n",
      "54. Create database schema for recycling center data\n",
      "    ‚îî‚îÄ From: As an admin, I want to manage recycling center information s...\n",
      "\n",
      "55. Develop form component for adding new recycling centers\n",
      "    ‚îî‚îÄ From: As an admin, I want to manage recycling center information s...\n",
      "\n",
      "56. Develop form component for editing existing recycling centers\n",
      "    ‚îî‚îÄ From: As an admin, I want to manage recycling center information s...\n",
      "\n",
      "57. Implement data validation for recycling center information\n",
      "    ‚îî‚îÄ From: As an admin, I want to manage recycling center information s...\n",
      "\n",
      "58. Develop list component for displaying recycling centers\n",
      "    ‚îî‚îÄ From: As an admin, I want to manage recycling center information s...\n",
      "\n",
      "59. Add filtering and sorting functionality to recycling center list\n",
      "    ‚îî‚îÄ From: As an admin, I want to manage recycling center information s...\n",
      "\n",
      "60. Implement deletion functionality for recycling centers\n",
      "    ‚îî‚îÄ From: As an admin, I want to manage recycling center information s...\n",
      "\n",
      "61. Add confirmation prompt before deleting a recycling center\n",
      "    ‚îî‚îÄ From: As an admin, I want to manage recycling center information s...\n",
      "\n",
      "62. Add distance filter option to search form\n",
      "    ‚îî‚îÄ From: As a user, I want to filter search results by distance so th...\n",
      "\n",
      "63. Create distance filter dropdown with predefined options\n",
      "    ‚îî‚îÄ From: As a user, I want to filter search results by distance so th...\n",
      "\n",
      "64. Implement distance filter logic on search results\n",
      "    ‚îî‚îÄ From: As a user, I want to filter search results by distance so th...\n",
      "\n",
      "65. Calculate distance between user location and facility location\n",
      "    ‚îî‚îÄ From: As a user, I want to filter search results by distance so th...\n",
      "\n",
      "66. Sort search results by distance\n",
      "    ‚îî‚îÄ From: As a user, I want to filter search results by distance so th...\n",
      "\n",
      "67. Display distance to each facility in search results\n",
      "    ‚îî‚îÄ From: As a user, I want to filter search results by distance so th...\n",
      "\n",
      "68. Update search results display to reflect filtered results\n",
      "    ‚îî‚îÄ From: As a user, I want to filter search results by distance so th...\n",
      "\n",
      "69. Add unit test for distance filter logic\n",
      "    ‚îî‚îÄ From: As a user, I want to filter search results by distance so th...\n",
      "\n",
      "70. Design operating hours display component\n",
      "    ‚îî‚îÄ From: As a user, I want to view operating hours for each recycling...\n",
      "\n",
      "71. Create API endpoint to fetch operating hours for a facility\n",
      "    ‚îî‚îÄ From: As a user, I want to view operating hours for each recycling...\n",
      "\n",
      "72. Implement facility detail page to display operating hours\n",
      "    ‚îî‚îÄ From: As a user, I want to view operating hours for each recycling...\n",
      "\n",
      "73. Integrate API endpoint with facility detail page\n",
      "    ‚îî‚îÄ From: As a user, I want to view operating hours for each recycling...\n",
      "\n",
      "74. Handle cases where operating hours are not available\n",
      "    ‚îî‚îÄ From: As a user, I want to view operating hours for each recycling...\n",
      "\n",
      "75. Add operating hours to facility data model\n",
      "    ‚îî‚îÄ From: As a user, I want to view operating hours for each recycling...\n",
      "\n",
      "76. Update facility search results to include operating hours\n",
      "    ‚îî‚îÄ From: As a user, I want to view operating hours for each recycling...\n",
      "\n",
      "77. Display operating hours in facility list display component\n",
      "    ‚îî‚îÄ From: As a user, I want to view operating hours for each recycling...\n",
      "\n",
      "78. Implement click handler on facility list item to request directions\n",
      "    ‚îî‚îÄ From: As a user, I want to get directions to a recycling center so...\n",
      "\n",
      "79. Create API request to mapping service (e.g. Google Maps) for directions\n",
      "    ‚îî‚îÄ From: As a user, I want to get directions to a recycling center so...\n",
      "\n",
      "80. Handle API response and extract directions data\n",
      "    ‚îî‚îÄ From: As a user, I want to get directions to a recycling center so...\n",
      "\n",
      "81. Design and implement directions display component\n",
      "    ‚îî‚îÄ From: As a user, I want to get directions to a recycling center so...\n",
      "\n",
      "82. Display directions data in the directions display component\n",
      "    ‚îî‚îÄ From: As a user, I want to get directions to a recycling center so...\n",
      "\n",
      "83. Add option to open directions in native mapping app\n",
      "    ‚îî‚îÄ From: As a user, I want to get directions to a recycling center so...\n",
      "\n",
      "84. Implement click handler to open directions in native mapping app\n",
      "    ‚îî‚îÄ From: As a user, I want to get directions to a recycling center so...\n",
      "\n",
      "85. Add option to print directions\n",
      "    ‚îî‚îÄ From: As a user, I want to get directions to a recycling center so...\n",
      "\n",
      "86. Implement print functionality for directions\n",
      "    ‚îî‚îÄ From: As a user, I want to get directions to a recycling center so...\n",
      "\n",
      "87. Design photo upload interface component\n",
      "    ‚îî‚îÄ From: As a user, I want to upload photos of recycling centers so t...\n",
      "\n",
      "88. Implement file input field for photo upload\n",
      "    ‚îî‚îÄ From: As a user, I want to upload photos of recycling centers so t...\n",
      "\n",
      "89. Create API endpoint for photo upload\n",
      "    ‚îî‚îÄ From: As a user, I want to upload photos of recycling centers so t...\n",
      "\n",
      "90. Handle photo upload to cloud storage\n",
      "    ‚îî‚îÄ From: As a user, I want to upload photos of recycling centers so t...\n",
      "\n",
      "91. Store photo metadata in database\n",
      "    ‚îî‚îÄ From: As a user, I want to upload photos of recycling centers so t...\n",
      "\n",
      "92. Associate uploaded photo with facility ID\n",
      "    ‚îî‚îÄ From: As a user, I want to upload photos of recycling centers so t...\n",
      "\n",
      "93. Implement photo validation (size, type, etc.)\n",
      "    ‚îî‚îÄ From: As a user, I want to upload photos of recycling centers so t...\n",
      "\n",
      "94. Display uploaded photo on facility details page\n",
      "    ‚îî‚îÄ From: As a user, I want to upload photos of recycling centers so t...\n",
      "\n",
      "95. Add photo upload success/failure feedback to user\n",
      "    ‚îî‚îÄ From: As a user, I want to upload photos of recycling centers so t...\n",
      "\n",
      "96. Implement photo deletion API endpoint\n",
      "    ‚îî‚îÄ From: As a user, I want to upload photos of recycling centers so t...\n",
      "\n",
      "97. Remove photo from cloud storage on deletion\n",
      "    ‚îî‚îÄ From: As a user, I want to upload photos of recycling centers so t...\n",
      "\n",
      "98. Update facility details page to show all photos\n",
      "    ‚îî‚îÄ From: As a user, I want to upload photos of recycling centers so t...\n",
      "\n",
      "99. Create \"Report Inaccuracy\" button on facility detail page\n",
      "    ‚îî‚îÄ From: As a user, I want to report incorrect information about recy...\n",
      "\n",
      "100. Implement click handler for \"Report Inaccuracy\" button\n",
      "    ‚îî‚îÄ From: As a user, I want to report incorrect information about recy...\n",
      "\n",
      "101. Design report inaccuracy form with fields for description and contact info\n",
      "    ‚îî‚îÄ From: As a user, I want to report incorrect information about recy...\n",
      "\n",
      "102. Validate user input on report inaccuracy form\n",
      "    ‚îî‚îÄ From: As a user, I want to report incorrect information about recy...\n",
      "\n",
      "103. Send report inaccuracy form data to backend API\n",
      "    ‚îî‚îÄ From: As a user, I want to report incorrect information about recy...\n",
      "\n",
      "104. Create backend API endpoint to receive report inaccuracy data\n",
      "    ‚îî‚îÄ From: As a user, I want to report incorrect information about recy...\n",
      "\n",
      "105. Store report inaccuracy data in database\n",
      "    ‚îî‚îÄ From: As a user, I want to report incorrect information about recy...\n",
      "\n",
      "106. Design admin dashboard to display reported inaccuracies\n",
      "    ‚îî‚îÄ From: As a user, I want to report incorrect information about recy...\n",
      "\n",
      "107. Implement filtering and sorting for reported inaccuracies on admin dashboard\n",
      "    ‚îî‚îÄ From: As a user, I want to report incorrect information about recy...\n",
      "\n",
      "108. Create backend API endpoint to update facility information based on reported inaccuracies\n",
      "    ‚îî‚îÄ From: As a user, I want to report incorrect information about recy...\n",
      "\n",
      "\n",
      "üîó TASK DEPENDENCIES:\n",
      "--------------------------------------------------\n",
      "Found 84 tasks with dependencies:\n",
      "\n",
      "1. üìã TASK: Design public landing page layout\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design facility component', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "2. üìã TASK: Implement facility search without authentication\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create anonymous user session handling', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "3. üìã TASK: Display basic facility information publicly\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design facility component', 'coupling': 'tight', 'rework_effort': '3'}\n",
      "\n",
      "4. üìã TASK: Detect user's location via browser API or IP\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create anonymous user session handling', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "5. üìã TASK: Show recycling centers within a radius of the user\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': \"Detect user's location via browser API or IP\", 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "6. üìã TASK: Design registration form layout\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Add \"Sign up for more features\" prompt', 'coupling': 'loose', 'rework_effort': '1'}\n",
      "\n",
      "7. üìã TASK: Implement user registration API endpoint\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create user database schema', 'coupling': 'tight', 'rework_effort': '8'}\n",
      "\n",
      "8. üìã TASK: Validate user input on server-side\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Validate user input on client-side', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "9. üìã TASK: Hash and store user password securely\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Validate user input on server-side', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "10. üìã TASK: Generate and send account verification email\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Hash and store user password securely', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "11. üìã TASK: Implement email verification API endpoint\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Generate and send account verification email', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "12. üìã TASK: Update user account status upon verification\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement email verification API endpoint', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "13. üìã TASK: Add \"Log in\" functionality after account creation\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design account creation success page', 'coupling': 'loose', 'rework_effort': '1'}\n",
      "\n",
      "14. üìã TASK: Design material type search input component\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Store user preferences for favorite recycling centers', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "15. üìã TASK: Populate material type database with initial data\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create material type database schema', 'coupling': 'tight', 'rework_effort': '8'}\n",
      "\n",
      "16. üìã TASK: Implement material type search query logic\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Populate material type database with initial data', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "17. üìã TASK: Integrate search query with facility database\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement material type search query logic', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "18. üìã TASK: Filter facility search results by material type\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Integrate search query with facility database', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "19. üìã TASK: Display material type search results with facility information\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Filter facility search results by material type', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "20. üìã TASK: Design rating and review form component\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Add material type search input validation', 'coupling': 'loose', 'rework_effort': '1'}\n",
      "\n",
      "21. üìã TASK: Implement rating and review submission handling\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create rating and review database schema', 'coupling': 'tight', 'rework_effort': '8'}\n",
      "\n",
      "22. üìã TASK: Validate user authentication for rating and review submission\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement rating and review submission handling', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "23. üìã TASK: Associate rating and review with user and facility\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Validate user authentication for rating and review submission', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "24. üìã TASK: Calculate and display average rating for each facility\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Associate rating and review with user and facility', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "25. üìã TASK: Display individual ratings and reviews for each facility\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Calculate and display average rating for each facility', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "26. üìã TASK: Implement sorting and filtering for ratings and reviews\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Display individual ratings and reviews for each facility', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "27. üìã TASK: Design rating and review display component\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Add rating and review moderation functionality', 'coupling': 'loose', 'rework_effort': '1'}\n",
      "\n",
      "28. üìã TASK: Create notification preference storage in user profile\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design notification system architecture', 'coupling': 'tight', 'rework_effort': '8'}\n",
      "\n",
      "29. üìã TASK: Implement geolocation-based notification filtering\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create notification preference storage in user profile', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "30. üìã TASK: Develop notification content generation for new recycling centers\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement geolocation-based notification filtering', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "31. üìã TASK: Integrate notification system with facility creation event\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Develop notification content generation for new recycling centers', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "32. üìã TASK: Implement email sending service for notifications\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design notification email template', 'coupling': 'loose', 'rework_effort': '1'}\n",
      "\n",
      "33. üìã TASK: Update user profile to store notification preferences\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Add notification toggle in user profile settings', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "34. üìã TASK: Create admin user authentication and authorization\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design admin dashboard layout for recycling center management', 'coupling': 'tight', 'rework_effort': '8'}\n",
      "\n",
      "35. üìã TASK: Implement CRUD operations for recycling center data\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create admin user authentication and authorization', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "36. üìã TASK: Design data model for recycling center information\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement CRUD operations for recycling center data', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "37. üìã TASK: Create database schema for recycling center data\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design data model for recycling center information', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "38. üìã TASK: Develop form component for adding new recycling centers\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create database schema for recycling center data', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "39. üìã TASK: Develop form component for editing existing recycling centers\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Develop form component for adding new recycling centers', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "40. üìã TASK: Implement data validation for recycling center information\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Develop form component for editing existing recycling centers', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "41. üìã TASK: Develop list component for displaying recycling centers\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement data validation for recycling center information', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "42. üìã TASK: Add filtering and sorting functionality to recycling center list\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Develop list component for displaying recycling centers', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "43. üìã TASK: Add confirmation prompt before deleting a recycling center\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement deletion functionality for recycling centers', 'coupling': 'loose', 'rework_effort': '1'}\n",
      "\n",
      "44. üìã TASK: Create distance filter dropdown with predefined options\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Add distance filter option to search form', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "45. üìã TASK: Implement distance filter logic on search results\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create distance filter dropdown with predefined options', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "46. üìã TASK: Calculate distance between user location and facility location\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement distance filter logic on search results', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "47. üìã TASK: Sort search results by distance\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Calculate distance between user location and facility location', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "48. üìã TASK: Display distance to each facility in search results\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Sort search results by distance', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "49. üìã TASK: Update search results display to reflect filtered results\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Display distance to each facility in search results', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "50. üìã TASK: Design operating hours display component\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Add unit test for distance filter logic', 'coupling': 'loose', 'rework_effort': '1'}\n",
      "\n",
      "51. üìã TASK: Implement facility detail page to display operating hours\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create API endpoint to fetch operating hours for a facility', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "52. üìã TASK: Integrate API endpoint with facility detail page\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement facility detail page to display operating hours', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "53. üìã TASK: Handle cases where operating hours are not available\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Integrate API endpoint with facility detail page', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "54. üìã TASK: Add operating hours to facility data model\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Handle cases where operating hours are not available', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "55. üìã TASK: Update facility search results to include operating hours\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Add operating hours to facility data model', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "56. üìã TASK: Display operating hours in facility list display component\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Update facility search results to include operating hours', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "57. üìã TASK: Create API request to mapping service (e.g. Google Maps) for directions\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement click handler on facility list item to request directions', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "58. üìã TASK: Handle API response and extract directions data\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create API request to mapping service (e.g. Google Maps) for directions', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "59. üìã TASK: Design and implement directions display component\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Handle API response and extract directions data', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "60. üìã TASK: Display directions data in the directions display component\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design and implement directions display component', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "61. üìã TASK: Add option to open directions in native mapping app\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Display directions data in the directions display component', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "62. üìã TASK: Implement click handler to open directions in native mapping app\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Add option to open directions in native mapping app', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "63. üìã TASK: Add option to print directions\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement click handler to open directions in native mapping app', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "64. üìã TASK: Implement print functionality for directions\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Add option to print directions', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "65. üìã TASK: Implement file input field for photo upload\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design photo upload interface component', 'coupling': 'loose', 'rework_effort': '1'}\n",
      "\n",
      "66. üìã TASK: Handle photo upload to cloud storage\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create API endpoint for photo upload', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "67. üìã TASK: Store photo metadata in database\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Handle photo upload to cloud storage', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "68. üìã TASK: Associate uploaded photo with facility ID\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Store photo metadata in database', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "69. üìã TASK: Implement photo validation (size, type, etc.)\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Associate uploaded photo with facility ID', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "70. üìã TASK: Display uploaded photo on facility details page\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement photo validation (size, type, etc.)', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "71. üìã TASK: Add photo upload success/failure feedback to user\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Display uploaded photo on facility details page', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "72. üìã TASK: Implement photo deletion API endpoint\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Add photo upload success/failure feedback to user', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "73. üìã TASK: Remove photo from cloud storage on deletion\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement photo deletion API endpoint', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "74. üìã TASK: Update facility details page to show all photos\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Remove photo from cloud storage on deletion', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "75. üìã TASK: Create \"Report Inaccuracy\" button on facility detail page\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Update facility details page to show all photos', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "76. üìã TASK: Implement click handler for \"Report Inaccuracy\" button\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create \"Report Inaccuracy\" button on facility detail page', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "77. üìã TASK: Design report inaccuracy form with fields for description and contact info\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement click handler for \"Report Inaccuracy\" button', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "78. üìã TASK: Validate user input on report inaccuracy form\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design report inaccuracy form with fields for description and contact info', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "79. üìã TASK: Send report inaccuracy form data to backend API\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Validate user input on report inaccuracy form', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "80. üìã TASK: Create backend API endpoint to receive report inaccuracy data\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Send report inaccuracy form data to backend API', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "81. üìã TASK: Store report inaccuracy data in database\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create backend API endpoint to receive report inaccuracy data', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "82. üìã TASK: Design admin dashboard to display reported inaccuracies\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Store report inaccuracy data in database', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "83. üìã TASK: Implement filtering and sorting for reported inaccuracies on admin dashboard\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design admin dashboard to display reported inaccuracies', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "84. üìã TASK: Create backend API endpoint to update facility information based on reported inaccuracies\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement filtering and sorting for reported inaccuracies on admin dashboard', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "\n",
      "üéØ SKILLS REQUIRED FOR EACH TASK:\n",
      "--------------------------------------------------\n",
      " 1. üìã Please provide the user story you'd like me to break down into tasks. I'll respond with the numbered list of tasks.\n",
      "     üõ†Ô∏è  Skills: Please go ahead and provide the user story. I'll break it down into tasks and identify the required technical skills for each task.\n",
      "\n",
      " 2. üìã Design public landing page layout\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design\n",
      "\n",
      " 3. üìã Create anonymous user session handling\n",
      "     üõ†Ô∏è  Skills: Backend development, Session management\n",
      "\n",
      " 4. üìã Implement facility search without authentication\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      " 5. üìã Display basic facility information publicly\n",
      "     üõ†Ô∏è  Skills: Frontend development, HTML, CSS\n",
      "\n",
      " 6. üìã Design facility component\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design\n",
      "\n",
      " 7. üìã Detect user's location via browser API or IP\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, Geolocation API\n",
      "\n",
      " 8. üìã Show recycling centers within a radius of the user\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, Geolocation API, Mapping API (e.g. Google Maps)\n",
      "\n",
      " 9. üìã Design facility list display component\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design, CSS, HTML\n",
      "\n",
      "10. üìã Add \"Sign up for more features\" prompt\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design\n",
      "\n",
      "11. üìã Design registration form layout\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design, HTML, CSS\n",
      "\n",
      "12. üìã Create user database schema\n",
      "     üõ†Ô∏è  Skills: Database design, Database skills\n",
      "\n",
      "13. üìã Implement user registration API endpoint\n",
      "     üõ†Ô∏è  Skills: Backend development, API design, Database skills\n",
      "\n",
      "14. üìã Validate user input on client-side\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript\n",
      "\n",
      "15. üìã Validate user input on server-side\n",
      "     üõ†Ô∏è  Skills: Backend development, Validation\n",
      "\n",
      "16. üìã Hash and store user password securely\n",
      "     üõ†Ô∏è  Skills: Backend development, Cryptography, Password hashing\n",
      "\n",
      "17. üìã Generate and send account verification email\n",
      "     üõ†Ô∏è  Skills: Backend development, Email service integration\n",
      "\n",
      "18. üìã Implement email verification API endpoint\n",
      "     üõ†Ô∏è  Skills: Backend development, API development, Email service integration\n",
      "\n",
      "19. üìã Update user account status upon verification\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "20. üìã Design account creation success page\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design\n",
      "\n",
      "21. üìã Add \"Log in\" functionality after account creation\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS\n",
      "\n",
      "22. üìã Store user preferences for favorite recycling centers\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "23. üìã Design material type search input component\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design\n",
      "\n",
      "24. üìã Create material type database schema\n",
      "     üõ†Ô∏è  Skills: Database design, Database skills\n",
      "\n",
      "25. üìã Populate material type database with initial data\n",
      "     üõ†Ô∏è  Skills: Database skills, Data migration, SQL\n",
      "\n",
      "26. üìã Implement material type search query logic\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills, SQL\n",
      "\n",
      "27. üìã Integrate search query with facility database\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills, SQL\n",
      "\n",
      "28. üìã Filter facility search results by material type\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "29. üìã Display material type search results with facility information\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS, UI/UX design\n",
      "\n",
      "30. üìã Add material type search input validation\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS\n",
      "\n",
      "31. üìã Design rating and review form component\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design\n",
      "\n",
      "32. üìã Create rating and review database schema\n",
      "     üõ†Ô∏è  Skills: Database design, Database skills\n",
      "\n",
      "33. üìã Implement rating and review submission handling\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "34. üìã Validate user authentication for rating and review submission\n",
      "     üõ†Ô∏è  Skills: Backend development, Authentication and authorization, Database skills\n",
      "\n",
      "35. üìã Associate rating and review with user and facility\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills, Data modeling\n",
      "\n",
      "36. üìã Calculate and display average rating for each facility\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills, SQL\n",
      "\n",
      "37. üìã Display individual ratings and reviews for each facility\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS\n",
      "\n",
      "38. üìã Implement sorting and filtering for ratings and reviews\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS\n",
      "\n",
      "39. üìã Add rating and review moderation functionality\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "40. üìã Design rating and review display component\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design, CSS, HTML\n",
      "\n",
      "41. üìã Design notification system architecture\n",
      "     üõ†Ô∏è  Skills: Architecture design, System design\n",
      "\n",
      "42. üìã Create notification preference storage in user profile\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "43. üìã Implement geolocation-based notification filtering\n",
      "     üõ†Ô∏è  Skills: Backend development, Geolocation services integration, Notification system development\n",
      "\n",
      "44. üìã Develop notification content generation for new recycling centers\n",
      "     üõ†Ô∏è  Skills: Backend development, Template engine (e.g. Handlebars), String manipulation, Data processing\n",
      "\n",
      "45. üìã Integrate notification system with facility creation event\n",
      "     üõ†Ô∏è  Skills: Backend development, Event-driven programming, Notification system integration\n",
      "\n",
      "46. üìã Design notification email template\n",
      "     üõ†Ô∏è  Skills: Email template design, HTML, CSS\n",
      "\n",
      "47. üìã Implement email sending service for notifications\n",
      "     üõ†Ô∏è  Skills: Backend development, Email service integration\n",
      "\n",
      "48. üìã Add notification toggle in user profile settings\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS\n",
      "\n",
      "49. üìã Update user profile to store notification preferences\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "50. üìã Design admin dashboard layout for recycling center management\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design\n",
      "\n",
      "51. üìã Create admin user authentication and authorization\n",
      "     üõ†Ô∏è  Skills: Backend development, Authentication and authorization\n",
      "\n",
      "52. üìã Implement CRUD operations for recycling center data\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "53. üìã Design data model for recycling center information\n",
      "     üõ†Ô∏è  Skills: Database design, Data modeling\n",
      "\n",
      "54. üìã Create database schema for recycling center data\n",
      "     üõ†Ô∏è  Skills: Database design, Data modeling, SQL\n",
      "\n",
      "55. üìã Develop form component for adding new recycling centers\n",
      "     üõ†Ô∏è  Skills: Frontend development, HTML, CSS, JavaScript, UI/UX design, React (or other frontend framework)\n",
      "\n",
      "56. üìã Develop form component for editing existing recycling centers\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS\n",
      "\n",
      "57. üìã Implement data validation for recycling center information\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills, Data validation\n",
      "\n",
      "58. üìã Develop list component for displaying recycling centers\n",
      "     üõ†Ô∏è  Skills: Frontend development, React, JavaScript, CSS, HTML\n",
      "\n",
      "59. üìã Add filtering and sorting functionality to recycling center list\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS\n",
      "\n",
      "60. üìã Implement deletion functionality for recycling centers\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "61. üìã Add confirmation prompt before deleting a recycling center\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript\n",
      "\n",
      "62. üìã Add distance filter option to search form\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS\n",
      "\n",
      "63. üìã Create distance filter dropdown with predefined options\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS\n",
      "\n",
      "64. üìã Implement distance filter logic on search results\n",
      "     üõ†Ô∏è  Skills: Backend development, Algorithm design, Geographic information system (GIS) skills\n",
      "\n",
      "65. üìã Calculate distance between user location and facility location\n",
      "     üõ†Ô∏è  Skills: Backend development, Geospatial calculations, Location-based services\n",
      "\n",
      "66. üìã Sort search results by distance\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills, Geospatial querying\n",
      "\n",
      "67. üìã Display distance to each facility in search results\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, Geolocation API integration\n",
      "\n",
      "68. üìã Update search results display to reflect filtered results\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript\n",
      "\n",
      "69. üìã Add unit test for distance filter logic\n",
      "     üõ†Ô∏è  Skills: Unit testing, Backend development\n",
      "\n",
      "70. üìã Design operating hours display component\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design\n",
      "\n",
      "71. üìã Create API endpoint to fetch operating hours for a facility\n",
      "     üõ†Ô∏è  Skills: Backend development, API design, Database skills\n",
      "\n",
      "72. üìã Implement facility detail page to display operating hours\n",
      "     üõ†Ô∏è  Skills: Frontend development, HTML, CSS, JavaScript\n",
      "\n",
      "73. üìã Integrate API endpoint with facility detail page\n",
      "     üõ†Ô∏è  Skills: Backend development, API integration, Frontend development\n",
      "\n",
      "74. üìã Handle cases where operating hours are not available\n",
      "     üõ†Ô∏è  Skills: Backend development, Conditional logic implementation\n",
      "\n",
      "75. üìã Add operating hours to facility data model\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "76. üìã Update facility search results to include operating hours\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "77. üìã Display operating hours in facility list display component\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML/CSS\n",
      "\n",
      "78. üìã Implement click handler on facility list item to request directions\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, Google Maps API integration\n",
      "\n",
      "79. üìã Create API request to mapping service (e.g. Google Maps) for directions\n",
      "     üõ†Ô∏è  Skills: Backend development, API integration, HTTP request handling\n",
      "\n",
      "80. üìã Handle API response and extract directions data\n",
      "     üõ†Ô∏è  Skills: Backend development, API integration, JSON parsing, Data extraction\n",
      "\n",
      "81. üìã Design and implement directions display component\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design, JavaScript, HTML, CSS\n",
      "\n",
      "82. üìã Display directions data in the directions display component\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS\n",
      "\n",
      "83. üìã Add option to open directions in native mapping app\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, Mobile app development (optional)\n",
      "\n",
      "84. üìã Implement click handler to open directions in native mapping app\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript\n",
      "\n",
      "85. üìã Add option to print directions\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS\n",
      "\n",
      "86. üìã Implement print functionality for directions\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML/CSS\n",
      "\n",
      "87. üìã Design photo upload interface component\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design\n",
      "\n",
      "88. üìã Implement file input field for photo upload\n",
      "     üõ†Ô∏è  Skills: Frontend development, HTML, JavaScript\n",
      "\n",
      "89. üìã Create API endpoint for photo upload\n",
      "     üõ†Ô∏è  Skills: Backend development, API design, File upload handling\n",
      "\n",
      "90. üìã Handle photo upload to cloud storage\n",
      "     üõ†Ô∏è  Skills: Cloud storage integration, Backend development, File upload handling\n",
      "\n",
      "91. üìã Store photo metadata in database\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "92. üìã Associate uploaded photo with facility ID\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "93. üìã Implement photo validation (size, type, etc.)\n",
      "     üõ†Ô∏è  Skills: Backend development, Image processing\n",
      "\n",
      "94. üìã Display uploaded photo on facility details page\n",
      "     üõ†Ô∏è  Skills: Frontend development, HTML, CSS\n",
      "\n",
      "95. üìã Add photo upload success/failure feedback to user\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, UI/UX design\n",
      "\n",
      "96. üìã Implement photo deletion API endpoint\n",
      "     üõ†Ô∏è  Skills: Backend development, API development, Database skills\n",
      "\n",
      "97. üìã Remove photo from cloud storage on deletion\n",
      "     üõ†Ô∏è  Skills: Cloud storage integration, Backend development\n",
      "\n",
      "98. üìã Update facility details page to show all photos\n",
      "     üõ†Ô∏è  Skills: Frontend development, HTML, CSS, JavaScript\n",
      "\n",
      "99. üìã Create \"Report Inaccuracy\" button on facility detail page\n",
      "     üõ†Ô∏è  Skills: Frontend development, HTML, CSS, JavaScript\n",
      "\n",
      "100. üìã Implement click handler for \"Report Inaccuracy\" button\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS\n",
      "\n",
      "101. üìã Design report inaccuracy form with fields for description and contact info\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design, HTML, CSS\n",
      "\n",
      "102. üìã Validate user input on report inaccuracy form\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML, CSS\n",
      "\n",
      "103. üìã Send report inaccuracy form data to backend API\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, API integration\n",
      "\n",
      "104. üìã Create backend API endpoint to receive report inaccuracy data\n",
      "     üõ†Ô∏è  Skills: Backend development, API design, Data handling\n",
      "\n",
      "105. üìã Store report inaccuracy data in database\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      "106. üìã Design admin dashboard to display reported inaccuracies\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design\n",
      "\n",
      "107. üìã Implement filtering and sorting for reported inaccuracies on admin dashboard\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills, SQL\n",
      "\n",
      "108. üìã Create backend API endpoint to update facility information based on reported inaccuracies\n",
      "     üõ†Ô∏è  Skills: Backend development, API design, Database skills\n",
      "\n",
      "\n",
      "üìà DETAILED ANALYSIS:\n",
      "--------------------------------------------------\n",
      "üìä Tasks Generated per Story:\n",
      "   ‚Ä¢ As a user, I want to click on the addres...: 1 tasks\n",
      "   ‚Ä¢ As a user, I want to be able to anonymou...: 9 tasks\n",
      "   ‚Ä¢ As a user, I want to create an account s...: 12 tasks\n",
      "   ‚Ä¢ As a user, I want to search for recyclin...: 8 tasks\n",
      "   ‚Ä¢ As a user, I want to rate and review rec...: 10 tasks\n",
      "   ‚Ä¢ As a user, I want to receive notificatio...: 9 tasks\n",
      "   ‚Ä¢ As an admin, I want to manage recycling ...: 12 tasks\n",
      "   ‚Ä¢ As a user, I want to filter search resul...: 8 tasks\n",
      "   ‚Ä¢ As a user, I want to view operating hour...: 8 tasks\n",
      "   ‚Ä¢ As a user, I want to get directions to a...: 9 tasks\n",
      "   ‚Ä¢ As a user, I want to upload photos of re...: 12 tasks\n",
      "   ‚Ä¢ As a user, I want to report incorrect in...: 10 tasks\n",
      "\n",
      "üîó Dependency Statistics:\n",
      "   ‚Ä¢ Tasks with dependencies: 84\n",
      "   ‚Ä¢ Maximum dependencies per task: 1\n",
      "   ‚Ä¢ Average dependencies per task: 1.0\n",
      "\n",
      "üéØ Skills Analysis:\n",
      "   ‚Ä¢ Unique skills identified: 54\n",
      "   ‚Ä¢ Most common skills: Notification system integration, Conditional logic implementation, API design, Event-driven programming, Geographic information system (GIS) skills\n"
     ]
    }
   ],
   "source": [
    "# Add this to your existing code to show detailed results immediately\n",
    "\n",
    "class EnhancedIndividualProcessor:\n",
    "    \"\"\"Enhanced version that captures and displays detailed results\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Use your existing components\n",
    "        self.decomposer = TaskDecomposerAgent()\n",
    "        self.consolidator = TaskConsolidatorAgent()\n",
    "        self.dependency_analyzer = DependencyAnalyzerAgent()\n",
    "        self.skill_mapper = SkillMapperAgent()\n",
    "    \n",
    "    async def process_stories_with_details(self, user_stories: List[str]):\n",
    "        \"\"\"Process stories and immediately display detailed results\"\"\"\n",
    "        print(f\"üè¢ TRADITIONALISTS: Processing {len(user_stories)} stories individually...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Use the existing process_multiple_user_stories function\n",
    "            result = await process_multiple_user_stories(user_stories)\n",
    "            \n",
    "            if \"error\" in result:\n",
    "                raise Exception(result[\"error\"])\n",
    "            \n",
    "            # Calculate metrics\n",
    "            api_calls = len(user_stories) + 1 + len(result[\"tasks\"])\n",
    "            total_tasks = sum(len(tasks) for tasks in result.get(\"task_origins\", {}).values())\n",
    "            duplicate_reduction = 1 - (len(result[\"tasks\"]) / total_tasks) if total_tasks > 0 else 0\n",
    "            dependencies_found = sum(len(deps) for deps in result[\"dependencies\"].values())\n",
    "            total_skills = sum(len(skills) for skills in result[\"required_skills\"].values())\n",
    "            \n",
    "            print(f\"‚úÖ SUCCESS: Processed {len(user_stories)} stories with {api_calls} API calls\")\n",
    "            \n",
    "            # IMMEDIATELY DISPLAY DETAILED RESULTS\n",
    "            self.display_detailed_results(result, time.time() - start_time, api_calls)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ERROR: {str(e)}\")\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def display_detailed_results(self, result, execution_time, api_calls):\n",
    "        \"\"\"Display comprehensive detailed results immediately\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üè¢ PARTY A: TRADITIONALISTS - COMPLETE DETAILED RESULTS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # SUMMARY METRICS\n",
    "        print(\"\\nüìä PERFORMANCE SUMMARY:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"‚è±Ô∏è  Execution Time: {execution_time:.2f} seconds\")\n",
    "        print(f\"üîå API Calls: {api_calls}\")\n",
    "        print(f\"üìã Total Tasks Generated: {len(result['tasks'])}\")\n",
    "        print(f\"üîó Dependencies Found: {sum(len(deps) for deps in result['dependencies'].values())}\")\n",
    "        print(f\"üéØ Skills Identified: {sum(len(skills) for skills in result['required_skills'].values())}\")\n",
    "        print(f\"‚ö° Efficiency: {len(result['tasks']) / api_calls:.2f} tasks per API call\")\n",
    "        \n",
    "        # DETAILED TASKS\n",
    "        print(f\"\\nüìã ALL {len(result['tasks'])} DECOMPOSED TASKS:\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, task in enumerate(result['tasks'], 1):\n",
    "            print(f\"{i:2d}. {task}\")\n",
    "            \n",
    "            # Show which story(ies) generated this task\n",
    "            origins = result['task_origins'].get(task, [])\n",
    "            if origins:\n",
    "                if len(origins) == 1:\n",
    "                    print(f\"    ‚îî‚îÄ From: {origins[0][:60]}...\")\n",
    "                else:\n",
    "                    print(f\"    ‚îî‚îÄ From {len(origins)} stories (duplicate found):\")\n",
    "                    for origin in origins:\n",
    "                        print(f\"       ‚Ä¢ {origin[:55]}...\")\n",
    "            print()\n",
    "        \n",
    "        # DEPENDENCIES\n",
    "        print(f\"\\nüîó TASK DEPENDENCIES:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        tasks_with_deps = {task: deps for task, deps in result['dependencies'].items() if deps}\n",
    "        \n",
    "        if tasks_with_deps:\n",
    "            print(f\"Found {len(tasks_with_deps)} tasks with dependencies:\\n\")\n",
    "            \n",
    "            for i, (task, deps) in enumerate(tasks_with_deps.items(), 1):\n",
    "                print(f\"{i}. üìã TASK: {task}\")\n",
    "                print(f\"   ‚¨áÔ∏è  DEPENDS ON:\")\n",
    "                for j, dep in enumerate(deps, 1):\n",
    "                    print(f\"      {j}. {dep}\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è  No dependencies detected between tasks\")\n",
    "        \n",
    "        # SKILLS MAPPING\n",
    "        print(f\"\\nüéØ SKILLS REQUIRED FOR EACH TASK:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, (task, skills) in enumerate(result['required_skills'].items(), 1):\n",
    "            if skills:  # Only show tasks with skills\n",
    "                print(f\"{i:2d}. üìã {task}\")\n",
    "                print(f\"     üõ†Ô∏è  Skills: {', '.join(skills)}\")\n",
    "                print()\n",
    "        \n",
    "        # ANALYSIS\n",
    "        print(f\"\\nüìà DETAILED ANALYSIS:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Task distribution per story\n",
    "        story_counts = {}\n",
    "        for task, origins in result['task_origins'].items():\n",
    "            for origin in origins:\n",
    "                short_origin = origin[:40] + \"...\" if len(origin) > 40 else origin\n",
    "                story_counts[short_origin] = story_counts.get(short_origin, 0) + 1\n",
    "        \n",
    "        print(\"üìä Tasks Generated per Story:\")\n",
    "        for story, count in story_counts.items():\n",
    "            print(f\"   ‚Ä¢ {story}: {count} tasks\")\n",
    "        \n",
    "        # Dependency analysis\n",
    "        dep_counts = [len(deps) for deps in result['dependencies'].values()]\n",
    "        if dep_counts:\n",
    "            max_deps = max(dep_counts)\n",
    "            avg_deps = sum(dep_counts) / len(dep_counts)\n",
    "            tasks_with_deps_count = sum(1 for d in dep_counts if d > 0)\n",
    "            \n",
    "            print(f\"\\nüîó Dependency Statistics:\")\n",
    "            print(f\"   ‚Ä¢ Tasks with dependencies: {tasks_with_deps_count}\")\n",
    "            print(f\"   ‚Ä¢ Maximum dependencies per task: {max_deps}\")\n",
    "            print(f\"   ‚Ä¢ Average dependencies per task: {avg_deps:.1f}\")\n",
    "        \n",
    "        # Skills analysis\n",
    "        all_skills = set()\n",
    "        for skills in result['required_skills'].values():\n",
    "            all_skills.update(skills)\n",
    "        \n",
    "        print(f\"\\nüéØ Skills Analysis:\")\n",
    "        print(f\"   ‚Ä¢ Unique skills identified: {len(all_skills)}\")\n",
    "        print(f\"   ‚Ä¢ Most common skills: {', '.join(list(all_skills)[:5])}\")\n",
    "\n",
    "# SIMPLE FUNCTION TO RUN AND DISPLAY EVERYTHING\n",
    "async def run_with_full_details():\n",
    "    \"\"\"Run the processor and display all detailed results immediately\"\"\"\n",
    "    \n",
    "    print(\"üè¢ PARTY A: INDIVIDUAL PROCESSING WITH FULL DETAILS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Philosophy: 'One story at a time, done right'\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Use sample stories\n",
    "    user_stories = SAMPLE_USER_STORIES\n",
    "    print(f\"Processing {len(user_stories)} sample user stories...\")\n",
    "    \n",
    "    # Create processor and run with detailed display\n",
    "    processor = EnhancedIndividualProcessor()\n",
    "    result = await processor.process_stories_with_details(user_stories)\n",
    "    \n",
    "    return result\n",
    "\n",
    "result = await run_with_full_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91976800-a6ce-4ca3-8da1-f8a7261e1007",
   "metadata": {},
   "source": [
    "**Individual Processing Performance Analysis**\n",
    "\n",
    "- Processing Time\n",
    "> **Performance:** ‚≠ê‚≠ê‚≠ê (Slowest)\n",
    "\n",
    "- Characteristics :\n",
    "\n",
    "> Sequential processing of each story\n",
    "\n",
    "> No parallelization benefits\n",
    "\n",
    "> Processing time scales linearly: `O(n)` where n = number of stories\n",
    "\n",
    "> Overhead from multiple API round-trips\n",
    "\n",
    "- Expected Range\n",
    "> **15-30 seconds for 10 stories**\n",
    "\n",
    "- Bottlenecks\n",
    "> **Network latency multiplied by story count**\n",
    "\n",
    "---\n",
    "\n",
    "- üî§ Token Usage\n",
    "> **Efficiency:** ‚≠ê‚≠ê (Highest Usage)\n",
    "\n",
    "\n",
    "- Formula\n",
    "> **(Context + Examples + Story) √ó Number of Stories + Dependencies + Skills**\n",
    "\n",
    "- Estimated Tokens\n",
    "> **~800-1200 per story + analysis overhead**\n",
    "\n",
    "---\n",
    "\n",
    "- API Costs\n",
    "> **Cost Rating:** ‚≠ê (Most Expensive)\n",
    "\n",
    "- Cost Structure\n",
    "> **High number of API calls: Stories + 1 (dependencies) + Unique_Tasks (skills)**\n",
    "\n",
    "- Typical Example\n",
    "> **10 stories = 10 + 1 + 25 = 36 API calls**\n",
    "\n",
    "- Cost Factors\n",
    "  \n",
    "> Maximum API call count\n",
    "\n",
    "> Redundant context transmission\n",
    "\n",
    "> Individual skill mapping calls\n",
    "\n",
    "---\n",
    "\n",
    "- Dependency Detection Accuracy\n",
    "> **Accuracy:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Highest)\n",
    "\n",
    "- Advantages\n",
    "  \n",
    "> Each story gets individual attention\n",
    "\n",
    "> Detailed task breakdown per story\n",
    "\n",
    "> Comprehensive dependency analysis on final consolidated tasks\n",
    "\n",
    "> No context dilution\n",
    "\n",
    "---\n",
    "\n",
    "- üìä Summary\n",
    "\n",
    "- Best Performance Aspects\n",
    "\n",
    "> **‚úÖ Highest reliability and accuracy**\n",
    "\n",
    "> **‚úÖ Battle-tested methodology**\n",
    "\n",
    "> **‚úÖ Error isolation per story**\n",
    "\n",
    "> **‚úÖ Comprehensive individual analysis**\n",
    "\n",
    "- Trade-offs\n",
    "  \n",
    "> **‚ö†Ô∏è Higher API usage**\n",
    "\n",
    "> **‚ö†Ô∏è Slower execution time**\n",
    "\n",
    "> **‚ö†Ô∏è Less efficient for large batches**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be20a6a8-7737-447c-b810-919bbb9bbf53",
   "metadata": {},
   "source": [
    "#### 2.1.2 Strategy 2: Batch All Processing\n",
    "\n",
    "**Approach**: Process all user stories in a single batch\n",
    "\n",
    "**Trade-offs**:\n",
    "- ‚úÖ Better cross-story dependency detection\n",
    "- ‚úÖ Lower API costs with single call\n",
    "- ‚úÖ Maintains global context awareness\n",
    "- ‚ùå Token limit constraints for large batches\n",
    "- ‚ùå Harder to recover from errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2818c74-6429-4ff1-a3ad-4b0596cf9e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ PARTY B: GROUPED PROCESSING WITH FULL DETAILS\n",
      "============================================================\n",
      "Philosophy: 'Smart batching for balanced efficiency'\n",
      "Group size: 2\n",
      "\n",
      "Processing 5 sample user stories...\n",
      "üöÄ OPTIMIZERS: Processing 5 stories in groups of 2...\n",
      "üì¶ Created 3 groups for processing\n",
      "   Processing group 1/3 (2 stories)...\n",
      "   ‚úÖ Group 1 completed\n",
      "   Processing group 2/3 (2 stories)...\n",
      "   ‚úÖ Group 2 completed\n",
      "   Processing group 3/3 (1 stories)...\n",
      "   ‚úÖ Group 3 completed\n",
      "üîÑ Consolidating tasks across all groups...\n",
      "üîó Analyzing task dependencies...\n",
      "üéØ Mapping required skills...\n",
      "‚úÖ SUCCESS: Processed 0 stories with 4 API calls\n",
      "\n",
      "================================================================================\n",
      "üöÄ PARTY B: OPTIMIZERS - COMPLETE DETAILED RESULTS\n",
      "================================================================================\n",
      "\n",
      "üìä PERFORMANCE SUMMARY:\n",
      "--------------------------------------------------\n",
      "‚è±Ô∏è  Execution Time: 5.02 seconds\n",
      "üîå API Calls: 4\n",
      "üì¶ Group Size: 2\n",
      "üìã Total Tasks Generated: 0\n",
      "üéØ Unique Tasks After Consolidation: 0\n",
      "üîÑ Duplicate Reduction: 0.0%\n",
      "üîó Dependencies Found: 0\n",
      "üõ†Ô∏è  Skills Identified: 0\n",
      "‚ö° Efficiency: 0.00 tasks per API call\n",
      "\n",
      "üìã ALL 0 CONSOLIDATED TASKS:\n",
      "--------------------------------------------------\n",
      "\n",
      "üîó TASK DEPENDENCIES:\n",
      "--------------------------------------------------\n",
      "‚ÑπÔ∏è  No dependencies detected between tasks\n",
      "\n",
      "üéØ SKILLS REQUIRED FOR EACH TASK:\n",
      "--------------------------------------------------\n",
      "\n",
      "üì¶ GROUPING ANALYSIS:\n",
      "--------------------------------------------------\n",
      "üìä Tasks Generated per Story:\n",
      "\n",
      "üéØ Grouping Efficiency:\n",
      "   ‚Ä¢ Group size used: 2\n",
      "   ‚Ä¢ Number of groups: 3\n",
      "   ‚Ä¢ Average tasks per group call: 0.0\n",
      "\n",
      "üõ†Ô∏è  Skills Analysis:\n",
      "   ‚Ä¢ Unique skills identified: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@dataclass\n",
    "class ProcessingResults:\n",
    "    method: str\n",
    "    execution_time: float\n",
    "    api_calls: int\n",
    "    total_tasks: int\n",
    "    unique_tasks: int\n",
    "    duplicate_reduction: float\n",
    "    dependencies_found: int\n",
    "    total_skills: int\n",
    "    stories_processed: int\n",
    "    errors: List[str]\n",
    "\n",
    "class GroupedBatchDecomposer:\n",
    "    \"\"\"Batch decomposer optimized for group processing\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.few_shot_examples = \"\"\"\n",
    "User Stories:\n",
    "1. As a user, I want to click on the address so that it takes me to a new tab with Google Maps.\n",
    "2. As a user, I want to be able to anonymously view public information so that I know about recycling centers near me before creating an account.\n",
    "3. As a user, I want to create an account so that I can save my favorite recycling centers.\n",
    "\n",
    "Tasks for Story 1:\n",
    "1. Make address text clickable\n",
    "2. Implement click handler to format address for Google Maps URL\n",
    "3. Open Google Maps in new tab/window\n",
    "4. Add proper URL encoding for address parameters\n",
    "\n",
    "Tasks for Story 2:\n",
    "1. Design public landing page layout\n",
    "2. Create anonymous user session handling\n",
    "3. Implement facility search without authentication\n",
    "4. Display basic facility information publicly \n",
    "5. Design facility component\n",
    "6. Detect user's location via browser API or IP\n",
    "7. Show recycling centers within a radius of the user\n",
    "8. Design facility list display component\n",
    "\n",
    "Tasks for Story 3:\n",
    "1. Design user registration form\n",
    "2. Implement user authentication system\n",
    "3. Create user profile management\n",
    "4. Add favorites functionality to UI\n",
    "5. Implement save/unsave facility feature\n",
    "6. Design favorites list component\n",
    "\"\"\"\n",
    "    \n",
    "    async def decompose_group(self, user_stories: List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"Decompose a group of user stories (typically 3-5 stories)\"\"\"\n",
    "        stories_text = \"\\n\".join([f\"{i+1}. {story}\" for i, story in enumerate(user_stories)])\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are a task decomposition expert. Break down EACH of the following user stories into specific, actionable technical tasks.\n",
    "Each task should be simple and focused on a single responsibility.\n",
    "\n",
    "For each user story, provide tasks in the format:\n",
    "Tasks for Story X:\n",
    "1. Task description\n",
    "2. Task description\n",
    "...\n",
    "\n",
    "IMPORTANT: Return tasks for ALL user stories. Do NOT skip any stories.\n",
    "\n",
    "Examples:\n",
    "{self.few_shot_examples}\n",
    "\n",
    "User Stories:\n",
    "{stories_text}\n",
    "\n",
    "Tasks:\n",
    "\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"llama3-70b-8192\",\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        return self._parse_response(response.choices[0].message.content.strip(), user_stories)\n",
    "    \n",
    "    def _parse_response(self, content: str, user_stories: List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"Parse the LLM response into structured task data\"\"\"\n",
    "        result = {}\n",
    "        lines = content.split('\\n')\n",
    "        current_story = None\n",
    "        current_tasks = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            if line.lower().startswith('tasks for story'):\n",
    "                if current_story is not None and current_tasks:\n",
    "                    result[current_story] = current_tasks\n",
    "                \n",
    "                story_match = re.search(r'story\\s+(\\d+)', line.lower())\n",
    "                if story_match:\n",
    "                    story_num = int(story_match.group(1)) - 1\n",
    "                    if 0 <= story_num < len(user_stories):\n",
    "                        current_story = user_stories[story_num]\n",
    "                        current_tasks = []\n",
    "            \n",
    "            elif line and any(line.startswith(str(i) + '.') for i in range(1, 21)):\n",
    "                task = re.sub(r'^\\d+\\.\\s*', '', line).strip()\n",
    "                if task and len(task) > 10:\n",
    "                    current_tasks.append(task)\n",
    "        \n",
    "        if current_story is not None and current_tasks:\n",
    "            result[current_story] = current_tasks\n",
    "        \n",
    "        return result\n",
    "\n",
    "class EnhancedGroupedProcessor:\n",
    "    \"\"\"\n",
    "    Enhanced Grouped Processor that captures and displays detailed results\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, group_size: int = 3):\n",
    "        self.group_size = group_size\n",
    "        self.batch_decomposer = GroupedBatchDecomposer()\n",
    "        self.consolidator = TaskConsolidatorAgent()\n",
    "        self.dependency_analyzer = DependencyAnalyzerAgent()\n",
    "        self.skill_mapper = SkillMapperAgent()\n",
    "    \n",
    "    async def process_stories_with_details(self, user_stories: List[str]):\n",
    "        \"\"\"Process stories and immediately display detailed results\"\"\"\n",
    "        print(f\"üöÄ OPTIMIZERS: Processing {len(user_stories)} stories in groups of {self.group_size}...\")\n",
    "        start_time = time.time()\n",
    "        errors = []\n",
    "        api_calls = 0\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Group stories and decompose each group\n",
    "            groups = [user_stories[i:i + self.group_size] for i in range(0, len(user_stories), self.group_size)]\n",
    "            all_user_stories_tasks = {}\n",
    "            \n",
    "            print(f\"üì¶ Created {len(groups)} groups for processing\")\n",
    "            \n",
    "            for i, group in enumerate(groups, 1):\n",
    "                try:\n",
    "                    print(f\"   Processing group {i}/{len(groups)} ({len(group)} stories)...\")\n",
    "                    group_tasks = await self.batch_decomposer.decompose_group(group)\n",
    "                    api_calls += 1\n",
    "                    all_user_stories_tasks.update(group_tasks)\n",
    "                    print(f\"   ‚úÖ Group {i} completed\")\n",
    "                except Exception as e:\n",
    "                    error_msg = f\"Failed to process group {i}: {str(e)}\"\n",
    "                    errors.append(error_msg)\n",
    "                    print(f\"   ‚ùå {error_msg}\")\n",
    "            \n",
    "            # Step 2: Consolidate tasks from all groups\n",
    "            print(\"üîÑ Consolidating tasks across all groups...\")\n",
    "            unique_tasks, task_origins = self.consolidator.consolidate_tasks(all_user_stories_tasks)\n",
    "            \n",
    "            # Step 3: Analyze dependencies\n",
    "            print(\"üîó Analyzing task dependencies...\")\n",
    "            dependencies = await self.dependency_analyzer.analyze(unique_tasks)\n",
    "            api_calls += 1\n",
    "            \n",
    "            # Step 4: Map skills for each unique task\n",
    "            print(\"üéØ Mapping required skills...\")\n",
    "            skill_map = {}\n",
    "            for task in unique_tasks:\n",
    "                try:\n",
    "                    skills = await self.skill_mapper.map_skills(task)\n",
    "                    skill_map[task] = skills\n",
    "                    api_calls += 1\n",
    "                except Exception as e:\n",
    "                    error_msg = f\"Failed to map skills for task: {str(e)}\"\n",
    "                    errors.append(error_msg)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            total_tasks = sum(len(tasks) for tasks in all_user_stories_tasks.values())\n",
    "            duplicate_reduction = (total_tasks - len(unique_tasks)) / total_tasks if total_tasks > 0 else 0\n",
    "            dependencies_found = sum(len(deps) for deps in dependencies.values())\n",
    "            total_skills = sum(len(skills) for skills in skill_map.values())\n",
    "            \n",
    "            print(f\"‚úÖ SUCCESS: Processed {len(all_user_stories_tasks)} stories with {api_calls} API calls\")\n",
    "            \n",
    "            # IMMEDIATELY DISPLAY DETAILED RESULTS\n",
    "            self.display_detailed_results(\n",
    "                unique_tasks, task_origins, dependencies, skill_map, \n",
    "                time.time() - start_time, api_calls, total_tasks, errors\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"tasks\": unique_tasks,\n",
    "                \"task_origins\": task_origins,\n",
    "                \"dependencies\": dependencies,\n",
    "                \"required_skills\": skill_map,\n",
    "                \"api_calls\": api_calls,\n",
    "                \"execution_time\": time.time() - start_time,\n",
    "                \"errors\": errors\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå CRITICAL ERROR: {str(e)}\")\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def display_detailed_results(self, unique_tasks, task_origins, dependencies, skill_map, execution_time, api_calls, total_tasks, errors):\n",
    "        \"\"\"Display comprehensive detailed results immediately\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üöÄ PARTY B: OPTIMIZERS - COMPLETE DETAILED RESULTS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # SUMMARY METRICS\n",
    "        print(f\"\\nüìä PERFORMANCE SUMMARY:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"‚è±Ô∏è  Execution Time: {execution_time:.2f} seconds\")\n",
    "        print(f\"üîå API Calls: {api_calls}\")\n",
    "        print(f\"üì¶ Group Size: {self.group_size}\")\n",
    "        print(f\"üìã Total Tasks Generated: {total_tasks}\")\n",
    "        print(f\"üéØ Unique Tasks After Consolidation: {len(unique_tasks)}\")\n",
    "        print(f\"üîÑ Duplicate Reduction: {((total_tasks - len(unique_tasks)) / total_tasks * 100) if total_tasks > 0 else 0:.1f}%\")\n",
    "        print(f\"üîó Dependencies Found: {sum(len(deps) for deps in dependencies.values())}\")\n",
    "        print(f\"üõ†Ô∏è  Skills Identified: {sum(len(skills) for skills in skill_map.values())}\")\n",
    "        print(f\"‚ö° Efficiency: {len(unique_tasks) / api_calls:.2f} tasks per API call\")\n",
    "        \n",
    "        if errors:\n",
    "            print(f\"‚ö†Ô∏è  Errors: {len(errors)}\")\n",
    "            for error in errors:\n",
    "                print(f\"   ‚Ä¢ {error}\")\n",
    "        \n",
    "        # DETAILED TASKS\n",
    "        print(f\"\\nüìã ALL {len(unique_tasks)} CONSOLIDATED TASKS:\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, task in enumerate(unique_tasks, 1):\n",
    "            print(f\"{i:2d}. {task}\")\n",
    "            \n",
    "            # Show which story(ies) generated this task\n",
    "            origins = task_origins.get(task, [])\n",
    "            if origins:\n",
    "                if len(origins) == 1:\n",
    "                    print(f\"    ‚îî‚îÄ From: {origins[0][:60]}...\")\n",
    "                else:\n",
    "                    print(f\"    ‚îî‚îÄ From {len(origins)} stories (DUPLICATE CONSOLIDATED):\")\n",
    "                    for origin in origins:\n",
    "                        print(f\"       ‚Ä¢ {origin[:55]}...\")\n",
    "            print()\n",
    "        \n",
    "        # DEPENDENCIES\n",
    "        print(f\"\\nüîó TASK DEPENDENCIES:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        tasks_with_deps = {task: deps for task, deps in dependencies.items() if deps}\n",
    "        \n",
    "        if tasks_with_deps:\n",
    "            print(f\"Found {len(tasks_with_deps)} tasks with dependencies:\\n\")\n",
    "            \n",
    "            for i, (task, deps) in enumerate(tasks_with_deps.items(), 1):\n",
    "                print(f\"{i}. üìã TASK: {task}\")\n",
    "                print(f\"   ‚¨áÔ∏è  DEPENDS ON:\")\n",
    "                for j, dep in enumerate(deps, 1):\n",
    "                    print(f\"      {j}. {dep}\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è  No dependencies detected between tasks\")\n",
    "        \n",
    "        # SKILLS MAPPING\n",
    "        print(f\"\\nüéØ SKILLS REQUIRED FOR EACH TASK:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, (task, skills) in enumerate(skill_map.items(), 1):\n",
    "            if skills:  # Only show tasks with skills\n",
    "                print(f\"{i:2d}. üìã {task}\")\n",
    "                print(f\"     üõ†Ô∏è  Skills: {', '.join(skills)}\")\n",
    "                print()\n",
    "        \n",
    "        # GROUPING ANALYSIS\n",
    "        print(f\"\\nüì¶ GROUPING ANALYSIS:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Analyze how tasks were distributed from groups\n",
    "        story_counts = {}\n",
    "        for task, origins in task_origins.items():\n",
    "            for origin in origins:\n",
    "                short_origin = origin[:40] + \"...\" if len(origin) > 40 else origin\n",
    "                story_counts[short_origin] = story_counts.get(short_origin, 0) + 1\n",
    "        \n",
    "        print(\"üìä Tasks Generated per Story:\")\n",
    "        for story, count in story_counts.items():\n",
    "            print(f\"   ‚Ä¢ {story}: {count} tasks\")\n",
    "        \n",
    "        print(f\"\\nüéØ Grouping Efficiency:\")\n",
    "        print(f\"   ‚Ä¢ Group size used: {self.group_size}\")\n",
    "        print(f\"   ‚Ä¢ Number of groups: {api_calls - 1 - len(unique_tasks)}\") # Subtract dependency and skill calls\n",
    "        print(f\"   ‚Ä¢ Average tasks per group call: {total_tasks / max(1, api_calls - 1 - len(unique_tasks)):.1f}\")\n",
    "        \n",
    "        # Skills analysis\n",
    "        all_skills = set()\n",
    "        for skills in skill_map.values():\n",
    "            all_skills.update(skills)\n",
    "        \n",
    "        print(f\"\\nüõ†Ô∏è  Skills Analysis:\")\n",
    "        print(f\"   ‚Ä¢ Unique skills identified: {len(all_skills)}\")\n",
    "        if all_skills:\n",
    "            print(f\"   ‚Ä¢ Most common skills: {', '.join(list(all_skills)[:5])}\")\n",
    "\n",
    "# ============================================================================\n",
    "# JUPYTER-COMPATIBLE FUNCTION WITH DETAILED DISPLAY\n",
    "# ============================================================================\n",
    "\n",
    "async def run_grouped_with_full_details(group_size: int = 3):\n",
    "    \"\"\"Run the grouped processor and display all detailed results immediately\"\"\"\n",
    "    \n",
    "    print(\"üöÄ PARTY B: GROUPED PROCESSING WITH FULL DETAILS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Philosophy: 'Smart batching for balanced efficiency'\")\n",
    "    print(f\"Group size: {group_size}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Use sample stories\n",
    "    user_stories = SAMPLE_USER_STORIES\n",
    "    print(f\"Processing {len(user_stories)} sample user stories...\")\n",
    "    \n",
    "    # Create processor and run with detailed display\n",
    "    processor = EnhancedGroupedProcessor(group_size=group_size)\n",
    "    result = await processor.process_stories_with_details(user_stories)\n",
    "    \n",
    "    return result\n",
    "\n",
    "result = await run_grouped_with_full_details(group_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed2197f-7974-409f-8b69-229202d45684",
   "metadata": {},
   "source": [
    "**Grouped Processing Performance Analysis**\n",
    "- Processing Time\n",
    "> **Performance:** ‚≠ê‚≠ê‚≠ê‚≠ê (Balanced)\n",
    "- Characteristics :\n",
    "  \n",
    "> Moderate parallelization through grouping\n",
    "\n",
    "> Processing time: `O(n/g)` where g = group size\n",
    "\n",
    "> Reduced API round-trips\n",
    "\n",
    "> Configurable group sizes for optimization\n",
    "- Expected Range\n",
    "> **8-15 seconds for 10 stories (groups of 3)**\n",
    "- Bottlenecks\n",
    "> **Sweet spot between speed and reliability**\n",
    "---\n",
    "- üî§ Token Usage\n",
    "> **Efficiency:** ‚≠ê‚≠ê‚≠ê‚≠ê (Balanced)\n",
    "- Formula\n",
    "> **(Context + Examples + Group_Stories) √ó Number_of_Groups + Dependencies + Skills**\n",
    "- Estimated Tokens\n",
    "> **~400-600 per story + analysis overhead**\n",
    "---\n",
    "- API Costs\n",
    "> **Cost Rating:** ‚≠ê‚≠ê‚≠ê‚≠ê (Moderate)\n",
    "---\n",
    "- Dependency Detection Accuracy\n",
    "> **Accuracy:** ‚≠ê‚≠ê‚≠ê‚≠ê (High)\n",
    "- Advantages\n",
    "  \n",
    "> Good task breakdown within groups\n",
    "\n",
    "> Effective cross-group dependency detection\n",
    "\n",
    "> Minimal context dilution\n",
    "\n",
    "> Balanced detail vs. efficiency\n",
    "- Trade-offs\n",
    "  \n",
    "> Slightly less granular than individual processing\n",
    "\n",
    "> Good inter-group dependency mapping\n",
    "\n",
    "> Maintains quality while improving speed\n",
    "---\n",
    "- Error Recovery Capability\n",
    "> **Resilience:** ‚≠ê‚≠ê‚≠ê‚≠ê (Very Good)\n",
    "- Recovery Features\n",
    "  \n",
    "> **Group Isolation:** Failed group doesn't affect others\n",
    "\n",
    "> **Partial Processing:** Can continue with successful groups\n",
    "\n",
    "> **Adaptive Grouping:** Can adjust group sizes based on failure patterns\n",
    "\n",
    "> **Moderate Debugging:** Can isolate issues to specific groups\n",
    "- Failure Scenarios\n",
    "> **Group failure rate ~5-10%**\n",
    "---\n",
    "- üìä Summary\n",
    "- Best Performance Aspects\n",
    "  \n",
    "> **‚úÖ Balanced efficiency vs. reliability**\n",
    "\n",
    "> **‚úÖ Scalable to large story sets**\n",
    "\n",
    "> **‚úÖ Error resilience per group**\n",
    "\n",
    "> **‚úÖ Configurable group sizes**\n",
    "- Trade-offs\n",
    "  \n",
    "> **‚ö†Ô∏è More complex than batch-all**\n",
    "\n",
    "> **‚ö†Ô∏è Coordination overhead**\n",
    "\n",
    "> **‚ö†Ô∏è Not maximally efficient**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f90bd-174c-4fb0-891a-b66fc2b60c6d",
   "metadata": {},
   "source": [
    "#### 2.1.3 Strategy 3: Grouped Processing\n",
    "\n",
    "**Approach**: Process user stories in logical groups\n",
    "\n",
    "**Trade-offs**:\n",
    "- ‚úÖ Balanced approach between individual and batch\n",
    "- ‚úÖ Some dependency detection within groups\n",
    "- ‚úÖ Manageable token usage\n",
    "- ‚ùå May miss cross-group dependencies\n",
    "- ‚ùå Requires post-processing to merge results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08bc864b-3090-45af-9676-430779052dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° PARTY C: FIXED BATCH ALL PROCESSING WITH FULL DETAILS\n",
      "============================================================\n",
      "Philosophy: 'All or nothing - maximum efficiency'\n",
      "Enhanced with robust parsing and debugging\n",
      "\n",
      "Processing 12 sample user stories in ONE MEGA-BATCH...\n",
      "‚ö° REVOLUTIONARIES: Processing ALL 12 stories in one mega-batch...\n",
      "\n",
      "üîç CONTEXT ANALYSIS:\n",
      "   Stories: 12\n",
      "   Estimated tokens: 315\n",
      "   Risk level: LOW\n",
      "\n",
      "üöÄ Launching mega-batch decomposition...\n",
      "üîç DEBUG: Sending 12 stories to LLM...\n",
      "üîç DEBUG: Received response length: 3259 characters\n",
      "üîç DEBUG: First 200 chars: Here are the tasks for each user story:\n",
      "\n",
      "**Tasks for Story 1:**\n",
      "1. Make address text clickable\n",
      "2. Implement click handler to format address for Google Maps URL\n",
      "3. Open Google Maps in new tab/window\n",
      "4....\n",
      "üîç DEBUG: Starting to parse response for 12 stories\n",
      "üîç DEBUG: Processing 85 lines...\n",
      "üîç DEBUG: Added task: Make address text clickable...\n",
      "üîç DEBUG: Added task: Implement click handler to format address for Google Maps UR...\n",
      "üîç DEBUG: Added task: Open Google Maps in new tab/window...\n",
      "üîç DEBUG: Final result: 0 stories with tasks\n",
      "üîç DEBUG: No results from primary parsing, trying fallback...\n",
      "üîç DEBUG: Using fallback parsing...\n",
      "üîç DEBUG: Fallback saved final 60 tasks for story 1\n",
      "üîç DEBUG: Parsed 1 stories from response\n",
      "‚úÖ Successfully decomposed 1 stories!\n",
      "   üìã As a user, I want to click on the address so that ... -> 60 tasks\n",
      "\n",
      "üîÑ Consolidating tasks across entire batch...\n",
      "üìä Consolidated 60 tasks into 60 unique tasks\n",
      "üîó Analyzing dependencies across all tasks...\n",
      "[DEPENDENCY_ANALYSIS] Tokens - Input: 926, Output: 628, Total: 1554\n",
      "üéØ Mapping skills for all unique tasks...\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 10, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 7, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 10, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 11, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 10, Total: 155\n",
      "   Progress: 5/60 tasks processed\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 10, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 143, Output: 10, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 12, Total: 161\n",
      "   Progress: 10/60 tasks processed\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 23, Total: 172\n",
      "[SKILL_MAPPING] Tokens - Input: 153, Output: 13, Total: 166\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 16, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 11, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 12, Total: 156\n",
      "   Progress: 15/60 tasks processed\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 13, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 13, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 10, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "   Progress: 20/60 tasks processed\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 7, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 10, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 16, Total: 162\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 21, Total: 167\n",
      "   Progress: 25/60 tasks processed\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 7, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 7, Total: 151\n",
      "   Progress: 30/60 tasks processed\n",
      "[SKILL_MAPPING] Tokens - Input: 151, Output: 17, Total: 168\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 7, Total: 151\n",
      "[SKILL_MAPPING] Tokens - Input: 152, Output: 13, Total: 165\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 10, Total: 154\n",
      "   Progress: 35/60 tasks processed\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 7, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 7, Total: 151\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 6, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 11, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "   Progress: 40/60 tasks processed\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 12, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 152, Output: 12, Total: 164\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 10, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "   Progress: 45/60 tasks processed\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 10, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 13, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 10, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 13, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 10, Total: 155\n",
      "   Progress: 50/60 tasks processed\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 12, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 6, Total: 150\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 13, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 16, Total: 162\n",
      "   Progress: 55/60 tasks processed\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 7, Total: 151\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 7, Total: 151\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 11, Total: 161\n",
      "   Progress: 60/60 tasks processed\n",
      "‚úÖ Successfully mapped skills for 60/60 tasks\n",
      "üèÜ MEGA SUCCESS: Processed 1 stories with only 62 API calls!\n",
      "‚ö° Efficiency: 0.97 tasks per API call\n",
      "\n",
      "================================================================================\n",
      "‚ö° PARTY C: REVOLUTIONARIES - COMPLETE DETAILED RESULTS\n",
      "================================================================================\n",
      "\n",
      "üìä REVOLUTIONARY PERFORMANCE SUMMARY:\n",
      "--------------------------------------------------\n",
      "‚è±Ô∏è  Execution Time: 91.89 seconds\n",
      "üîå API Calls: 62 (ULTRA-EFFICIENT!)\n",
      "üìã Total Tasks Generated: 60\n",
      "üéØ Unique Tasks After Consolidation: 60\n",
      "üîÑ Duplicate Reduction: 0.0%\n",
      "üîó Dependencies Found: 27\n",
      "üõ†Ô∏è  Skills Identified: 164\n",
      "‚ö° EFFICIENCY SCORE: 0.97 tasks per API call üöÄ\n",
      "\n",
      "üîç CONTEXT WINDOW ANALYSIS:\n",
      "   Stories processed: 12\n",
      "   Estimated tokens used: 315\n",
      "   Risk level: LOW\n",
      "   Within safe limits: ‚úÖ YES\n",
      "\n",
      "üìã ALL 60 MEGA-BATCH PROCESSED TASKS:\n",
      "--------------------------------------------------\n",
      " 1. Make address text clickable\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      " 2. Implement click handler to format address for Google Maps URL\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      " 3. Open Google Maps in new tab/window\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      " 4. Add proper URL encoding for address parameters\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      " 5. Design public landing page layout\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      " 6. Create anonymous user session handling\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      " 7. Implement facility search without authentication\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      " 8. Display basic facility information publicly\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      " 9. Design facility component\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "10. Detect user's location via browser API or IP\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "11. Show recycling centers within a radius of the user\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "12. Implement filtering by distance (optional, but related to story 8)\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "13. Design user registration form\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "14. Implement user authentication system\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "15. Create user profile management\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "16. Add favorites functionality to UI\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "17. Implement save/unsave facility feature\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "18. Integrate with facility search results\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "19. Design material type search input field\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "20. Implement material type search functionality\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "21. Update facility search results to include material type filtering\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "22. Create material type database schema\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "23. Populate material type database with relevant data\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "24. Design rating and review input form\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "25. Implement rating and review submission functionality\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "26. Create rating and review database schema\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "27. Populate rating and review database with user submissions\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "28. Display ratings and reviews on facility detail page\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "29. Implement rating and review moderation functionality (optional)\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "30. Design notification system architecture\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "31. Implement notification system for new recycling centers in user's area\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "32. Integrate with user profile management\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "33. Create notification preferences management\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "34. Implement notification sending functionality (e.g., email, in-app)\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "35. Design admin dashboard layout\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "36. Implement facility management functionality (CRUD operations)\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "37. Create facility database schema\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "38. Populate facility database with initial data\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "39. Implement data validation and sanitization for facility information\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "40. Implement distance-based filtering for facility search results\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "41. Update facility search results to include distance information\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "42. Integrate with user's location detection (from Story 2)\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "43. Design operating hours display component\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "44. Implement operating hours display on facility detail page\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "45. Create operating hours database schema\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "46. Populate operating hours database with relevant data\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "47. Implement directions functionality using Google Maps API\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "48. Integrate with facility detail page\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "49. Add directions button to facility search results\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "50. Design photo upload input field\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "51. Implement photo upload functionality\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "52. Create photo database schema\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "53. Populate photo database with user uploads\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "54. Display photos on facility detail page\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "55. Design report incorrect information input form\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "56. Implement report submission functionality\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "57. Create report database schema\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "58. Populate report database with user submissions\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "59. Implement report moderation functionality (optional)\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "60. Integrate with facility management functionality (Story 7)\n",
      "    ‚îî‚îÄ From: As a user, I want to click on the address so that it takes m...\n",
      "\n",
      "\n",
      "üîó TASK DEPENDENCIES:\n",
      "--------------------------------------------------\n",
      "Found 27 tasks with dependencies:\n",
      "\n",
      "1. üìã TASK: Make address text clickable\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design facility component', 'coupling': 'tight', 'rework_effort': '3'}\n",
      "\n",
      "2. üìã TASK: Implement click handler to format address for Google Maps URL\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Make address text clickable', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "3. üìã TASK: Open Google Maps in new tab/window\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement click handler to format address for Google Maps URL', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "4. üìã TASK: Add proper URL encoding for address parameters\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement click handler to format address for Google Maps URL', 'coupling': 'loose', 'rework_effort': '1'}\n",
      "\n",
      "5. üìã TASK: Implement facility search without authentication\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create anonymous user session handling', 'coupling': 'tight', 'rework_effort': '8'}\n",
      "\n",
      "6. üìã TASK: Display basic facility information publicly\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design facility component', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "7. üìã TASK: Show recycling centers within a radius of the user\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': \"Detect user's location via browser API or IP\", 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "8. üìã TASK: Implement filtering by distance (optional, but related to story 8)\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Display basic facility information publicly', 'coupling': 'moderate', 'rework_effort': '3'}\n",
      "\n",
      "9. üìã TASK: Integrate with facility search results\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement save/unsave facility feature', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "10. üìã TASK: Update facility search results to include material type filtering\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement material type search functionality', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "11. üìã TASK: Create material type database schema\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement material type search functionality', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "12. üìã TASK: Display ratings and reviews on facility detail page\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Populate rating and review database with user submissions', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "13. üìã TASK: Implement notification system for new recycling centers in user's area\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Design notification system architecture', 'coupling': 'tight', 'rework_effort': '8'}\n",
      "\n",
      "14. üìã TASK: Integrate with user profile management\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create user profile management', 'coupling': 'moderate', 'rework_effort': '3'}\n",
      "\n",
      "15. üìã TASK: Implement facility management functionality (CRUD operations)\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create facility database schema', 'coupling': 'tight', 'rework_effort': '8'}\n",
      "\n",
      "16. üìã TASK: Implement data validation and sanitization for facility information\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Populate facility database with initial data', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "17. üìã TASK: Implement distance-based filtering for facility search results\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': \"Integrate with user's location detection (from Story 2)\", 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "18. üìã TASK: Update facility search results to include distance information\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement distance-based filtering for facility search results', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "19. üìã TASK: Design operating hours display component\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': \"Integrate with user's location detection (from Story 2)\", 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "20. üìã TASK: Implement operating hours display on facility detail page\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Create operating hours database schema', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "21. üìã TASK: Implement directions functionality using Google Maps API\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Populate operating hours database with relevant data', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "22. üìã TASK: Integrate with facility detail page\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement directions functionality using Google Maps API', 'coupling': 'moderate', 'rework_effort': '2'}\n",
      "\n",
      "23. üìã TASK: Add directions button to facility search results\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement directions functionality using Google Maps API', 'coupling': 'loose', 'rework_effort': '1'}\n",
      "\n",
      "24. üìã TASK: Display photos on facility detail page\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Populate photo database with user uploads', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "25. üìã TASK: Create report database schema\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement report submission functionality', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "26. üìã TASK: Implement report moderation functionality (optional)\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Populate report database with user submissions', 'coupling': 'tight', 'rework_effort': '5'}\n",
      "\n",
      "27. üìã TASK: Integrate with facility management functionality (Story 7)\n",
      "   ‚¨áÔ∏è  DEPENDS ON:\n",
      "      1. {'task': 'Implement facility management functionality (CRUD operations)', 'coupling': 'moderate', 'rework_effort': '3'}\n",
      "\n",
      "\n",
      "üéØ SKILLS REQUIRED FOR EACH TASK:\n",
      "--------------------------------------------------\n",
      " 1. üìã Make address text clickable\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML\n",
      "\n",
      " 2. üìã Implement click handler to format address for Google Maps URL\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript\n",
      "\n",
      " 3. üìã Open Google Maps in new tab/window\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, HTML\n",
      "\n",
      " 4. üìã Add proper URL encoding for address parameters\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, URL encoding\n",
      "\n",
      " 5. üìã Design public landing page layout\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design\n",
      "\n",
      " 6. üìã Create anonymous user session handling\n",
      "     üõ†Ô∏è  Skills: Backend development, Session management\n",
      "\n",
      " 7. üìã Implement facility search without authentication\n",
      "     üõ†Ô∏è  Skills: Backend development, Database skills\n",
      "\n",
      " 8. üìã Display basic facility information publicly\n",
      "     üõ†Ô∏è  Skills: Frontend development, HTML, CSS\n",
      "\n",
      " 9. üìã Design facility component\n",
      "     üõ†Ô∏è  Skills: Frontend development, UI/UX design\n",
      "\n",
      "10. üìã Detect user's location via browser API or IP\n",
      "     üõ†Ô∏è  Skills: Frontend development, JavaScript, Geolocation API\n",
      "\n",
      "   ... and skills for 50 more tasks\n",
      "\n",
      "üéØ REVOLUTIONARY VERDICT:\n",
      "   ‚ö†Ô∏è  EFFICIENCY CONCERNS - Consider optimizing or using grouped approach\n",
      "\n",
      "üí• RISK vs REWARD SUMMARY:\n",
      "   ‚úÖ REWARDS: Minimal API calls (62), Maximum speed, Lowest cost\n",
      "   ‚ö†Ô∏è  RISKS: Single point of failure, Context limits, Harder debugging\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ProcessingResults:\n",
    "    method: str\n",
    "    execution_time: float\n",
    "    api_calls: int\n",
    "    total_tasks: int\n",
    "    unique_tasks: int\n",
    "    duplicate_reduction: float\n",
    "    dependencies_found: int\n",
    "    total_skills: int\n",
    "    stories_processed: int\n",
    "    errors: List[str]\n",
    "\n",
    "class FixedBatchAllTaskDecomposer:\n",
    "    \"\"\"Ultra-efficient batch decomposer with robust parsing\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.few_shot_examples = \"\"\"\n",
    "User Stories:\n",
    "1. As a user, I want to click on the address so that it takes me to a new tab with Google Maps.\n",
    "2. As a user, I want to be able to anonymously view public information so that I know about recycling centers near me before creating an account.\n",
    "3. As a user, I want to create an account so that I can save my favorite recycling centers.\n",
    "\n",
    "Tasks for Story 1:\n",
    "1. Make address text clickable\n",
    "2. Implement click handler to format address for Google Maps URL\n",
    "3. Open Google Maps in new tab/window\n",
    "4. Add proper URL encoding for address parameters\n",
    "\n",
    "Tasks for Story 2:\n",
    "1. Design public landing page layout\n",
    "2. Create anonymous user session handling\n",
    "3. Implement facility search without authentication\n",
    "4. Display basic facility information publicly \n",
    "5. Design facility component\n",
    "6. Detect user's location via browser API or IP\n",
    "7. Show recycling centers within a radius of the user\n",
    "\n",
    "Tasks for Story 3:\n",
    "1. Design user registration form\n",
    "2. Implement user authentication system\n",
    "3. Create user profile management\n",
    "4. Add favorites functionality to UI\n",
    "5. Implement save/unsave facility feature\n",
    "\"\"\"\n",
    "    \n",
    "    async def decompose_all_stories(self, user_stories: List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Decompose ALL user stories in a single, powerful API call.\n",
    "        \"\"\"\n",
    "        stories_text = \"\\n\".join([f\"{i+1}. {story}\" for i, story in enumerate(user_stories)])\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert task decomposition system. Break down ALL of the following user stories into specific, actionable technical tasks.\n",
    "\n",
    "For each user story, provide tasks in the format:\n",
    "Tasks for Story X:\n",
    "1. Task description\n",
    "2. Task description\n",
    "...\n",
    "\n",
    "CRITICAL: Return tasks for EVERY SINGLE user story provided. Do NOT skip any stories.\n",
    "\n",
    "Examples:\n",
    "{self.few_shot_examples}\n",
    "\n",
    "User Stories to Process:\n",
    "{stories_text}\n",
    "\n",
    "Tasks:\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            print(f\"üîç DEBUG: Sending {len(user_stories)} stories to LLM...\")\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                model=\"llama3-70b-8192\",\n",
    "                temperature=0.3,\n",
    "                max_tokens=4000\n",
    "            )\n",
    "            \n",
    "            raw_response = response.choices[0].message.content.strip()\n",
    "            print(f\"üîç DEBUG: Received response length: {len(raw_response)} characters\")\n",
    "            print(f\"üîç DEBUG: First 200 chars: {raw_response[:200]}...\")\n",
    "            \n",
    "            parsed_result = self._parse_massive_response(raw_response, user_stories)\n",
    "            print(f\"üîç DEBUG: Parsed {len(parsed_result)} stories from response\")\n",
    "            \n",
    "            return parsed_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"üîç DEBUG: Exception in decompose_all_stories: {str(e)}\")\n",
    "            raise Exception(f\"Batch decomposition failed: {str(e)}\")\n",
    "    \n",
    "    def _parse_massive_response(self, content: str, user_stories: List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Enhanced parsing with better error handling and debugging\n",
    "        \"\"\"\n",
    "        print(f\"üîç DEBUG: Starting to parse response for {len(user_stories)} stories\")\n",
    "        \n",
    "        result = {}\n",
    "        lines = content.split('\\n')\n",
    "        current_story = None\n",
    "        current_tasks = []\n",
    "        \n",
    "        print(f\"üîç DEBUG: Processing {len(lines)} lines...\")\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Look for story headers with multiple patterns\n",
    "            if (line.lower().startswith('tasks for story') or \n",
    "                line.lower().startswith('story') or\n",
    "                re.match(r'^\\d+\\.\\s*as\\s+a', line.lower())):\n",
    "                \n",
    "                # Save previous story if exists\n",
    "                if current_story is not None and current_tasks:\n",
    "                    print(f\"üîç DEBUG: Saved {len(current_tasks)} tasks for story: {current_story[:50]}...\")\n",
    "                    result[current_story] = current_tasks\n",
    "                \n",
    "                # Extract story number\n",
    "                story_match = re.search(r'story\\s+(\\d+)', line.lower())\n",
    "                if story_match:\n",
    "                    story_num = int(story_match.group(1)) - 1\n",
    "                    if 0 <= story_num < len(user_stories):\n",
    "                        current_story = user_stories[story_num]\n",
    "                        current_tasks = []\n",
    "                        print(f\"üîç DEBUG: Starting story {story_num + 1}: {current_story[:50]}...\")\n",
    "                    else:\n",
    "                        print(f\"üîç DEBUG: Invalid story number {story_num + 1}\")\n",
    "                else:\n",
    "                    # Try to match the story directly if no number found\n",
    "                    for story in user_stories:\n",
    "                        if story.lower() in line.lower():\n",
    "                            current_story = story\n",
    "                            current_tasks = []\n",
    "                            print(f\"üîç DEBUG: Matched story by content: {story[:50]}...\")\n",
    "                            break\n",
    "            \n",
    "            # Look for task items with flexible patterns\n",
    "            elif line and (any(line.startswith(str(i) + '.') for i in range(1, 51)) or \n",
    "                          line.startswith('-') or \n",
    "                          line.startswith('‚Ä¢')):\n",
    "                \n",
    "                # Extract task text\n",
    "                task = line\n",
    "                if line.startswith(('-', '‚Ä¢')):\n",
    "                    task = line[1:].strip()\n",
    "                else:\n",
    "                    task = re.sub(r'^\\d+\\.\\s*', '', line).strip()\n",
    "                \n",
    "                if task and len(task) > 5:  # More lenient minimum length\n",
    "                    current_tasks.append(task)\n",
    "                    if len(current_tasks) <= 3:  # Only log first few tasks\n",
    "                        print(f\"üîç DEBUG: Added task: {task[:60]}...\")\n",
    "        \n",
    "        # Don't forget the last story\n",
    "        if current_story is not None and current_tasks:\n",
    "            print(f\"üîç DEBUG: Saved final {len(current_tasks)} tasks for story: {current_story[:50]}...\")\n",
    "            result[current_story] = current_tasks\n",
    "        \n",
    "        print(f\"üîç DEBUG: Final result: {len(result)} stories with tasks\")\n",
    "        for story, tasks in result.items():\n",
    "            print(f\"üîç DEBUG: {story[:40]}... -> {len(tasks)} tasks\")\n",
    "        \n",
    "        # If no results, try alternative parsing\n",
    "        if not result:\n",
    "            print(\"üîç DEBUG: No results from primary parsing, trying fallback...\")\n",
    "            result = self._fallback_parsing(content, user_stories)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _fallback_parsing(self, content: str, user_stories: List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"Fallback parsing method\"\"\"\n",
    "        print(\"üîç DEBUG: Using fallback parsing...\")\n",
    "        \n",
    "        result = {}\n",
    "        lines = content.split('\\n')\n",
    "        \n",
    "        # Simple approach: assume tasks are listed after story mentions\n",
    "        current_story_index = 0\n",
    "        current_tasks = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Look for numbered tasks\n",
    "            if re.match(r'^\\d+\\.', line):\n",
    "                task = re.sub(r'^\\d+\\.\\s*', '', line).strip()\n",
    "                if task and len(task) > 5:\n",
    "                    current_tasks.append(task)\n",
    "            \n",
    "            # If we have tasks and see a new story indicator, save current and move to next\n",
    "            elif current_tasks and (line.lower().startswith('story') or \n",
    "                                   line.lower().startswith('tasks') or\n",
    "                                   re.match(r'^\\d+\\.\\s*as\\s+a', line.lower())):\n",
    "                \n",
    "                if current_story_index < len(user_stories):\n",
    "                    result[user_stories[current_story_index]] = current_tasks\n",
    "                    print(f\"üîç DEBUG: Fallback saved {len(current_tasks)} tasks for story {current_story_index + 1}\")\n",
    "                    current_story_index += 1\n",
    "                    current_tasks = []\n",
    "        \n",
    "        # Save final tasks\n",
    "        if current_tasks and current_story_index < len(user_stories):\n",
    "            result[user_stories[current_story_index]] = current_tasks\n",
    "            print(f\"üîç DEBUG: Fallback saved final {len(current_tasks)} tasks for story {current_story_index + 1}\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "class FixedBatchAllProcessor:\n",
    "    \"\"\"\n",
    "    Fixed Batch All Processor with robust error handling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.batch_decomposer = FixedBatchAllTaskDecomposer()\n",
    "        self.consolidator = TaskConsolidatorAgent()\n",
    "        self.dependency_analyzer = DependencyAnalyzerAgent()\n",
    "        self.skill_mapper = SkillMapperAgent()\n",
    "    \n",
    "    def check_context_limits(self, user_stories: List[str]) -> Dict[str, any]:\n",
    "        \"\"\"Analyze if the batch size is appropriate for the LLM context window\"\"\"\n",
    "        total_chars = sum(len(story) for story in user_stories)\n",
    "        estimated_tokens = total_chars // 4  # Rough estimate\n",
    "        \n",
    "        # Llama3-70b has ~8k context window\n",
    "        max_safe_tokens = 6000  # Leave room for response\n",
    "        \n",
    "        analysis = {\n",
    "            \"total_stories\": len(user_stories),\n",
    "            \"total_characters\": total_chars,\n",
    "            \"estimated_tokens\": estimated_tokens,\n",
    "            \"max_safe_tokens\": max_safe_tokens,\n",
    "            \"within_limits\": estimated_tokens < max_safe_tokens,\n",
    "            \"risk_level\": \"LOW\" if estimated_tokens < max_safe_tokens * 0.5 else \n",
    "                        \"MEDIUM\" if estimated_tokens < max_safe_tokens * 0.8 else \"HIGH\"\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    async def process_stories_with_details(self, user_stories: List[str]):\n",
    "        \"\"\"Process stories with enhanced error handling and debugging\"\"\"\n",
    "        print(f\"‚ö° REVOLUTIONARIES: Processing ALL {len(user_stories)} stories in one mega-batch...\")\n",
    "        start_time = time.time()\n",
    "        errors = []\n",
    "        api_calls = 0\n",
    "        \n",
    "        # Context analysis\n",
    "        context_analysis = self.check_context_limits(user_stories)\n",
    "        print(f\"\\nüîç CONTEXT ANALYSIS:\")\n",
    "        print(f\"   Stories: {context_analysis['total_stories']}\")\n",
    "        print(f\"   Estimated tokens: {context_analysis['estimated_tokens']}\")\n",
    "        print(f\"   Risk level: {context_analysis['risk_level']}\")\n",
    "        \n",
    "        if not context_analysis['within_limits']:\n",
    "            print(\"‚ö†Ô∏è  WARNING: Large batch size may hit context limits!\")\n",
    "            print(\"   Proceeding with mega-batch approach anyway...\")\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Decompose ALL stories in one massive call\n",
    "            print(\"\\nüöÄ Launching mega-batch decomposition...\")\n",
    "            user_stories_tasks = await self.batch_decomposer.decompose_all_stories(user_stories)\n",
    "            api_calls += 1\n",
    "            \n",
    "            if not user_stories_tasks:\n",
    "                raise Exception(\"Batch decomposition returned no results after parsing\")\n",
    "            \n",
    "            print(f\"‚úÖ Successfully decomposed {len(user_stories_tasks)} stories!\")\n",
    "            \n",
    "            # Debug: Show what we got\n",
    "            for story, tasks in user_stories_tasks.items():\n",
    "                print(f\"   üìã {story[:50]}... -> {len(tasks)} tasks\")\n",
    "            \n",
    "            # Step 2: Consolidate tasks across all stories\n",
    "            print(\"\\nüîÑ Consolidating tasks across entire batch...\")\n",
    "            unique_tasks, task_origins = self.consolidator.consolidate_tasks(user_stories_tasks)\n",
    "            total_tasks_before_consolidation = sum(len(tasks) for tasks in user_stories_tasks.values())\n",
    "            print(f\"üìä Consolidated {total_tasks_before_consolidation} tasks into {len(unique_tasks)} unique tasks\")\n",
    "            \n",
    "            # Step 3: Analyze dependencies in one call\n",
    "            print(\"üîó Analyzing dependencies across all tasks...\")\n",
    "            dependencies = await self.dependency_analyzer.analyze(unique_tasks)\n",
    "            api_calls += 1\n",
    "            \n",
    "            # Step 4: Map skills for each unique task (with progress tracking)\n",
    "            print(\"üéØ Mapping skills for all unique tasks...\")\n",
    "            skill_map = {}\n",
    "            successful_mappings = 0\n",
    "            \n",
    "            for i, task in enumerate(unique_tasks, 1):\n",
    "                try:\n",
    "                    skills = await self.skill_mapper.map_skills(task)\n",
    "                    skill_map[task] = skills\n",
    "                    successful_mappings += 1\n",
    "                    api_calls += 1\n",
    "                    \n",
    "                    # Progress indicator\n",
    "                    if i % 5 == 0 or i == len(unique_tasks):\n",
    "                        print(f\"   Progress: {i}/{len(unique_tasks)} tasks processed\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    error_msg = f\"Failed to map skills for task '{task[:30]}...': {str(e)}\"\n",
    "                    errors.append(error_msg)\n",
    "            \n",
    "            print(f\"‚úÖ Successfully mapped skills for {successful_mappings}/{len(unique_tasks)} tasks\")\n",
    "            \n",
    "            # Calculate metrics\n",
    "            duplicate_reduction = (total_tasks_before_consolidation - len(unique_tasks)) / total_tasks_before_consolidation if total_tasks_before_consolidation > 0 else 0\n",
    "            dependencies_found = sum(len(deps) for deps in dependencies.values())\n",
    "            total_skills = sum(len(skills) for skills in skill_map.values())\n",
    "            \n",
    "            print(f\"üèÜ MEGA SUCCESS: Processed {len(user_stories_tasks)} stories with only {api_calls} API calls!\")\n",
    "            print(f\"‚ö° Efficiency: {len(unique_tasks) / api_calls:.2f} tasks per API call\")\n",
    "            \n",
    "            # IMMEDIATELY DISPLAY DETAILED RESULTS\n",
    "            self.display_detailed_results(\n",
    "                unique_tasks, task_origins, dependencies, skill_map, \n",
    "                time.time() - start_time, api_calls, total_tasks_before_consolidation, \n",
    "                errors, context_analysis\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"tasks\": unique_tasks,\n",
    "                \"task_origins\": task_origins,\n",
    "                \"dependencies\": dependencies,\n",
    "                \"required_skills\": skill_map,\n",
    "                \"api_calls\": api_calls,\n",
    "                \"execution_time\": time.time() - start_time,\n",
    "                \"errors\": errors,\n",
    "                \"context_analysis\": context_analysis\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"üí• CRITICAL FAILURE: {str(e)}\")\n",
    "            print(f\"üîç DEBUG: Full error details: {repr(e)}\")\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def display_detailed_results(self, unique_tasks, task_origins, dependencies, skill_map, execution_time, api_calls, total_tasks, errors, context_analysis):\n",
    "        \"\"\"Display comprehensive detailed results immediately\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"‚ö° PARTY C: REVOLUTIONARIES - COMPLETE DETAILED RESULTS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # SUMMARY METRICS\n",
    "        print(f\"\\nüìä REVOLUTIONARY PERFORMANCE SUMMARY:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"‚è±Ô∏è  Execution Time: {execution_time:.2f} seconds\")\n",
    "        print(f\"üîå API Calls: {api_calls} (ULTRA-EFFICIENT!)\")\n",
    "        print(f\"üìã Total Tasks Generated: {total_tasks}\")\n",
    "        print(f\"üéØ Unique Tasks After Consolidation: {len(unique_tasks)}\")\n",
    "        print(f\"üîÑ Duplicate Reduction: {((total_tasks - len(unique_tasks)) / total_tasks * 100) if total_tasks > 0 else 0:.1f}%\")\n",
    "        print(f\"üîó Dependencies Found: {sum(len(deps) for deps in dependencies.values())}\")\n",
    "        print(f\"üõ†Ô∏è  Skills Identified: {sum(len(skills) for skills in skill_map.values())}\")\n",
    "        print(f\"‚ö° EFFICIENCY SCORE: {len(unique_tasks) / api_calls:.2f} tasks per API call üöÄ\")\n",
    "        \n",
    "        # Context analysis results\n",
    "        print(f\"\\nüîç CONTEXT WINDOW ANALYSIS:\")\n",
    "        print(f\"   Stories processed: {context_analysis['total_stories']}\")\n",
    "        print(f\"   Estimated tokens used: {context_analysis['estimated_tokens']}\")\n",
    "        print(f\"   Risk level: {context_analysis['risk_level']}\")\n",
    "        print(f\"   Within safe limits: {'‚úÖ YES' if context_analysis['within_limits'] else '‚ö†Ô∏è  NO'}\")\n",
    "        \n",
    "        if errors:\n",
    "            print(f\"\\n‚ö†Ô∏è  Errors Encountered: {len(errors)}\")\n",
    "            for error in errors[:3]:\n",
    "                print(f\"   ‚Ä¢ {error}\")\n",
    "            if len(errors) > 3:\n",
    "                print(f\"   ... and {len(errors) - 3} more errors\")\n",
    "        \n",
    "        # DETAILED TASKS\n",
    "        print(f\"\\nüìã ALL {len(unique_tasks)} MEGA-BATCH PROCESSED TASKS:\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, task in enumerate(unique_tasks, 1):\n",
    "            print(f\"{i:2d}. {task}\")\n",
    "            \n",
    "            # Show which story(ies) generated this task\n",
    "            origins = task_origins.get(task, [])\n",
    "            if origins:\n",
    "                if len(origins) == 1:\n",
    "                    print(f\"    ‚îî‚îÄ From: {origins[0][:60]}...\")\n",
    "                else:\n",
    "                    print(f\"    ‚îî‚îÄ From {len(origins)} stories (MEGA-BATCH CONSOLIDATION):\")\n",
    "                    for origin in origins:\n",
    "                        print(f\"       ‚Ä¢ {origin[:55]}...\")\n",
    "            print()\n",
    "        \n",
    "        # DEPENDENCIES\n",
    "        print(f\"\\nüîó TASK DEPENDENCIES:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        tasks_with_deps = {task: deps for task, deps in dependencies.items() if deps}\n",
    "        \n",
    "        if tasks_with_deps:\n",
    "            print(f\"Found {len(tasks_with_deps)} tasks with dependencies:\\n\")\n",
    "            \n",
    "            for i, (task, deps) in enumerate(tasks_with_deps.items(), 1):\n",
    "                print(f\"{i}. üìã TASK: {task}\")\n",
    "                print(f\"   ‚¨áÔ∏è  DEPENDS ON:\")\n",
    "                for j, dep in enumerate(deps, 1):\n",
    "                    print(f\"      {j}. {dep}\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è  No dependencies detected between tasks\")\n",
    "        \n",
    "        # SKILLS MAPPING\n",
    "        print(f\"\\nüéØ SKILLS REQUIRED FOR EACH TASK:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        skills_shown = 0\n",
    "        for i, (task, skills) in enumerate(skill_map.items(), 1):\n",
    "            if skills and skills_shown < 10:  # Limit display to first 10 for brevity\n",
    "                print(f\"{i:2d}. üìã {task}\")\n",
    "                print(f\"     üõ†Ô∏è  Skills: {', '.join(skills)}\")\n",
    "                print()\n",
    "                skills_shown += 1\n",
    "        \n",
    "        if len(skill_map) > skills_shown:\n",
    "            print(f\"   ... and skills for {len(skill_map) - skills_shown} more tasks\")\n",
    "        \n",
    "        # REVOLUTIONARY VERDICT\n",
    "        efficiency_score = len(unique_tasks) / api_calls\n",
    "        print(f\"\\nüéØ REVOLUTIONARY VERDICT:\")\n",
    "        if efficiency_score > 2.0:\n",
    "            print(\"   üèÜ REVOLUTIONARY SUCCESS! Ultra-high efficiency achieved!\")\n",
    "        elif efficiency_score > 1.0:\n",
    "            print(\"   üìä SOLID REVOLUTIONARY PERFORMANCE! Good efficiency, acceptable risk\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  EFFICIENCY CONCERNS - Consider optimizing or using grouped approach\")\n",
    "        \n",
    "        print(f\"\\nüí• RISK vs REWARD SUMMARY:\")\n",
    "        print(f\"   ‚úÖ REWARDS: Minimal API calls ({api_calls}), Maximum speed, Lowest cost\")\n",
    "        print(f\"   ‚ö†Ô∏è  RISKS: Single point of failure, Context limits, Harder debugging\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FIXED JUPYTER-COMPATIBLE FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "async def run_fixed_batch_all_with_full_details():\n",
    "    \"\"\"Run the FIXED batch all processor with enhanced debugging\"\"\"\n",
    "    \n",
    "    print(\"‚ö° PARTY C: FIXED BATCH ALL PROCESSING WITH FULL DETAILS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Philosophy: 'All or nothing - maximum efficiency'\")\n",
    "    print(\"Enhanced with robust parsing and debugging\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Use sample stories\n",
    "    user_stories = SAMPLE_USER_STORIES\n",
    "    print(f\"Processing {len(user_stories)} sample user stories in ONE MEGA-BATCH...\")\n",
    "    \n",
    "    # Create processor and run with detailed display\n",
    "    processor = FixedBatchAllProcessor()\n",
    "    result = await processor.process_stories_with_details(user_stories)\n",
    "    \n",
    "    return result\n",
    "\n",
    "result = await run_fixed_batch_all_with_full_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a121200-0cd3-45e8-9433-fa05e6f70429",
   "metadata": {},
   "source": [
    "**Batch All Processing Performance Analysis**\n",
    "- Processing Time\n",
    "> **Performance:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Fastest)\n",
    "- Characteristics :\n",
    "  \n",
    "> Single mega-batch processing\n",
    "\n",
    "> Maximum parallelization within LLM\n",
    "\n",
    "> Minimal API round-trips\n",
    "\n",
    "> Processing time: `O(1)` for decomposition step\n",
    "- Expected Range\n",
    "> **5-10 seconds for 10 stories**\n",
    "- Bottlenecks\n",
    "> **Single decomposition call + analysis**\n",
    "---\n",
    "- üî§ Token Usage\n",
    "> **Efficiency:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Most Efficient)\n",
    "- Formula\n",
    "> **Context + Examples + All_Stories + Dependencies + Skills**\n",
    "- Estimated Tokens\n",
    "> **~200-300 per story + analysis overhead**\n",
    "---\n",
    "- API Costs\n",
    "> **Cost Rating:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Cheapest)\n",
    "- Cost Structure\n",
    "> **Minimum API calls: 1 (decomposition) + 1 (dependencies) + Unique_Tasks (skills)**\n",
    "- Typical Example\n",
    "> **10 stories = 1 + 1 + 25 = 27 API calls**\n",
    "- Cost Factors\n",
    "  \n",
    "> ~40-50% cost reduction vs. Individual\n",
    "\n",
    "> Maximum cost optimization\n",
    "\n",
    "> Revolutionary efficiency approach\n",
    "---\n",
    "- Dependency Detection Accuracy\n",
    "> **Accuracy:** ‚≠ê‚≠ê‚≠ê (Variable)\n",
    "- Challenges\n",
    "  \n",
    "> Context dilution with large batches\n",
    "\n",
    "> Potential task detail reduction\n",
    "\n",
    "> LLM attention distribution across many stories\n",
    "\n",
    "> Risk of missing subtle dependencies\n",
    "- Mitigation\n",
    "> **Works best with <15 stories**\n",
    "---\n",
    "- Error Recovery Capability\n",
    "> **Resilience:** ‚≠ê‚≠ê (Risky)\n",
    "- Vulnerabilities\n",
    "  \n",
    "> **Single Point of Failure:** One failed call affects entire batch\n",
    "\n",
    "> **All-or-Nothing:** No partial processing capability\n",
    "\n",
    "> **Difficult Debugging:** Hard to isolate specific story issues\n",
    "\n",
    "> **Context Limits:** May hit token limits with large batches\n",
    "- Failure Scenarios\n",
    "> **Batch failure rate ~10-20% for large sets**\n",
    "---\n",
    "- üìä Summary\n",
    "- Best Performance Aspects\n",
    "  \n",
    "> **‚úÖ MAXIMUM efficiency - fewest API calls possible**\n",
    "\n",
    "> **‚úÖ FASTEST processing - single decomposition step**\n",
    "\n",
    "> **‚úÖ LOWEST cost - minimal API usage**\n",
    "\n",
    "> **‚úÖ ELEGANT simplicity - clean approach**\n",
    "- Trade-offs\n",
    "  \n",
    "> **‚ö†Ô∏è High-risk, high-reward approach**\n",
    "\n",
    "> **‚ö†Ô∏è Single point of failure**\n",
    "\n",
    "> **‚ö†Ô∏è Context window limitations**\n",
    "\n",
    "> **‚ö†Ô∏è Harder to debug issues**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2317ac0-ce9d-4cb3-a858-d78e3543f996",
   "metadata": {},
   "source": [
    "## 3. Treatment Architecture & Implementation\n",
    "\n",
    "### 3.1 Architecture Decision: Multi-Agent vs Single Agent\n",
    "\n",
    "#### 3.1.1 Single Agent Approach\n",
    "> **One Agent handles all steps: decomposition, dependency analysis, and skill mapping**\n",
    "\n",
    "- **Advantages:**\n",
    "  - Simpler implementation\n",
    "  - No coordination overhead\n",
    "  - Single point of control\n",
    "\n",
    "- **Disadvantages:**\n",
    "  - Limited specialization\n",
    "  - Potential context overload\n",
    "  - Reduced modularity\n",
    "\n",
    "\n",
    "#### 3.1.2 Multi-Agent System \n",
    "> **A collaborative system of specialized LLM-based agents, each optimized for a distinct responsibility**\n",
    "\n",
    "- **Advantages:**\n",
    "  - **Modularity:** Each agent specializes in one task\n",
    "  - **Parallelism:** Agents can work simultaneously \n",
    "  - **Token Optimization:** Focused context per agent\n",
    "  - **Scalability:** Easy to add/modify individual agents\n",
    "    \n",
    "---\n",
    "#### 3.1.3 **Decision Rationale:**\n",
    "> **We chose the multi-agent system for modularity, parallelism and token optimization**\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 Multi-Agent Workflow Architecture\n",
    "\n",
    "### 3.2.1 Agent Composition\n",
    "\n",
    "- **Task Decomposer Agent**\n",
    "  \n",
    "> **Input:** User stories\n",
    "  \n",
    "> **utput:** Raw tasks\n",
    "  \n",
    "> **Responsibility:** Break down user stories into actionable tasks\n",
    "\n",
    "- **Task Consolidator Agent**\n",
    "\n",
    "> **Input:** Raw tasks\n",
    "\n",
    "> **Output:** Refined tasks\n",
    " \n",
    "> **Responsibility:** Remove duplicates and merge similar tasks\n",
    "\n",
    "- **Skill Mapper Agent**\n",
    "\n",
    "> **Input:** Refined tasks\n",
    " \n",
    "> **Output:** Required skills\n",
    " \n",
    "> **Responsibility:** Identify technical skills needed for each task\n",
    "\n",
    "- **Dependency Analyzer Agent**\n",
    "\n",
    "> **Input:** Refined tasks\n",
    "  \n",
    "> **Output:** Dependencies\n",
    "\n",
    "> **Responsibility:** Determine task dependencies and execution order\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2.2 Workflow Process\n",
    "\n",
    "- **Data Flow**\n",
    "```\n",
    "user stories ‚Üí Task Decomposer Agent ‚Üí raw tasks\n",
    "                                          ‚Üì\n",
    "                                   Task Consolidator Agent ‚Üí refined tasks\n",
    "                                          ‚Üì                        ‚Üì\n",
    "                                   Skill Mapper Agent        Dependency Analyzer Agent\n",
    "                                          ‚Üì                        ‚Üì\n",
    "                                   required skills            dependencies\n",
    "                                          ‚Üì                        ‚Üì\n",
    "                                              OUTPUT\n",
    "```\n",
    "\n",
    "1. **Input Processing:** User stories fed to Task Decomposer Agent\n",
    "2. **Task Generation:** Raw tasks created from user stories\n",
    "3. **Task Refinement:** Consolidator Agent removes duplicates\n",
    "4. **Parallel Analysis:** \n",
    "   - Skill Mapper identifies required skills\n",
    "   - Dependency Analyzer determines task relationships\n",
    "5. **Output Synthesis:** All results combined into final output\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a61963a-a99f-4bae-a7ba-02b7104a8ade",
   "metadata": {},
   "source": [
    "### 3.3 Model Selection & Deployment Strategy\n",
    "\n",
    "#### 3.3.1 Local Models\n",
    "> **Run on-premises but resource heavy**\n",
    "\n",
    "- **Advantages:**\n",
    "  - Full data control and privacy\n",
    "  - No API rate limits\n",
    "  - One-time setup cost\n",
    "  - Offline capability\n",
    "\n",
    "- **Disadvantages:**\n",
    "  - High computational requirements\n",
    "  - Significant hardware investment\n",
    "  - Model maintenance overhead\n",
    "  - Limited to available local resources\n",
    "\n",
    "#### 3.3.2 API-Based Models  \n",
    "> **Served by third-party providers but the free plan is constrained**\n",
    "\n",
    "- **Advantages:**\n",
    "  - No infrastructure setup required\n",
    "  - Access to state-of-the-art models\n",
    "  - Automatic updates and maintenance\n",
    "  - Scalable on-demand\n",
    "\n",
    "- **Disadvantages:**\n",
    "  - API rate limits on free tiers\n",
    "  - Data privacy considerations\n",
    "  - Ongoing API costs\n",
    "  - Internet dependency\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "> **We chose Llama3-70B on Groq for both performance and prompt length advantages**\n",
    "\n",
    "> **Why Llama3-70B?**\n",
    "\n",
    "- **High Performance:** 70B parameters provide excellent reasoning\n",
    "- **Long Context Window:** Supports complex multi-story processing\n",
    "- **Open Source:** Flexible deployment options\n",
    "- **Proven Track Record:** Well-tested for text generation tasks\n",
    "\n",
    "> **Alternative options**\n",
    "- **Local deployment** for data-sensitive applications\n",
    "- **Other API providers** for comparison and redundancy\n",
    "- **Model fine-tuning** for domain-specific improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66e4876-dcb3-4859-9b9a-64f8b0f42348",
   "metadata": {},
   "source": [
    "### configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b197091-5e45-4fc2-a28e-3d950deb27ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.3,\n",
    "    max_tokens=4000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b117bf31-311a-4df9-8fa6-3e88faba105c",
   "metadata": {},
   "source": [
    "### Model Parameters\n",
    "- **Model:** llama3-70b-8192\n",
    "- **Temperature:** 0.3 (balanced creativity/consistency)\n",
    "- **Max Tokens:** 4000 (supports large responses)\n",
    "- **Context Window:** 8192 tokens (sufficient for multi-story processing)\n",
    "- **Rate limit:** 30 reauest per minute "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027dbfe-c396-4de4-a0a7-2b93860930b3",
   "metadata": {},
   "source": [
    "### 3.4 Prompt Engineering Strategies\n",
    "\n",
    "#### 3.4.1 Strategy 1: Zero-Shot Prompting\n",
    "\n",
    "- **Definition**\n",
    "> **Asking the model to perform a task without providing any examples or prior context, relying entirely on the model's pre-trained knowledge**\n",
    "\n",
    "- **Core Approach**\n",
    "\n",
    "> **Direct task instruction** without examples\n",
    "\n",
    "> **Relies on model's inherent capabilities**\n",
    "\n",
    ">  **Minimal context and guidance**\n",
    "\n",
    "> **Straightforward task description**\n",
    "\n",
    "- ‚úÖ **Advantages**\n",
    "\n",
    "> Shortest possible prompts reduce API costs and token usage\n",
    "\n",
    "> Good for straightforward, well-defined tasks\n",
    "\n",
    "> Fast execution\n",
    "\n",
    "\n",
    "- ‚ùå **Disadvantages**\n",
    "\n",
    "> Less control over output format and structure\n",
    "\n",
    "> May produce inconsistent results across runs\n",
    "\n",
    "> Output format may vary without examples\n",
    "\n",
    "> Complex tasks may be misunderstood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0031b96e-a369-4394-8391-5f8854972351",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18352967-abee-4464-a992-2cc051de649b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ ZERO-SHOT PROMPTING STRATEGY DEMO\n",
      "============================================================\n",
      "Testing zero-shot prompting with sample user stories...\n",
      "\n",
      "üéØ Using ZERO-SHOT prompting strategy\n",
      "==================================================\n",
      "Strategy: Direct instructions without examples\n",
      "Benefits: Minimal tokens, simple implementation\n",
      "Trade-offs: Less control over output format\n",
      "\n",
      "üîÑ Processing story 1/12\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 88, Output: 153, Total: 241\n",
      "   Generated 8 tasks\n",
      "üîÑ Processing story 2/12\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 92, Output: 200, Total: 292\n",
      "   Generated 14 tasks\n",
      "üîÑ Processing story 3/12\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 84, Output: 273, Total: 357\n",
      "   Generated 16 tasks\n",
      "üîÑ Processing story 4/12\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 89, Output: 263, Total: 352\n",
      "   Generated 14 tasks\n",
      "üîÑ Processing story 5/12\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 86, Output: 235, Total: 321\n",
      "   Generated 13 tasks\n",
      "üîÑ Processing story 6/12\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 86, Output: 187, Total: 273\n",
      "   Generated 10 tasks\n",
      "üîÑ Processing story 7/12\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 84, Output: 321, Total: 405\n",
      "   Generated 13 tasks\n",
      "üîÑ Processing story 8/12\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 86, Output: 217, Total: 303\n",
      "   Generated 11 tasks\n",
      "üîÑ Processing story 9/12\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 86, Output: 241, Total: 327\n",
      "   Generated 12 tasks\n",
      "üîÑ Processing story 10/12\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 85, Output: 173, Total: 258\n",
      "   Generated 10 tasks\n",
      "üîÑ Processing story 11/12\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 87, Output: 274, Total: 361\n",
      "   Generated 12 tasks\n",
      "üîÑ Processing story 12/12\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 84, Output: 220, Total: 304\n",
      "   Generated 11 tasks\n",
      "\n",
      "üîÑ Consolidating tasks...\n",
      "üîÑ Analyzing dependencies and mapping skills...\n",
      "[DEPENDENCY_ANALYSIS] Tokens - Input: 2829, Output: 3067, Total: 5896\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 28, Total: 102\n",
      "[SKILL_MAPPING] Tokens - Input: 81, Output: 30, Total: 111\n",
      "[SKILL_MAPPING] Tokens - Input: 73, Output: 33, Total: 106\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 42, Total: 121\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 27, Total: 102\n",
      "[SKILL_MAPPING] Tokens - Input: 72, Output: 13, Total: 85\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 25, Total: 104\n",
      "[SKILL_MAPPING] Tokens - Input: 84, Output: 38, Total: 122\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 127, Total: 201\n",
      "[SKILL_MAPPING] Tokens - Input: 69, Output: 60, Total: 129\n",
      "[SKILL_MAPPING] Tokens - Input: 71, Output: 72, Total: 143\n",
      "[SKILL_MAPPING] Tokens - Input: 73, Output: 70, Total: 143\n",
      "[SKILL_MAPPING] Tokens - Input: 70, Output: 71, Total: 141\n",
      "[SKILL_MAPPING] Tokens - Input: 73, Output: 75, Total: 148\n",
      "[SKILL_MAPPING] Tokens - Input: 72, Output: 107, Total: 179\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 60, Total: 135\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 53, Total: 127\n",
      "[SKILL_MAPPING] Tokens - Input: 71, Output: 100, Total: 171\n",
      "[SKILL_MAPPING] Tokens - Input: 73, Output: 92, Total: 165\n",
      "[SKILL_MAPPING] Tokens - Input: 73, Output: 61, Total: 134\n",
      "[SKILL_MAPPING] Tokens - Input: 70, Output: 87, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 116, Total: 190\n",
      "[SKILL_MAPPING] Tokens - Input: 77, Output: 110, Total: 187\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 60, Total: 139\n",
      "[SKILL_MAPPING] Tokens - Input: 72, Output: 106, Total: 178\n",
      "[SKILL_MAPPING] Tokens - Input: 78, Output: 43, Total: 121\n",
      "[SKILL_MAPPING] Tokens - Input: 71, Output: 80, Total: 151\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 43, Total: 118\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 97, Total: 176\n",
      "[SKILL_MAPPING] Tokens - Input: 76, Output: 94, Total: 170\n",
      "[SKILL_MAPPING] Tokens - Input: 71, Output: 49, Total: 120\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 86, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 76, Output: 102, Total: 178\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 81, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 107, Total: 181\n",
      "[SKILL_MAPPING] Tokens - Input: 71, Output: 60, Total: 131\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 87, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 77, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 54, Total: 129\n",
      "[SKILL_MAPPING] Tokens - Input: 77, Output: 43, Total: 120\n",
      "[SKILL_MAPPING] Tokens - Input: 76, Output: 128, Total: 204\n",
      "[SKILL_MAPPING] Tokens - Input: 77, Output: 54, Total: 131\n",
      "[SKILL_MAPPING] Tokens - Input: 81, Output: 99, Total: 180\n",
      "[SKILL_MAPPING] Tokens - Input: 76, Output: 66, Total: 142\n",
      "[SKILL_MAPPING] Tokens - Input: 78, Output: 65, Total: 143\n",
      "[SKILL_MAPPING] Tokens - Input: 78, Output: 97, Total: 175\n",
      "[SKILL_MAPPING] Tokens - Input: 77, Output: 94, Total: 171\n",
      "[SKILL_MAPPING] Tokens - Input: 70, Output: 93, Total: 163\n",
      "[SKILL_MAPPING] Tokens - Input: 80, Output: 103, Total: 183\n",
      "[SKILL_MAPPING] Tokens - Input: 76, Output: 116, Total: 192\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 94, Total: 169\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 111, Total: 190\n",
      "[SKILL_MAPPING] Tokens - Input: 82, Output: 93, Total: 175\n",
      "[SKILL_MAPPING] Tokens - Input: 80, Output: 92, Total: 172\n",
      "[SKILL_MAPPING] Tokens - Input: 76, Output: 109, Total: 185\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 56, Total: 130\n",
      "[SKILL_MAPPING] Tokens - Input: 77, Output: 89, Total: 166\n",
      "[SKILL_MAPPING] Tokens - Input: 84, Output: 82, Total: 166\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 84, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 72, Output: 96, Total: 168\n",
      "[SKILL_MAPPING] Tokens - Input: 72, Output: 78, Total: 150\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 74, Total: 149\n",
      "[SKILL_MAPPING] Tokens - Input: 71, Output: 75, Total: 146\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 83, Total: 162\n",
      "[SKILL_MAPPING] Tokens - Input: 73, Output: 93, Total: 166\n",
      "[SKILL_MAPPING] Tokens - Input: 70, Output: 54, Total: 124\n",
      "[SKILL_MAPPING] Tokens - Input: 73, Output: 120, Total: 193\n",
      "[SKILL_MAPPING] Tokens - Input: 76, Output: 83, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 72, Total: 146\n",
      "[SKILL_MAPPING] Tokens - Input: 77, Output: 141, Total: 218\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 96, Total: 171\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 117, Total: 196\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 129, Total: 208\n",
      "[SKILL_MAPPING] Tokens - Input: 81, Output: 91, Total: 172\n",
      "[SKILL_MAPPING] Tokens - Input: 83, Output: 85, Total: 168\n",
      "[SKILL_MAPPING] Tokens - Input: 84, Output: 45, Total: 129\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 62, Total: 141\n",
      "[SKILL_MAPPING] Tokens - Input: 80, Output: 98, Total: 178\n",
      "[SKILL_MAPPING] Tokens - Input: 72, Output: 111, Total: 183\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 135, Total: 214\n",
      "[SKILL_MAPPING] Tokens - Input: 86, Output: 92, Total: 178\n",
      "[SKILL_MAPPING] Tokens - Input: 81, Output: 39, Total: 120\n",
      "[SKILL_MAPPING] Tokens - Input: 93, Output: 84, Total: 177\n",
      "[SKILL_MAPPING] Tokens - Input: 87, Output: 83, Total: 170\n",
      "[SKILL_MAPPING] Tokens - Input: 91, Output: 105, Total: 196\n",
      "[SKILL_MAPPING] Tokens - Input: 88, Output: 107, Total: 195\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 93, Total: 168\n",
      "[SKILL_MAPPING] Tokens - Input: 91, Output: 80, Total: 171\n",
      "[SKILL_MAPPING] Tokens - Input: 77, Output: 31, Total: 108\n",
      "[SKILL_MAPPING] Tokens - Input: 73, Output: 40, Total: 113\n",
      "[SKILL_MAPPING] Tokens - Input: 73, Output: 82, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 78, Output: 60, Total: 138\n",
      "[SKILL_MAPPING] Tokens - Input: 83, Output: 57, Total: 140\n",
      "[SKILL_MAPPING] Tokens - Input: 77, Output: 78, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 72, Total: 146\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 75, Total: 150\n",
      "[SKILL_MAPPING] Tokens - Input: 77, Output: 76, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 72, Output: 47, Total: 119\n",
      "[SKILL_MAPPING] Tokens - Input: 86, Output: 46, Total: 132\n",
      "[SKILL_MAPPING] Tokens - Input: 77, Output: 69, Total: 146\n",
      "[SKILL_MAPPING] Tokens - Input: 77, Output: 106, Total: 183\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 90, Total: 169\n",
      "[SKILL_MAPPING] Tokens - Input: 78, Output: 62, Total: 140\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 76, Total: 151\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 75, Total: 150\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 111, Total: 185\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 113, Total: 187\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 86, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 77, Output: 73, Total: 150\n",
      "[SKILL_MAPPING] Tokens - Input: 72, Output: 62, Total: 134\n",
      "[SKILL_MAPPING] Tokens - Input: 72, Output: 47, Total: 119\n",
      "[SKILL_MAPPING] Tokens - Input: 73, Output: 89, Total: 162\n",
      "[SKILL_MAPPING] Tokens - Input: 77, Output: 107, Total: 184\n",
      "[SKILL_MAPPING] Tokens - Input: 86, Output: 65, Total: 151\n",
      "[SKILL_MAPPING] Tokens - Input: 72, Output: 150, Total: 222\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 76, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 70, Output: 73, Total: 143\n",
      "[SKILL_MAPPING] Tokens - Input: 71, Output: 78, Total: 149\n",
      "[SKILL_MAPPING] Tokens - Input: 81, Output: 64, Total: 145\n",
      "[SKILL_MAPPING] Tokens - Input: 84, Output: 49, Total: 133\n",
      "[SKILL_MAPPING] Tokens - Input: 83, Output: 145, Total: 228\n",
      "[SKILL_MAPPING] Tokens - Input: 82, Output: 69, Total: 151\n",
      "[SKILL_MAPPING] Tokens - Input: 83, Output: 103, Total: 186\n",
      "[SKILL_MAPPING] Tokens - Input: 76, Output: 33, Total: 109\n",
      "[SKILL_MAPPING] Tokens - Input: 81, Output: 99, Total: 180\n",
      "[SKILL_MAPPING] Tokens - Input: 80, Output: 52, Total: 132\n",
      "[SKILL_MAPPING] Tokens - Input: 80, Output: 71, Total: 151\n",
      "[SKILL_MAPPING] Tokens - Input: 80, Output: 67, Total: 147\n",
      "[SKILL_MAPPING] Tokens - Input: 79, Output: 99, Total: 178\n",
      "[SKILL_MAPPING] Tokens - Input: 82, Output: 63, Total: 145\n",
      "[SKILL_MAPPING] Tokens - Input: 80, Output: 87, Total: 167\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 133, Total: 208\n",
      "[SKILL_MAPPING] Tokens - Input: 81, Output: 78, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 78, Output: 53, Total: 131\n",
      "[SKILL_MAPPING] Tokens - Input: 76, Output: 31, Total: 107\n",
      "[SKILL_MAPPING] Tokens - Input: 73, Output: 90, Total: 163\n",
      "[SKILL_MAPPING] Tokens - Input: 75, Output: 60, Total: 135\n",
      "[SKILL_MAPPING] Tokens - Input: 82, Output: 70, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 76, Output: 98, Total: 174\n",
      "[SKILL_MAPPING] Tokens - Input: 74, Output: 109, Total: 183\n",
      "[SKILL_MAPPING] Tokens - Input: 82, Output: 86, Total: 168\n",
      "[SKILL_MAPPING] Tokens - Input: 86, Output: 90, Total: 176\n",
      "\n",
      "‚úÖ Zero-shot processing complete!\n",
      "üìä Total tokens used: 31907\n",
      "\n",
      "================================================================================\n",
      "üéØ ZERO-SHOT PROMPTING RESULTS\n",
      "================================================================================\n",
      "Strategy: Zero-Shot Prompting\n",
      "\n",
      "üìä TOKEN EFFICIENCY ANALYSIS:\n",
      "----------------------------------------\n",
      "Total Tokens: 31907\n",
      "Task Decomposition: 3794 tokens (1037‚Üí2757)\n",
      "Dependency Analysis: 5896 tokens (2829‚Üí3067)\n",
      "Skill Mapping: 22217 tokens (10934‚Üí11283)\n",
      "Estimated Cost: $0.490140\n",
      "\n",
      "üìã PROCESSING SUMMARY:\n",
      "----------------------------------------\n",
      "Stories Processed: 12\n",
      "Tasks Generated: 142\n",
      "Dependencies Found: 133\n",
      "Skills Identified: 1345\n",
      "\n",
      "üéØ GENERATED TASKS (First 5):\n",
      "----------------------------------------\n",
      "1. Add an HTML anchor element to the address element in the UI component.\n",
      "   From: 1 story(ies)\n",
      "2. Set the target attribute of the anchor element to \"_blank\" to open the link in a new tab.\n",
      "   From: 1 story(ies)\n",
      "3. Create a function to generate a Google Maps URL from the address.\n",
      "   From: 1 story(ies)\n",
      "4. Implement the function to generate a Google Maps URL using the Google Maps API or a URL template.\n",
      "   From: 1 story(ies)\n",
      "5. Set the href attribute of the anchor element to the generated Google Maps URL.\n",
      "   From: 1 story(ies)\n",
      "   ... and 137 more tasks\n",
      "\n",
      "üîç ZERO-SHOT STRATEGY ANALYSIS:\n",
      "----------------------------------------\n",
      "‚úÖ Advantages Demonstrated:\n",
      "   ‚Ä¢ Minimal token usage per prompt\n",
      "   ‚Ä¢ Simple, direct implementation\n",
      "   ‚Ä¢ Fast execution without examples\n",
      "   ‚Ä¢ Leveraged model's pre-trained knowledge\n",
      "\n",
      "‚ö†Ô∏è  Challenges Observed:\n",
      "   ‚Ä¢ Output format variations\n",
      "   ‚Ä¢ Parsing complexity required\n",
      "   ‚Ä¢ Less predictable structure\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from typing import Any, Dict, List, Set, Tuple\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Handle tiktoken import gracefully\n",
    "try:\n",
    "    import tiktoken\n",
    "    TIKTOKEN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  tiktoken not available, using fallback token counting\")\n",
    "    TIKTOKEN_AVAILABLE = False\n",
    "\n",
    "load_dotenv()\n",
    "client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "\n",
    "class TokenTracker:\n",
    "    \"\"\"Enhanced token tracking with detailed analytics\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        if TIKTOKEN_AVAILABLE:\n",
    "            try:\n",
    "                self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "            except:\n",
    "                self.tokenizer = None\n",
    "        else:\n",
    "            self.tokenizer = None\n",
    "        \n",
    "        self.token_usage = {\n",
    "            'task_decomposition': {'input': 0, 'output': 0, 'total': 0},\n",
    "            'dependency_analysis': {'input': 0, 'output': 0, 'total': 0},\n",
    "            'skill_mapping': {'input': 0, 'output': 0, 'total': 0},\n",
    "            'total_consumed': 0\n",
    "        }\n",
    "    \n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        \"\"\"Count tokens in text using tiktoken or fallback method\"\"\"\n",
    "        if self.tokenizer:\n",
    "            return len(self.tokenizer.encode(text))\n",
    "        else:\n",
    "            # Rough approximation: 1 token ‚âà 4 characters for most text\n",
    "            return len(text) // 4\n",
    "    \n",
    "    def track_api_call(self, category: str, input_text: str, output_text: str):\n",
    "        \"\"\"Track token usage for an API call\"\"\"\n",
    "        input_tokens = self.count_tokens(input_text)\n",
    "        output_tokens = self.count_tokens(output_text)\n",
    "        total_tokens = input_tokens + output_tokens\n",
    "        \n",
    "        self.token_usage[category]['input'] += input_tokens\n",
    "        self.token_usage[category]['output'] += output_tokens\n",
    "        self.token_usage[category]['total'] += total_tokens\n",
    "        self.token_usage['total_consumed'] += total_tokens\n",
    "        \n",
    "        print(f\"[{category.upper()}] Tokens - Input: {input_tokens}, Output: {output_tokens}, Total: {total_tokens}\")\n",
    "    \n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive token usage summary\"\"\"\n",
    "        return {\n",
    "            'breakdown': self.token_usage,\n",
    "            'cost_estimate': self.estimate_cost(),\n",
    "            'efficiency_metrics': self.calculate_efficiency()\n",
    "        }\n",
    "    \n",
    "    def estimate_cost(self) -> Dict[str, float]:\n",
    "        \"\"\"Estimate costs based on Groq pricing (approximate)\"\"\"\n",
    "        # Groq pricing is typically very low, these are example rates\n",
    "        input_rate = 0.00001  # per token\n",
    "        output_rate = 0.00002  # per token\n",
    "        \n",
    "        total_input = sum(cat['input'] for cat in self.token_usage.values() if isinstance(cat, dict))\n",
    "        total_output = sum(cat['output'] for cat in self.token_usage.values() if isinstance(cat, dict))\n",
    "        \n",
    "        input_cost = total_input * input_rate\n",
    "        output_cost = total_output * output_rate\n",
    "        \n",
    "        return {\n",
    "            'input_cost': input_cost,\n",
    "            'output_cost': output_cost,\n",
    "            'total_cost': input_cost + output_cost,\n",
    "            'cost_per_category': {\n",
    "                cat: {\n",
    "                    'input_cost': data['input'] * input_rate,\n",
    "                    'output_cost': data['output'] * output_rate,\n",
    "                    'total_cost': data['input'] * input_rate + data['output'] * output_rate\n",
    "                }\n",
    "                for cat, data in self.token_usage.items() \n",
    "                if isinstance(data, dict) and cat != 'total_consumed'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def calculate_efficiency(self) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate efficiency metrics\"\"\"\n",
    "        total_tokens = self.token_usage['total_consumed']\n",
    "        if total_tokens == 0:\n",
    "            return {'efficiency': 'No data'}\n",
    "        \n",
    "        categories = ['task_decomposition', 'dependency_analysis', 'skill_mapping']\n",
    "        \n",
    "        return {\n",
    "            'tokens_per_category': {\n",
    "                cat: self.token_usage[cat]['total'] \n",
    "                for cat in categories\n",
    "            },\n",
    "            'percentage_breakdown': {\n",
    "                cat: (self.token_usage[cat]['total'] / total_tokens) * 100 \n",
    "                for cat in categories\n",
    "            },\n",
    "            'input_output_ratio': {\n",
    "                cat: {\n",
    "                    'input_pct': (self.token_usage[cat]['input'] / self.token_usage[cat]['total']) * 100 if self.token_usage[cat]['total'] > 0 else 0,\n",
    "                    'output_pct': (self.token_usage[cat]['output'] / self.token_usage[cat]['total']) * 100 if self.token_usage[cat]['total'] > 0 else 0\n",
    "                }\n",
    "                for cat in categories\n",
    "            }\n",
    "        }\n",
    "\n",
    "class ZeroShotTaskDecomposer:\n",
    "    \"\"\"\n",
    "    Zero-Shot Task Decomposition Agent\n",
    "    \n",
    "    Demonstrates zero-shot prompting strategy:\n",
    "    - No examples provided\n",
    "    - Relies on model's pre-trained knowledge\n",
    "    - Clear, direct instructions\n",
    "    - Minimal token usage\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.strategy = \"Zero-Shot\"\n",
    "        \n",
    "    async def decompose(self, user_story: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Zero-shot prompt: Direct task description without examples\n",
    "        \"\"\"\n",
    "        # Zero-shot prompt: Clear instructions, no examples\n",
    "        prompt = f\"\"\"\n",
    "Break down the following user story into specific, actionable technical tasks. Each task should be:\n",
    "- A single, focused responsibility\n",
    "- Technically implementable\n",
    "- Clear and unambiguous\n",
    "- Ordered logically where possible\n",
    "\n",
    "Return only a numbered list of tasks without any headers, explanations, or additional text.\n",
    "\n",
    "User Story: {user_story}\n",
    "\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"llama3-70b-8192\",\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        # Track token usage\n",
    "        output_text = response.choices[0].message.content.strip()\n",
    "        token_tracker.track_api_call('task_decomposition', prompt, output_text)\n",
    "        \n",
    "        # Parse and clean the response\n",
    "        tasks = self._parse_tasks(output_text)\n",
    "        return tasks\n",
    "    \n",
    "    def _parse_tasks(self, content: str) -> List[str]:\n",
    "        \"\"\"Extract clean task list from LLM response\"\"\"\n",
    "        lines = content.split('\\n')\n",
    "        tasks = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Skip headers, explanatory text, and formatting\n",
    "            if any(skip_phrase in line.lower() for skip_phrase in [\n",
    "                'user story:', 'tasks:', 'here are', 'the following', \n",
    "                'broken down', 'specific', 'technical', '**', 'note:'\n",
    "            ]):\n",
    "                continue\n",
    "            \n",
    "            # Extract task from numbered list\n",
    "            clean_task = re.sub(r'^[\\d\\-\\*\\.\\)\\s]+', '', line)\n",
    "            clean_task = re.sub(r'^\\*\\*|\\*\\*$', '', clean_task)  # Remove bold markdown\n",
    "            clean_task = clean_task.strip()\n",
    "            \n",
    "            # Only add non-empty, substantial tasks\n",
    "            if clean_task and len(clean_task) > 10:\n",
    "                tasks.append(clean_task)\n",
    "        \n",
    "        return tasks\n",
    "\n",
    "class ZeroShotDependencyAnalyzer:\n",
    "    \"\"\"\n",
    "    Zero-Shot Dependency Analysis Agent\n",
    "    \n",
    "    Uses zero-shot prompting for dependency detection:\n",
    "    - Direct analysis instructions\n",
    "    - No dependency examples\n",
    "    - Clear output format specification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.strategy = \"Zero-Shot\"\n",
    "        \n",
    "    async def analyze(self, tasks: List[str]) -> Dict[str, List[Dict[str, str]]]:\n",
    "        if len(tasks) <= 1:\n",
    "            return {}\n",
    "            \n",
    "        tasks_str = \"\\n\".join([f\"{i+1}. {task}\" for i, task in enumerate(tasks)])\n",
    "        \n",
    "        # Zero-shot prompt: Direct dependency analysis without examples\n",
    "        prompt = f\"\"\"\n",
    "Analyze the dependencies between these tasks. Identify which tasks must be completed before others can begin.\n",
    "\n",
    "For each dependency relationship you identify, assess:\n",
    "1. Coupling degree: \"tight\" (major interdependence), \"moderate\" (some interdependence), or \"loose\" (minimal interdependence)\n",
    "2. Rework effort: estimate story points (1-13) needed if the prerequisite task changes or fails\n",
    "\n",
    "Return only actual dependencies in this exact format:\n",
    "- Task X depends on Task Y (coupling: DEGREE, rework_effort: POINTS)\n",
    "\n",
    "Only include dependencies that truly exist. Do not create artificial dependencies.\n",
    "\n",
    "Tasks:\n",
    "{tasks_str}\n",
    "\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"llama3-70b-8192\",\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # Track token usage\n",
    "        output_text = response.choices[0].message.content.strip()\n",
    "        token_tracker.track_api_call('dependency_analysis', prompt, output_text)\n",
    "        \n",
    "        dependencies = self._parse_dependencies(output_text, tasks)\n",
    "        return dependencies\n",
    "    \n",
    "    def _parse_dependencies(self, text: str, tasks: List[str]) -> Dict[str, List[Dict[str, str]]]:\n",
    "        \"\"\"Parse dependency relationships from zero-shot output\"\"\"\n",
    "        dependencies = {}\n",
    "        lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "        \n",
    "        for line in lines:\n",
    "            if \"depends on\" in line.lower():\n",
    "                try:\n",
    "                    # Extract task numbers, coupling, and rework effort\n",
    "                    clean_line = line.lower().replace('task', '').replace('-', '').strip()\n",
    "                    parts = clean_line.split(\"depends on\")\n",
    "                    \n",
    "                    if len(parts) == 2:\n",
    "                        dependent_num = parts[0].strip().split()[0]\n",
    "                        dependency_part = parts[1].strip()\n",
    "                        \n",
    "                        # Extract dependency number\n",
    "                        dependency_words = dependency_part.split()\n",
    "                        dependency_num = dependency_words[0] if dependency_words else \"\"\n",
    "                        \n",
    "                        # Extract coupling and rework effort from parentheses\n",
    "                        paren_start = dependency_part.find('(')\n",
    "                        paren_end = dependency_part.rfind(')')\n",
    "                        if paren_start != -1 and paren_end != -1:\n",
    "                            details = dependency_part[paren_start+1:paren_end]\n",
    "                            \n",
    "                            # Parse coupling and rework_effort\n",
    "                            coupling = \"moderate\"  # default\n",
    "                            rework_effort = \"3\"    # default\n",
    "                            \n",
    "                            if \"coupling:\" in details:\n",
    "                                coupling_match = re.search(r'coupling:\\s*(\\w+)', details)\n",
    "                                if coupling_match:\n",
    "                                    coupling = coupling_match.group(1)\n",
    "                            \n",
    "                            if \"rework_effort:\" in details:\n",
    "                                effort_match = re.search(r'rework_effort:\\s*(\\d+)', details)\n",
    "                                if effort_match:\n",
    "                                    rework_effort = effort_match.group(1)\n",
    "                        else:\n",
    "                            coupling = \"moderate\"\n",
    "                            rework_effort = \"3\"\n",
    "                        \n",
    "                        if dependent_num.isdigit() and dependency_num.isdigit():\n",
    "                            dependent_idx = int(dependent_num) - 1\n",
    "                            dependency_idx = int(dependency_num) - 1\n",
    "                            \n",
    "                            if 0 <= dependent_idx < len(tasks) and 0 <= dependency_idx < len(tasks):\n",
    "                                dependent_task = tasks[dependent_idx]\n",
    "                                dependency_task = tasks[dependency_idx]\n",
    "                                \n",
    "                                if dependent_task not in dependencies:\n",
    "                                    dependencies[dependent_task] = []\n",
    "                                \n",
    "                                dependencies[dependent_task].append({\n",
    "                                    \"task\": dependency_task,\n",
    "                                    \"coupling\": coupling,\n",
    "                                    \"rework_effort\": rework_effort\n",
    "                                })\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Couldn't parse dependency line: {line} - {str(e)}\")\n",
    "                    continue\n",
    "                    \n",
    "        return dependencies\n",
    "\n",
    "class ZeroShotSkillMapper:\n",
    "    \"\"\"\n",
    "    Zero-Shot Skill Mapping Agent\n",
    "    \n",
    "    Implements zero-shot prompting for skill identification:\n",
    "    - Direct skill identification instructions\n",
    "    - No skill examples provided\n",
    "    - Minimal context requirements\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.strategy = \"Zero-Shot\"\n",
    "        \n",
    "    async def map_skills(self, task: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Zero-shot prompt: Direct skill identification without examples\n",
    "        \"\"\"\n",
    "        # Zero-shot prompt: Clear skill identification without examples\n",
    "        prompt = f\"\"\"\n",
    "Identify the specific technical skills required to complete this task.\n",
    "\n",
    "Consider:\n",
    "- Programming languages needed\n",
    "- Frameworks or libraries required\n",
    "- Technical domains (frontend, backend, database, etc.)\n",
    "- Specialized knowledge areas\n",
    "\n",
    "Return only a bulleted list of skills without explanations or headers.\n",
    "\n",
    "Task: {task}\n",
    "\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"llama3-70b-8192\",\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        # Track token usage\n",
    "        output_text = response.choices[0].message.content.strip()\n",
    "        token_tracker.track_api_call('skill_mapping', prompt, output_text)\n",
    "        \n",
    "        skills = self._parse_skills(output_text)\n",
    "        return skills\n",
    "    \n",
    "    def _parse_skills(self, content: str) -> List[str]:\n",
    "        \"\"\"Extract clean skills list from zero-shot response\"\"\"\n",
    "        lines = content.split('\\n')\n",
    "        skills = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Skip headers and explanatory text\n",
    "            if any(skip_phrase in line.lower() for skip_phrase in [\n",
    "                'required skills:', 'task:', 'here are', 'the following', 'skills needed'\n",
    "            ]):\n",
    "                continue\n",
    "            \n",
    "            # Clean skill from bullet points\n",
    "            clean_skill = re.sub(r'^[\\-\\*\\s]+', '', line)\n",
    "            clean_skill = clean_skill.strip()\n",
    "            \n",
    "            if clean_skill and len(clean_skill) > 2:\n",
    "                skills.append(clean_skill)\n",
    "        \n",
    "        return skills\n",
    "\n",
    "class TaskConsolidatorAgent:\n",
    "    \"\"\"Task consolidation logic (unchanged from original)\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def consolidate_tasks(self, user_stories_tasks: Dict[str, List[str]]) -> Tuple[List[str], Dict[str, List[str]]]:\n",
    "        \"\"\"Consolidate tasks from multiple user stories\"\"\"\n",
    "        unique_tasks = []\n",
    "        task_origins = {}\n",
    "        seen_tasks = set()\n",
    "        \n",
    "        for user_story, tasks in user_stories_tasks.items():\n",
    "            for task in tasks:\n",
    "                task_lower = task.lower().strip()\n",
    "                is_duplicate = False\n",
    "                \n",
    "                for existing_task in seen_tasks:\n",
    "                    if self._are_similar_tasks(task_lower, existing_task.lower()):\n",
    "                        is_duplicate = True\n",
    "                        for unique_task in unique_tasks:\n",
    "                            if unique_task.lower() == existing_task.lower():\n",
    "                                if unique_task not in task_origins:\n",
    "                                    task_origins[unique_task] = []\n",
    "                                if user_story not in task_origins[unique_task]:\n",
    "                                    task_origins[unique_task].append(user_story)\n",
    "                                break\n",
    "                        break\n",
    "                \n",
    "                if not is_duplicate:\n",
    "                    unique_tasks.append(task)\n",
    "                    seen_tasks.add(task_lower)\n",
    "                    task_origins[task] = [user_story]\n",
    "        \n",
    "        return unique_tasks, task_origins\n",
    "    \n",
    "    def _are_similar_tasks(self, task1: str, task2: str) -> bool:\n",
    "        \"\"\"Simple similarity check for tasks\"\"\"\n",
    "        common_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n",
    "        \n",
    "        words1 = set(task1.split()) - common_words\n",
    "        words2 = set(task2.split()) - common_words\n",
    "        \n",
    "        if len(words1) == 0 or len(words2) == 0:\n",
    "            return False\n",
    "            \n",
    "        intersection = words1.intersection(words2)\n",
    "        union = words1.union(words2)\n",
    "        \n",
    "        similarity = len(intersection) / len(union) if union else 0\n",
    "        return similarity > 0.7\n",
    "\n",
    "# Global token tracker instance\n",
    "token_tracker = TokenTracker()\n",
    "\n",
    "async def _map_all_skills(mapper: ZeroShotSkillMapper, tasks: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"Map skills for all tasks concurrently\"\"\"\n",
    "    skill_tasks = await asyncio.gather(*[mapper.map_skills(task) for task in tasks])\n",
    "    return {task: skills for task, skills in zip(tasks, skill_tasks)}\n",
    "\n",
    "async def process_user_stories_zero_shot(user_stories: List[str]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Main processing function using Zero-Shot prompting strategy\n",
    "    \n",
    "    This demonstrates the zero-shot approach across all agents:\n",
    "    - No examples in prompts\n",
    "    - Direct task instructions\n",
    "    - Minimal token usage\n",
    "    - Reliance on model's pre-trained knowledge\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Reset token tracker for new session\n",
    "        global token_tracker\n",
    "        token_tracker = TokenTracker()\n",
    "        \n",
    "        print(\"üéØ Using ZERO-SHOT prompting strategy\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"Strategy: Direct instructions without examples\")\n",
    "        print(\"Benefits: Minimal tokens, simple implementation\")\n",
    "        print(\"Trade-offs: Less control over output format\")\n",
    "        print(\"\")\n",
    "        \n",
    "        # Step 1: Decompose each user story into tasks (Zero-Shot)\n",
    "        decomposer = ZeroShotTaskDecomposer()\n",
    "        user_stories_tasks = {}\n",
    "        \n",
    "        for i, user_story in enumerate(user_stories, 1):\n",
    "            print(f\"üîÑ Processing story {i}/{len(user_stories)}\")\n",
    "            tasks = await decomposer.decompose(user_story)\n",
    "            if tasks:\n",
    "                user_stories_tasks[user_story] = tasks\n",
    "                print(f\"   Generated {len(tasks)} tasks\")\n",
    "        \n",
    "        if not user_stories_tasks:\n",
    "            raise ValueError(\"No tasks were generated from any user story\")\n",
    "        \n",
    "        # Step 2: Consolidate tasks and eliminate duplicates\n",
    "        print(f\"\\nüîÑ Consolidating tasks...\")\n",
    "        consolidator = TaskConsolidatorAgent()\n",
    "        unique_tasks, task_origins = consolidator.consolidate_tasks(user_stories_tasks)\n",
    "        \n",
    "        # Step 3: Analyze dependencies and map skills (Zero-Shot)\n",
    "        print(f\"üîÑ Analyzing dependencies and mapping skills...\")\n",
    "        dep_analyzer = ZeroShotDependencyAnalyzer()\n",
    "        skill_mapper = ZeroShotSkillMapper()\n",
    "            \n",
    "        dependencies, skill_map = await asyncio.gather(\n",
    "            dep_analyzer.analyze(unique_tasks),\n",
    "            _map_all_skills(skill_mapper, unique_tasks)\n",
    "        )\n",
    "        \n",
    "        # Get token usage summary\n",
    "        token_summary = token_tracker.get_summary()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Zero-shot processing complete!\")\n",
    "        print(f\"üìä Total tokens used: {token_summary['breakdown']['total_consumed']}\")\n",
    "        \n",
    "        return {\n",
    "            \"strategy\": \"Zero-Shot Prompting\",\n",
    "            \"user_stories\": user_stories,\n",
    "            \"tasks\": unique_tasks,\n",
    "            \"task_origins\": task_origins,\n",
    "            \"dependencies\": dependencies,\n",
    "            \"required_skills\": skill_map,\n",
    "            \"token_usage\": token_summary\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing user stories: {str(e)}\")\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"strategy\": \"Zero-Shot Prompting\",\n",
    "            \"user_stories\": user_stories,\n",
    "            \"token_usage\": token_tracker.get_summary() if 'token_tracker' in globals() else None\n",
    "        }\n",
    "\n",
    "def display_zero_shot_results(result: Dict[str, Any]):\n",
    "    \"\"\"Enhanced display function for zero-shot results\"\"\"\n",
    "    \n",
    "    if \"error\" in result:\n",
    "        print(f\"‚ùå Error: {result['error']}\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üéØ ZERO-SHOT PROMPTING RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Strategy: {result['strategy']}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Token Usage Summary\n",
    "    if \"token_usage\" in result and result[\"token_usage\"]:\n",
    "        token_data = result[\"token_usage\"]\n",
    "        breakdown = token_data.get(\"breakdown\", {})\n",
    "        \n",
    "        print(\"üìä TOKEN EFFICIENCY ANALYSIS:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Total Tokens: {breakdown.get('total_consumed', 0)}\")\n",
    "        \n",
    "        categories = ['task_decomposition', 'dependency_analysis', 'skill_mapping']\n",
    "        for cat in categories:\n",
    "            if cat in breakdown:\n",
    "                data = breakdown[cat]\n",
    "                cat_name = cat.replace('_', ' ').title()\n",
    "                print(f\"{cat_name}: {data['total']} tokens ({data['input']}‚Üí{data['output']})\")\n",
    "        \n",
    "        if \"cost_estimate\" in token_data:\n",
    "            cost_data = token_data[\"cost_estimate\"]\n",
    "            print(f\"Estimated Cost: ${cost_data['total_cost']:.6f}\")\n",
    "        print(\"\")\n",
    "    \n",
    "    # Results Summary\n",
    "    print(\"üìã PROCESSING SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Stories Processed: {len(result['user_stories'])}\")\n",
    "    print(f\"Tasks Generated: {len(result['tasks'])}\")\n",
    "    print(f\"Dependencies Found: {sum(len(deps) for deps in result['dependencies'].values())}\")\n",
    "    print(f\"Skills Identified: {sum(len(skills) for skills in result['required_skills'].values())}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Tasks (first 5 for brevity)\n",
    "    print(\"üéØ GENERATED TASKS (First 5):\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, task in enumerate(result[\"tasks\"][:5], 1):\n",
    "        origins = result[\"task_origins\"].get(task, [])\n",
    "        print(f\"{i}. {task}\")\n",
    "        print(f\"   From: {len(origins)} story(ies)\")\n",
    "    \n",
    "    if len(result[\"tasks\"]) > 5:\n",
    "        print(f\"   ... and {len(result['tasks']) - 5} more tasks\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Zero-Shot Analysis\n",
    "    print(\"üîç ZERO-SHOT STRATEGY ANALYSIS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"‚úÖ Advantages Demonstrated:\")\n",
    "    print(\"   ‚Ä¢ Minimal token usage per prompt\")\n",
    "    print(\"   ‚Ä¢ Simple, direct implementation\")\n",
    "    print(\"   ‚Ä¢ Fast execution without examples\")\n",
    "    print(\"   ‚Ä¢ Leveraged model's pre-trained knowledge\")\n",
    "    print(\"\")\n",
    "    print(\"‚ö†Ô∏è  Challenges Observed:\")\n",
    "    print(\"   ‚Ä¢ Output format variations\")\n",
    "    print(\"   ‚Ä¢ Parsing complexity required\")\n",
    "    print(\"   ‚Ä¢ Less predictable structure\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "async def run_zero_shot_demo():\n",
    "    \"\"\"\n",
    "    Demo function to run zero-shot prompting strategy\n",
    "    \n",
    "    This function demonstrates the zero-shot approach with:\n",
    "    - Sample user stories\n",
    "    - Token tracking\n",
    "    - Performance analysis\n",
    "    - Strategy comparison insights\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üéØ ZERO-SHOT PROMPTING STRATEGY DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Testing zero-shot prompting with sample user stories...\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Use sample stories for demonstration\n",
    "    user_stories = SAMPLE_USER_STORIES\n",
    "    \n",
    "    # Process using zero-shot strategy\n",
    "    result = await process_user_stories_zero_shot(user_stories)\n",
    "    \n",
    "    # Display comprehensive results\n",
    "    display_zero_shot_results(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "result = await run_zero_shot_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b4746b-d2b8-4973-87fb-9aa51ebf95d8",
   "metadata": {},
   "source": [
    "#### 3.4.2 Strategy 2: Few-Shot Prompting\n",
    "\n",
    "- **Definition**\n",
    "> **Providing 2-5 examples of desired input-output pairs before asking the AI to perform the task on new data**\n",
    "\n",
    "- **Core Approach**\n",
    "\n",
    "> **Demonstration-based learning** through examples\n",
    "\n",
    "> **Pattern recognition** from provided samples\n",
    "\n",
    "> **Structured guidance** for consistent output\n",
    "\n",
    "> **Balance between efficiency and control**\n",
    "\n",
    "- ‚úÖ **Advantages**\n",
    "\n",
    "> **Examples demonstrate exact output structure and style**\n",
    "\n",
    "> **Moderate token usage with significant performance **\n",
    "\n",
    "> **Examples guide the model toward predictable outputs**\n",
    "\n",
    "> **Demonstrations clarify complex or ambiguous requirements**\n",
    "\n",
    "- ‚ùå **Disadvantages**\n",
    "\n",
    "> **Can be biased toward the specific examples provided**\n",
    "\n",
    "> **May not generalize well to very different user story types**\n",
    "\n",
    "> **More tokens required than zero-shot approach**\n",
    "\n",
    "> **Quality depends on careful example curation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e6ba3-6fa5-4bb6-bfed-99242b91f614",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f8810b2-50fd-4f34-9349-d1803f9097b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ FEW-SHOT PROMPTING STRATEGY DEMO\n",
      "============================================================\n",
      "Testing few-shot prompting with curated examples...\n",
      "\n",
      "üéØ Using FEW-SHOT prompting strategy\n",
      "==================================================\n",
      "Strategy: 2-5 examples demonstrate desired patterns\n",
      "Benefits: Better consistency, format control\n",
      "Trade-offs: Higher token usage, example dependency\n",
      "\n",
      "üîÑ Processing story 1/12 with examples...\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 270, Output: 25, Total: 295\n",
      "   Generated 1 tasks (guided by examples)\n",
      "üîÑ Processing story 2/12 with examples...\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 274, Output: 81, Total: 355\n",
      "   Generated 9 tasks (guided by examples)\n",
      "üîÑ Processing story 3/12 with examples...\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 266, Output: 107, Total: 373\n",
      "   Generated 12 tasks (guided by examples)\n",
      "üîÑ Processing story 4/12 with examples...\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 271, Output: 89, Total: 360\n",
      "   Generated 9 tasks (guided by examples)\n",
      "üîÑ Processing story 5/12 with examples...\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 268, Output: 121, Total: 389\n",
      "   Generated 12 tasks (guided by examples)\n",
      "üîÑ Processing story 6/12 with examples...\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 268, Output: 84, Total: 352\n",
      "   Generated 9 tasks (guided by examples)\n",
      "üîÑ Processing story 7/12 with examples...\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 266, Output: 111, Total: 377\n",
      "   Generated 12 tasks (guided by examples)\n",
      "üîÑ Processing story 8/12 with examples...\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 268, Output: 87, Total: 355\n",
      "   Generated 8 tasks (guided by examples)\n",
      "üîÑ Processing story 9/12 with examples...\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 268, Output: 91, Total: 359\n",
      "   Generated 9 tasks (guided by examples)\n",
      "üîÑ Processing story 10/12 with examples...\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 267, Output: 91, Total: 358\n",
      "   Generated 8 tasks (guided by examples)\n",
      "üîÑ Processing story 11/12 with examples...\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 269, Output: 92, Total: 361\n",
      "   Generated 10 tasks (guided by examples)\n",
      "üîÑ Processing story 12/12 with examples...\n",
      "[TASK_DECOMPOSITION] Tokens - Input: 266, Output: 109, Total: 375\n",
      "   Generated 9 tasks (guided by examples)\n",
      "\n",
      "üîÑ Consolidating tasks...\n",
      "üîÑ Analyzing dependencies and mapping skills with examples...\n",
      "[DEPENDENCY_ANALYSIS] Tokens - Input: 1453, Output: 1871, Total: 3324\n",
      "[SKILL_MAPPING] Tokens - Input: 164, Output: 24, Total: 188\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 10, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 143, Output: 10, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 16, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 10, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 12, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 23, Total: 172\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 16, Total: 165\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 10, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 7, Total: 151\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 11, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 13, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 11, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 8, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 12, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 12, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 11, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 10, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 17, Total: 165\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 21, Total: 171\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 10, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 10, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 13, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 7, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 7, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 11, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 11, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 10, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 11, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 12, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 7, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 10, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 13, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 10, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 10, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 13, Total: 163\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 7, Total: 151\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 11, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 11, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 18, Total: 164\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 21, Total: 167\n",
      "[SKILL_MAPPING] Tokens - Input: 151, Output: 12, Total: 163\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 12, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 10, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 10, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 11, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 153, Output: 7, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 11, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 12, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 16, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 8, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 10, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 13, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 13, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 12, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 7, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 17, Total: 167\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 17, Total: 164\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 10, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 12, Total: 162\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 10, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 11, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 11, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 10, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 11, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 11, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 7, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 13, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 152, Output: 13, Total: 165\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 7, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 10, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 151, Output: 13, Total: 164\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 11, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 11, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 144, Output: 10, Total: 154\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 10, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 12, Total: 158\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 13, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 145, Output: 7, Total: 152\n",
      "[SKILL_MAPPING] Tokens - Input: 146, Output: 7, Total: 153\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 13, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 12, Total: 159\n",
      "[SKILL_MAPPING] Tokens - Input: 147, Output: 8, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 19, Total: 167\n",
      "[SKILL_MAPPING] Tokens - Input: 152, Output: 16, Total: 168\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 6, Total: 155\n",
      "[SKILL_MAPPING] Tokens - Input: 151, Output: 13, Total: 164\n",
      "[SKILL_MAPPING] Tokens - Input: 150, Output: 7, Total: 157\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 13, Total: 161\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 12, Total: 160\n",
      "[SKILL_MAPPING] Tokens - Input: 149, Output: 7, Total: 156\n",
      "[SKILL_MAPPING] Tokens - Input: 148, Output: 8, Total: 156\n",
      "\n",
      "‚úÖ Few-shot processing complete!\n",
      "üìä Total tokens used: 24580\n",
      "\n",
      "================================================================================\n",
      "üéØ FEW-SHOT PROMPTING RESULTS\n",
      "================================================================================\n",
      "Strategy: Few-Shot Prompting\n",
      "\n",
      "üìä TOKEN EFFICIENCY ANALYSIS:\n",
      "----------------------------------------\n",
      "Total Tokens: 24580\n",
      "Task Decomposition: 4309 tokens (3221‚Üí1088)\n",
      "Dependency Analysis: 3324 tokens (1453‚Üí1871)\n",
      "Skill Mapping: 16947 tokens (15753‚Üí1194)\n",
      "Estimated Cost: $0.287330\n",
      "\n",
      "üìã PROCESSING SUMMARY:\n",
      "----------------------------------------\n",
      "Stories Processed: 12\n",
      "Tasks Generated: 107\n",
      "Dependencies Found: 81\n",
      "Skills Identified: 306\n",
      "\n",
      "üéØ GENERATED TASKS (First 5):\n",
      "----------------------------------------\n",
      "1. Please provide the user story you'd like me to break down into tasks. I'll respond with the numbered list of tasks.\n",
      "   From: 1 story(ies)\n",
      "2. Create anonymous user session handling\n",
      "   From: 1 story(ies)\n",
      "3. Design public landing page layout\n",
      "   From: 1 story(ies)\n",
      "4. Design facility component\n",
      "   From: 2 story(ies)\n",
      "5. Design facility list display component\n",
      "   From: 1 story(ies)\n",
      "   ... and 102 more tasks\n",
      "\n",
      "üîó DEPENDENCY EXAMPLES:\n",
      "----------------------------------------\n",
      "‚Ä¢ Create anonymous user session handling...\n",
      "  ‚îî‚îÄ Depends on: Implement facility search without authen...\n",
      "  ‚îî‚îÄ Coupling: TIGHT, Rework: 8 points\n",
      "\n",
      "‚Ä¢ Implement facility search without authen...\n",
      "  ‚îî‚îÄ Depends on: Design facility list display component...\n",
      "  ‚îî‚îÄ Coupling: TIGHT, Rework: 5 points\n",
      "\n",
      "‚Ä¢ Display basic facility information publi...\n",
      "  ‚îî‚îÄ Depends on: Implement facility search without authen...\n",
      "  ‚îî‚îÄ Coupling: MODERATE, Rework: 3 points\n",
      "\n",
      "   ... and 78 more dependencies\n",
      "\n",
      "üîç FEW-SHOT STRATEGY ANALYSIS:\n",
      "----------------------------------------\n",
      "‚úÖ Advantages Demonstrated:\n",
      "   ‚Ä¢ Consistent output formatting\n",
      "   ‚Ä¢ Pattern-guided task generation\n",
      "   ‚Ä¢ Structured dependency analysis\n",
      "   ‚Ä¢ Predictable skill categorization\n",
      "\n",
      "üìä Example Impact:\n",
      "   ‚Ä¢ Task format standardization\n",
      "   ‚Ä¢ Coupling assessment consistency\n",
      "   ‚Ä¢ Skill domain separation\n",
      "   ‚Ä¢ Reduced parsing complexity\n",
      "\n",
      "‚ö†Ô∏è  Considerations:\n",
      "   ‚Ä¢ Higher token usage than zero-shot\n",
      "   ‚Ä¢ Example selection affects quality\n",
      "   ‚Ä¢ Potential bias toward provided examples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from typing import Any, Dict, List, Set, Tuple\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Handle tiktoken import gracefully\n",
    "try:\n",
    "    import tiktoken\n",
    "    TIKTOKEN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  tiktoken not available, using fallback token counting\")\n",
    "    TIKTOKEN_AVAILABLE = False\n",
    "\n",
    "load_dotenv()\n",
    "client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "\n",
    "class TokenTracker:\n",
    "    \"\"\"Enhanced token tracking with detailed analytics\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        if TIKTOKEN_AVAILABLE:\n",
    "            try:\n",
    "                self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "            except:\n",
    "                self.tokenizer = None\n",
    "        else:\n",
    "            self.tokenizer = None\n",
    "        \n",
    "        self.token_usage = {\n",
    "            'task_decomposition': {'input': 0, 'output': 0, 'total': 0},\n",
    "            'dependency_analysis': {'input': 0, 'output': 0, 'total': 0},\n",
    "            'skill_mapping': {'input': 0, 'output': 0, 'total': 0},\n",
    "            'total_consumed': 0\n",
    "        }\n",
    "    \n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        \"\"\"Count tokens in text using tiktoken or fallback method\"\"\"\n",
    "        if self.tokenizer:\n",
    "            return len(self.tokenizer.encode(text))\n",
    "        else:\n",
    "            # Rough approximation: 1 token ‚âà 4 characters for most text\n",
    "            return len(text) // 4\n",
    "    \n",
    "    def track_api_call(self, category: str, input_text: str, output_text: str):\n",
    "        \"\"\"Track token usage for an API call\"\"\"\n",
    "        input_tokens = self.count_tokens(input_text)\n",
    "        output_tokens = self.count_tokens(output_text)\n",
    "        total_tokens = input_tokens + output_tokens\n",
    "        \n",
    "        self.token_usage[category]['input'] += input_tokens\n",
    "        self.token_usage[category]['output'] += output_tokens\n",
    "        self.token_usage[category]['total'] += total_tokens\n",
    "        self.token_usage['total_consumed'] += total_tokens\n",
    "        \n",
    "        print(f\"[{category.upper()}] Tokens - Input: {input_tokens}, Output: {output_tokens}, Total: {total_tokens}\")\n",
    "    \n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive token usage summary\"\"\"\n",
    "        return {\n",
    "            'breakdown': self.token_usage,\n",
    "            'cost_estimate': self.estimate_cost(),\n",
    "            'efficiency_metrics': self.calculate_efficiency()\n",
    "        }\n",
    "    \n",
    "    def estimate_cost(self) -> Dict[str, float]:\n",
    "        \"\"\"Estimate costs based on Groq pricing (approximate)\"\"\"\n",
    "        input_rate = 0.00001  # per token\n",
    "        output_rate = 0.00002  # per token\n",
    "        \n",
    "        total_input = sum(cat['input'] for cat in self.token_usage.values() if isinstance(cat, dict))\n",
    "        total_output = sum(cat['output'] for cat in self.token_usage.values() if isinstance(cat, dict))\n",
    "        \n",
    "        input_cost = total_input * input_rate\n",
    "        output_cost = total_output * output_rate\n",
    "        \n",
    "        return {\n",
    "            'input_cost': input_cost,\n",
    "            'output_cost': output_cost,\n",
    "            'total_cost': input_cost + output_cost\n",
    "        }\n",
    "    \n",
    "    def calculate_efficiency(self) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate efficiency metrics\"\"\"\n",
    "        total_tokens = self.token_usage['total_consumed']\n",
    "        if total_tokens == 0:\n",
    "            return {'efficiency': 'No data'}\n",
    "        \n",
    "        categories = ['task_decomposition', 'dependency_analysis', 'skill_mapping']\n",
    "        \n",
    "        return {\n",
    "            'percentage_breakdown': {\n",
    "                cat: (self.token_usage[cat]['total'] / total_tokens) * 100 \n",
    "                for cat in categories\n",
    "            }\n",
    "        }\n",
    "\n",
    "class FewShotTaskDecomposer:\n",
    "    \"\"\"\n",
    "    Few-Shot Task Decomposition Agent\n",
    "    \n",
    "    Demonstrates few-shot prompting strategy:\n",
    "    - Provides 2-5 examples of desired input-output pairs\n",
    "    - Establishes clear format and detail level\n",
    "    - Guides model toward consistent outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.strategy = \"Few-Shot\"\n",
    "        # Carefully curated examples covering different story types\n",
    "        self.few_shot_examples = \"\"\"\n",
    "User Story: As a user, I want to click on the address so that it takes me to a new tab with Google Maps.\n",
    "Tasks:\n",
    "1. Make address text clickable\n",
    "2. Implement click handler to format address for Google Maps URL\n",
    "3. Open Google Maps in new tab/window\n",
    "4. Add proper URL encoding for address parameters\n",
    "\n",
    "User Story: As a user, I want to be able to anonymously view public information so that I know about recycling centers near me before creating an account.\n",
    "Tasks:\n",
    "1. Design public landing page layout\n",
    "2. Create anonymous user session handling\n",
    "3. Implement facility search without authentication\n",
    "4. Display basic facility information publicly \n",
    "5. Design facility component\n",
    "6. Detect user's location via browser API or IP\n",
    "7. Show recycling centers within a radius of the user\n",
    "8. Design facility list display component\n",
    "9. Add \"Sign up for more features\" prompt\n",
    "\"\"\"\n",
    "        \n",
    "    async def decompose(self, user_story: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Few-shot prompt: Demonstrates format with examples before new task\n",
    "        \"\"\"\n",
    "        # Few-shot prompt: Examples + clear instructions + new input\n",
    "        prompt = f\"\"\"\n",
    "You are a task decomposition expert. Break down the following user story into specific, actionable technical tasks.\n",
    "Each task should be simple and focused on a single responsibility.\n",
    "\n",
    "IMPORTANT: Return ONLY the numbered list of tasks. Do NOT include explanatory text, headers, or additional commentary.\n",
    "\n",
    "Examples:\n",
    "{self.few_shot_examples}\n",
    "\n",
    "User Story: {user_story}\n",
    "Tasks:\n",
    "\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"llama3-70b-8192\",\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        # Track token usage\n",
    "        output_text = response.choices[0].message.content.strip()\n",
    "        token_tracker.track_api_call('task_decomposition', prompt, output_text)\n",
    "        \n",
    "        # Parse and clean the response\n",
    "        tasks = self._parse_tasks(output_text)\n",
    "        return tasks\n",
    "    \n",
    "    def _parse_tasks(self, content: str) -> List[str]:\n",
    "        \"\"\"Extract clean task list from LLM response\"\"\"\n",
    "        lines = content.split('\\n')\n",
    "        tasks = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Skip headers, explanatory text, and formatting\n",
    "            if any(skip_phrase in line.lower() for skip_phrase in [\n",
    "                'user story:', 'tasks:', 'here are', 'the following', \n",
    "                'broken down', 'specific', 'technical', '**', 'note:'\n",
    "            ]):\n",
    "                continue\n",
    "            \n",
    "            # Extract task from numbered list\n",
    "            clean_task = re.sub(r'^[\\d\\-\\*\\.\\)\\s]+', '', line)\n",
    "            clean_task = re.sub(r'^\\*\\*|\\*\\*$', '', clean_task)  # Remove bold markdown\n",
    "            clean_task = clean_task.strip()\n",
    "            \n",
    "            # Only add non-empty, substantial tasks\n",
    "            if clean_task and len(clean_task) > 10:\n",
    "                tasks.append(clean_task)\n",
    "        \n",
    "        return tasks\n",
    "\n",
    "class FewShotDependencyAnalyzer:\n",
    "    \"\"\"\n",
    "    Few-Shot Dependency Analysis Agent\n",
    "    \n",
    "    Uses few-shot prompting for dependency detection:\n",
    "    - Provides examples of different coupling types\n",
    "    - Demonstrates dependency analysis format\n",
    "    - Shows rework effort estimation patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.strategy = \"Few-Shot\"\n",
    "        # Examples showing different dependency types and coupling levels\n",
    "        self.few_shot_examples = \"\"\"\n",
    "Tasks:\n",
    "1. Make address text clickable\n",
    "2. Implement click handler for Google Maps URL\n",
    "3. Open Google Maps in new tab/window\n",
    "4. Add URL encoding for address parameters\n",
    "5. Design facility component\n",
    "6. Create anonymous user session handling\n",
    "7. Implement facility search without authentication\n",
    "\n",
    "Dependencies:\n",
    "- Task 1 depends on Task 5 (coupling: tight, rework_effort: 3)\n",
    "- Task 2 depends on Task 1 (coupling: tight, rework_effort: 5)\n",
    "- Task 3 depends on Task 2 (coupling: moderate, rework_effort: 2)\n",
    "- Task 4 depends on Task 2 (coupling: loose, rework_effort: 1)\n",
    "- Task 7 depends on Task 6 (coupling: tight, rework_effort: 8)\n",
    "\"\"\"\n",
    "        \n",
    "    async def analyze(self, tasks: List[str]) -> Dict[str, List[Dict[str, str]]]:\n",
    "        if len(tasks) <= 1:\n",
    "            return {}\n",
    "            \n",
    "        tasks_str = \"\\n\".join([f\"{i+1}. {task}\" for i, task in enumerate(tasks)])\n",
    "        \n",
    "        # Few-shot prompt: Examples showing dependency format and analysis\n",
    "        prompt = f\"\"\"\n",
    "Analyze dependencies between these tasks. Identify which tasks must be completed before others can start.\n",
    "For each dependency, also assess:\n",
    "1. Coupling degree: tight (high interdependence), moderate (some interdependence), loose (minimal interdependence)\n",
    "2. Rework effort: story points (1-13) needed if the prerequisite task fails\n",
    "\n",
    "Return ONLY dependencies that exist, using the exact format: \"- Task X depends on Task Y (coupling: DEGREE, rework_effort: POINTS)\"\n",
    "\n",
    "IMPORTANT: \n",
    "- Only return actual dependencies, not every possible combination\n",
    "- Coupling: tight = major rework needed, moderate = some rework, loose = minimal rework\n",
    "- Rework effort: 1-3 (low), 5-8 (medium), 13 (high)\n",
    "- Return ONLY the dependency list, no headers or explanations\n",
    "\n",
    "Example:\n",
    "{self.few_shot_examples}\n",
    "\n",
    "Tasks:\n",
    "{tasks_str}\n",
    "\n",
    "Dependencies:\n",
    "\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"llama3-70b-8192\",\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        # Track token usage\n",
    "        output_text = response.choices[0].message.content.strip()\n",
    "        token_tracker.track_api_call('dependency_analysis', prompt, output_text)\n",
    "        \n",
    "        dependencies = self._parse_dependencies(output_text, tasks)\n",
    "        return dependencies\n",
    "    \n",
    "    def _parse_dependencies(self, text: str, tasks: List[str]) -> Dict[str, List[Dict[str, str]]]:\n",
    "        \"\"\"Parse dependency relationships from few-shot output\"\"\"\n",
    "        dependencies = {}\n",
    "        lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "        \n",
    "        for line in lines:\n",
    "            if \"depends on\" in line.lower():\n",
    "                try:\n",
    "                    # Extract task numbers, coupling, and rework effort\n",
    "                    clean_line = line.lower().replace('task', '').replace('-', '').strip()\n",
    "                    parts = clean_line.split(\"depends on\")\n",
    "                    \n",
    "                    if len(parts) == 2:\n",
    "                        dependent_num = parts[0].strip().split()[0]\n",
    "                        dependency_part = parts[1].strip()\n",
    "                        \n",
    "                        # Extract dependency number\n",
    "                        dependency_words = dependency_part.split()\n",
    "                        dependency_num = dependency_words[0] if dependency_words else \"\"\n",
    "                        \n",
    "                        # Extract coupling and rework effort from parentheses\n",
    "                        paren_start = dependency_part.find('(')\n",
    "                        paren_end = dependency_part.rfind(')')\n",
    "                        if paren_start != -1 and paren_end != -1:\n",
    "                            details = dependency_part[paren_start+1:paren_end]\n",
    "                            \n",
    "                            # Parse coupling and rework_effort\n",
    "                            coupling = \"moderate\"  # default\n",
    "                            rework_effort = \"3\"    # default\n",
    "                            \n",
    "                            if \"coupling:\" in details:\n",
    "                                coupling_match = re.search(r'coupling:\\s*(\\w+)', details)\n",
    "                                if coupling_match:\n",
    "                                    coupling = coupling_match.group(1)\n",
    "                            \n",
    "                            if \"rework_effort:\" in details:\n",
    "                                effort_match = re.search(r'rework_effort:\\s*(\\d+)', details)\n",
    "                                if effort_match:\n",
    "                                    rework_effort = effort_match.group(1)\n",
    "                        else:\n",
    "                            coupling = \"moderate\"\n",
    "                            rework_effort = \"3\"\n",
    "                        \n",
    "                        if dependent_num.isdigit() and dependency_num.isdigit():\n",
    "                            dependent_idx = int(dependent_num) - 1\n",
    "                            dependency_idx = int(dependency_num) - 1\n",
    "                            \n",
    "                            if 0 <= dependent_idx < len(tasks) and 0 <= dependency_idx < len(tasks):\n",
    "                                dependent_task = tasks[dependent_idx]\n",
    "                                dependency_task = tasks[dependency_idx]\n",
    "                                \n",
    "                                if dependent_task not in dependencies:\n",
    "                                    dependencies[dependent_task] = []\n",
    "                                \n",
    "                                dependencies[dependent_task].append({\n",
    "                                    \"task\": dependency_task,\n",
    "                                    \"coupling\": coupling,\n",
    "                                    \"rework_effort\": rework_effort\n",
    "                                })\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Couldn't parse dependency line: {line} - {str(e)}\")\n",
    "                    continue\n",
    "                    \n",
    "        return dependencies\n",
    "\n",
    "class FewShotSkillMapper:\n",
    "    \"\"\"\n",
    "    Few-Shot Skill Mapping Agent\n",
    "    \n",
    "    Implements few-shot prompting for skill identification:\n",
    "    - Provides examples across different technical domains\n",
    "    - Demonstrates skill categorization patterns\n",
    "    - Shows appropriate skill granularity\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.strategy = \"Few-Shot\"\n",
    "        # Examples covering frontend, backend, and different skill types\n",
    "        self.few_shot_examples = \"\"\"\n",
    "Task: Make address text clickable\n",
    "Required Skills:\n",
    "- Frontend development\n",
    "\n",
    "Task: Implement click handler for Google Maps URL\n",
    "Required Skills:\n",
    "- Frontend development\n",
    "- JavaScript\n",
    "\n",
    "Task: Design public landing page layout\n",
    "Required Skills:\n",
    "- Frontend development\n",
    "- UI/UX design\n",
    "\n",
    "Task: Create anonymous user session handling\n",
    "Required Skills:\n",
    "- Backend development\n",
    "\n",
    "Task: Implement facility search without authentication\n",
    "Required Skills:\n",
    "- Backend development\n",
    "- Database skills\n",
    "\"\"\"\n",
    "        \n",
    "    async def map_skills(self, task: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Few-shot prompt: Examples demonstrate skill categorization patterns\n",
    "        \"\"\"\n",
    "        # Few-shot prompt: Examples showing skill identification patterns\n",
    "        prompt = f\"\"\"\n",
    "Identify the specific technical skills required to complete this task.\n",
    "Return ONLY a bulleted list of skills, no explanations or headers.\n",
    "Keep skills focused and avoid mixing frontend and backend skills unless necessary.\n",
    "\n",
    "Examples:\n",
    "{self.few_shot_examples}\n",
    "\n",
    "Task: {task}\n",
    "Required Skills:\n",
    "\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"llama3-70b-8192\",\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        # Track token usage\n",
    "        output_text = response.choices[0].message.content.strip()\n",
    "        token_tracker.track_api_call('skill_mapping', prompt, output_text)\n",
    "        \n",
    "        skills = self._parse_skills(output_text)\n",
    "        return skills\n",
    "    \n",
    "    def _parse_skills(self, content: str) -> List[str]:\n",
    "        \"\"\"Extract clean skills list from few-shot response\"\"\"\n",
    "        lines = content.split('\\n')\n",
    "        skills = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Skip headers and explanatory text\n",
    "            if any(skip_phrase in line.lower() for skip_phrase in [\n",
    "                'required skills:', 'task:', 'here are', 'the following', 'skills needed'\n",
    "            ]):\n",
    "                continue\n",
    "            \n",
    "            # Clean skill from bullet points\n",
    "            clean_skill = re.sub(r'^[\\-\\*\\s]+', '', line)\n",
    "            clean_skill = clean_skill.strip()\n",
    "            \n",
    "            if clean_skill and len(clean_skill) > 2:\n",
    "                skills.append(clean_skill)\n",
    "        \n",
    "        return skills\n",
    "\n",
    "class TaskConsolidatorAgent:\n",
    "    \"\"\"Task consolidation logic (unchanged from original)\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def consolidate_tasks(self, user_stories_tasks: Dict[str, List[str]]) -> Tuple[List[str], Dict[str, List[str]]]:\n",
    "        \"\"\"Consolidate tasks from multiple user stories\"\"\"\n",
    "        unique_tasks = []\n",
    "        task_origins = {}\n",
    "        seen_tasks = set()\n",
    "        \n",
    "        for user_story, tasks in user_stories_tasks.items():\n",
    "            for task in tasks:\n",
    "                task_lower = task.lower().strip()\n",
    "                is_duplicate = False\n",
    "                \n",
    "                for existing_task in seen_tasks:\n",
    "                    if self._are_similar_tasks(task_lower, existing_task.lower()):\n",
    "                        is_duplicate = True\n",
    "                        for unique_task in unique_tasks:\n",
    "                            if unique_task.lower() == existing_task.lower():\n",
    "                                if unique_task not in task_origins:\n",
    "                                    task_origins[unique_task] = []\n",
    "                                if user_story not in task_origins[unique_task]:\n",
    "                                    task_origins[unique_task].append(user_story)\n",
    "                                break\n",
    "                        break\n",
    "                \n",
    "                if not is_duplicate:\n",
    "                    unique_tasks.append(task)\n",
    "                    seen_tasks.add(task_lower)\n",
    "                    task_origins[task] = [user_story]\n",
    "        \n",
    "        return unique_tasks, task_origins\n",
    "    \n",
    "    def _are_similar_tasks(self, task1: str, task2: str) -> bool:\n",
    "        \"\"\"Simple similarity check for tasks\"\"\"\n",
    "        common_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n",
    "        \n",
    "        words1 = set(task1.split()) - common_words\n",
    "        words2 = set(task2.split()) - common_words\n",
    "        \n",
    "        if len(words1) == 0 or len(words2) == 0:\n",
    "            return False\n",
    "            \n",
    "        intersection = words1.intersection(words2)\n",
    "        union = words1.union(words2)\n",
    "        \n",
    "        similarity = len(intersection) / len(union) if union else 0\n",
    "        return similarity > 0.7\n",
    "\n",
    "# Global token tracker instance\n",
    "token_tracker = TokenTracker()\n",
    "\n",
    "async def _map_all_skills(mapper: FewShotSkillMapper, tasks: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"Map skills for all tasks concurrently\"\"\"\n",
    "    skill_tasks = await asyncio.gather(*[mapper.map_skills(task) for task in tasks])\n",
    "    return {task: skills for task, skills in zip(tasks, skill_tasks)}\n",
    "\n",
    "async def process_user_stories_few_shot(user_stories: List[str]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Main processing function using Few-Shot prompting strategy\n",
    "    \n",
    "    This demonstrates the few-shot approach across all agents:\n",
    "    - 2-5 carefully curated examples per agent\n",
    "    - Consistent format demonstration\n",
    "    - Pattern-based learning approach\n",
    "    - Balance between token usage and quality\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Reset token tracker for new session\n",
    "        global token_tracker\n",
    "        token_tracker = TokenTracker()\n",
    "        \n",
    "        print(\"üéØ Using FEW-SHOT prompting strategy\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"Strategy: 2-5 examples demonstrate desired patterns\")\n",
    "        print(\"Benefits: Better consistency, format control\")\n",
    "        print(\"Trade-offs: Higher token usage, example dependency\")\n",
    "        print(\"\")\n",
    "        \n",
    "        # Step 1: Decompose each user story into tasks (Few-Shot)\n",
    "        decomposer = FewShotTaskDecomposer()\n",
    "        user_stories_tasks = {}\n",
    "        \n",
    "        for i, user_story in enumerate(user_stories, 1):\n",
    "            print(f\"üîÑ Processing story {i}/{len(user_stories)} with examples...\")\n",
    "            tasks = await decomposer.decompose(user_story)\n",
    "            if tasks:\n",
    "                user_stories_tasks[user_story] = tasks\n",
    "                print(f\"   Generated {len(tasks)} tasks (guided by examples)\")\n",
    "        \n",
    "        if not user_stories_tasks:\n",
    "            raise ValueError(\"No tasks were generated from any user story\")\n",
    "        \n",
    "        # Step 2: Consolidate tasks and eliminate duplicates\n",
    "        print(f\"\\nüîÑ Consolidating tasks...\")\n",
    "        consolidator = TaskConsolidatorAgent()\n",
    "        unique_tasks, task_origins = consolidator.consolidate_tasks(user_stories_tasks)\n",
    "        \n",
    "        # Step 3: Analyze dependencies and map skills (Few-Shot)\n",
    "        print(f\"üîÑ Analyzing dependencies and mapping skills with examples...\")\n",
    "        dep_analyzer = FewShotDependencyAnalyzer()\n",
    "        skill_mapper = FewShotSkillMapper()\n",
    "            \n",
    "        dependencies, skill_map = await asyncio.gather(\n",
    "            dep_analyzer.analyze(unique_tasks),\n",
    "            _map_all_skills(skill_mapper, unique_tasks)\n",
    "        )\n",
    "        \n",
    "        # Get token usage summary\n",
    "        token_summary = token_tracker.get_summary()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Few-shot processing complete!\")\n",
    "        print(f\"üìä Total tokens used: {token_summary['breakdown']['total_consumed']}\")\n",
    "        \n",
    "        return {\n",
    "            \"strategy\": \"Few-Shot Prompting\",\n",
    "            \"user_stories\": user_stories,\n",
    "            \"tasks\": unique_tasks,\n",
    "            \"task_origins\": task_origins,\n",
    "            \"dependencies\": dependencies,\n",
    "            \"required_skills\": skill_map,\n",
    "            \"token_usage\": token_summary\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing user stories: {str(e)}\")\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"strategy\": \"Few-Shot Prompting\",\n",
    "            \"user_stories\": user_stories,\n",
    "            \"token_usage\": token_tracker.get_summary() if 'token_tracker' in globals() else None\n",
    "        }\n",
    "\n",
    "def display_few_shot_results(result: Dict[str, Any]):\n",
    "    \"\"\"Enhanced display function for few-shot results\"\"\"\n",
    "    \n",
    "    if \"error\" in result:\n",
    "        print(f\"‚ùå Error: {result['error']}\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üéØ FEW-SHOT PROMPTING RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Strategy: {result['strategy']}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Token Usage Summary\n",
    "    if \"token_usage\" in result and result[\"token_usage\"]:\n",
    "        token_data = result[\"token_usage\"]\n",
    "        breakdown = token_data.get(\"breakdown\", {})\n",
    "        \n",
    "        print(\"üìä TOKEN EFFICIENCY ANALYSIS:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Total Tokens: {breakdown.get('total_consumed', 0)}\")\n",
    "        \n",
    "        categories = ['task_decomposition', 'dependency_analysis', 'skill_mapping']\n",
    "        for cat in categories:\n",
    "            if cat in breakdown:\n",
    "                data = breakdown[cat]\n",
    "                cat_name = cat.replace('_', ' ').title()\n",
    "                print(f\"{cat_name}: {data['total']} tokens ({data['input']}‚Üí{data['output']})\")\n",
    "        \n",
    "        if \"cost_estimate\" in token_data:\n",
    "            cost_data = token_data[\"cost_estimate\"]\n",
    "            print(f\"Estimated Cost: ${cost_data['total_cost']:.6f}\")\n",
    "        print(\"\")\n",
    "    \n",
    "    # Results Summary\n",
    "    print(\"üìã PROCESSING SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Stories Processed: {len(result['user_stories'])}\")\n",
    "    print(f\"Tasks Generated: {len(result['tasks'])}\")\n",
    "    print(f\"Dependencies Found: {sum(len(deps) for deps in result['dependencies'].values())}\")\n",
    "    print(f\"Skills Identified: {sum(len(skills) for skills in result['required_skills'].values())}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Tasks (first 5 for brevity)\n",
    "    print(\"üéØ GENERATED TASKS (First 5):\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, task in enumerate(result[\"tasks\"][:5], 1):\n",
    "        origins = result[\"task_origins\"].get(task, [])\n",
    "        print(f\"{i}. {task}\")\n",
    "        print(f\"   From: {len(origins)} story(ies)\")\n",
    "    \n",
    "    if len(result[\"tasks\"]) > 5:\n",
    "        print(f\"   ... and {len(result['tasks']) - 5} more tasks\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Dependencies (first 3 for brevity)\n",
    "    print(\"üîó DEPENDENCY EXAMPLES:\")\n",
    "    print(\"-\" * 40)\n",
    "    dep_count = 0\n",
    "    for dependent_task, deps in result[\"dependencies\"].items():\n",
    "        if dep_count >= 3:\n",
    "            break\n",
    "        for dep in deps:\n",
    "            dep_count += 1\n",
    "            coupling = dep.get('coupling', 'unknown')\n",
    "            rework_effort = dep.get('rework_effort', 'unknown')\n",
    "            print(f\"‚Ä¢ {dependent_task[:40]}...\")\n",
    "            print(f\"  ‚îî‚îÄ Depends on: {dep['task'][:40]}...\")\n",
    "            print(f\"  ‚îî‚îÄ Coupling: {coupling.upper()}, Rework: {rework_effort} points\")\n",
    "            print(\"\")\n",
    "            if dep_count >= 3:\n",
    "                break\n",
    "    \n",
    "    total_deps = sum(len(deps) for deps in result['dependencies'].values())\n",
    "    if total_deps > 3:\n",
    "        print(f\"   ... and {total_deps - 3} more dependencies\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Few-Shot Analysis\n",
    "    print(\"üîç FEW-SHOT STRATEGY ANALYSIS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"‚úÖ Advantages Demonstrated:\")\n",
    "    print(\"   ‚Ä¢ Consistent output formatting\")\n",
    "    print(\"   ‚Ä¢ Pattern-guided task generation\")\n",
    "    print(\"   ‚Ä¢ Structured dependency analysis\")\n",
    "    print(\"   ‚Ä¢ Predictable skill categorization\")\n",
    "    print(\"\")\n",
    "    print(\"üìä Example Impact:\")\n",
    "    print(\"   ‚Ä¢ Task format standardization\")\n",
    "    print(\"   ‚Ä¢ Coupling assessment consistency\")\n",
    "    print(\"   ‚Ä¢ Skill domain separation\")\n",
    "    print(\"   ‚Ä¢ Reduced parsing complexity\")\n",
    "    print(\"\")\n",
    "    print(\"‚ö†Ô∏è  Considerations:\")\n",
    "    print(\"   ‚Ä¢ Higher token usage than zero-shot\")\n",
    "    print(\"   ‚Ä¢ Example selection affects quality\")\n",
    "    print(\"   ‚Ä¢ Potential bias toward provided examples\")\n",
    "    print(\"\")\n",
    "\n",
    "async def run_few_shot_demo():\n",
    "    \"\"\"\n",
    "    Demo function to run few-shot prompting strategy\n",
    "    \n",
    "    This function demonstrates the few-shot approach with:\n",
    "    - Curated examples for each agent\n",
    "    - Token tracking and comparison\n",
    "    - Quality analysis\n",
    "    - Strategy performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üéØ FEW-SHOT PROMPTING STRATEGY DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Testing few-shot prompting with curated examples...\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Use sample stories for demonstration\n",
    "    user_stories = SAMPLE_USER_STORIES\n",
    "    \n",
    "    # Process using few-shot strategy\n",
    "    result = await process_user_stories_few_shot(user_stories)\n",
    "    \n",
    "    # Display comprehensive results\n",
    "    display_few_shot_results(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def compare_strategies_token_usage(zero_shot_result: Dict[str, Any], few_shot_result: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Compare token usage between zero-shot and few-shot strategies\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä STRATEGY COMPARISON: TOKEN USAGE ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Extract token data\n",
    "    zero_shot_tokens = zero_shot_result.get('token_usage', {}).get('breakdown', {})\n",
    "    few_shot_tokens = few_shot_result.get('token_usage', {}).get('breakdown', {})\n",
    "    \n",
    "    zero_shot_total = zero_shot_tokens.get('total_consumed', 0)\n",
    "    few_shot_total = few_shot_tokens.get('total_consumed', 0)\n",
    "    \n",
    "    print(f\"üéØ TOTAL TOKEN COMPARISON:\")\n",
    "    print(f\"Zero-Shot:  {zero_shot_total:,} tokens\")\n",
    "    print(f\"Few-Shot:   {few_shot_total:,} tokens\")\n",
    "    \n",
    "    if zero_shot_total > 0:\n",
    "        increase = ((few_shot_total - zero_shot_total) / zero_shot_total) * 100\n",
    "        print(f\"Difference: {few_shot_total - zero_shot_total:,} tokens ({increase:+.1f}%)\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Category breakdown\n",
    "    categories = ['task_decomposition', 'dependency_analysis', 'skill_mapping']\n",
    "    print(f\"üìã CATEGORY BREAKDOWN:\")\n",
    "    print(f\"{'Category':<20} {'Zero-Shot':<12} {'Few-Shot':<12} {'Difference':<12}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for cat in categories:\n",
    "        zero_tokens = zero_shot_tokens.get(cat, {}).get('total', 0)\n",
    "        few_tokens = few_shot_tokens.get(cat, {}).get('total', 0)\n",
    "        diff = few_tokens - zero_tokens\n",
    "        \n",
    "        cat_name = cat.replace('_', ' ').title()\n",
    "        print(f\"{cat_name:<20} {zero_tokens:<12,} {few_tokens:<12,} {diff:<+12,}\")\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    # Cost comparison\n",
    "    zero_cost = zero_shot_result.get('token_usage', {}).get('cost_estimate', {}).get('total_cost', 0)\n",
    "    few_cost = few_shot_result.get('token_usage', {}).get('cost_estimate', {}).get('total_cost', 0)\n",
    "    \n",
    "    print(f\"üí∞ COST COMPARISON:\")\n",
    "    print(f\"Zero-Shot: ${zero_cost:.6f}\")\n",
    "    print(f\"Few-Shot:  ${few_cost:.6f}\")\n",
    "    \n",
    "    if zero_cost > 0:\n",
    "        cost_increase = ((few_cost - zero_cost) / zero_cost) * 100\n",
    "        print(f\"Difference: ${few_cost - zero_cost:.6f} ({cost_increase:+.1f}%)\")\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    # Quality vs Cost Analysis\n",
    "    print(f\"üéØ STRATEGY TRADE-OFF ANALYSIS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Zero-Shot Strategy:\")\n",
    "    print(f\"  ‚úÖ Lower token usage ({zero_shot_total:,} tokens)\")\n",
    "    print(f\"  ‚úÖ Faster processing (no examples)\")\n",
    "    print(f\"  ‚ö†Ô∏è  Variable output quality\")\n",
    "    print(f\"  ‚ö†Ô∏è  Less format control\")\n",
    "    print(\"\")\n",
    "    print(f\"Few-Shot Strategy:\")\n",
    "    print(f\"  ‚úÖ Consistent output format\")\n",
    "    print(f\"  ‚úÖ Better pattern recognition\")\n",
    "    print(f\"  ‚úÖ Predictable results\")\n",
    "    print(f\"  ‚ö†Ô∏è  Higher token usage ({few_shot_total:,} tokens)\")\n",
    "    print(\"\")\n",
    "    print(f\"üí° RECOMMENDATION:\")\n",
    "    if increase < 50:\n",
    "        print(f\"   Few-shot provides good value - only {increase:.1f}% more tokens\")\n",
    "        print(f\"   for significantly improved consistency and quality\")\n",
    "    else:\n",
    "        print(f\"   Consider use case: {increase:.1f}% token increase\")\n",
    "        print(f\"   May be worth it for production systems requiring consistency\")\n",
    "\n",
    "def analyze_few_shot_quality_improvements(result: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Analyze quality improvements from few-shot examples\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üîç FEW-SHOT QUALITY ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    tasks = result.get('tasks', [])\n",
    "    dependencies = result.get('dependencies', {})\n",
    "    skills = result.get('required_skills', {})\n",
    "    \n",
    "    # Task quality analysis\n",
    "    print(\"üìã TASK QUALITY METRICS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Analyze task length consistency\n",
    "    task_lengths = [len(task.split()) for task in tasks]\n",
    "    avg_length = sum(task_lengths) / len(task_lengths) if task_lengths else 0\n",
    "    \n",
    "    print(f\"Tasks Generated: {len(tasks)}\")\n",
    "    print(f\"Average Task Length: {avg_length:.1f} words\")\n",
    "    print(f\"Task Length Range: {min(task_lengths) if task_lengths else 0}-{max(task_lengths) if task_lengths else 0} words\")\n",
    "    \n",
    "    # Check for consistent formatting\n",
    "    formatted_tasks = sum(1 for task in tasks if len(task.split()) >= 3)\n",
    "    formatting_consistency = (formatted_tasks / len(tasks)) * 100 if tasks else 0\n",
    "    print(f\"Well-formatted Tasks: {formatting_consistency:.1f}%\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Dependency quality analysis\n",
    "    print(\"üîó DEPENDENCY QUALITY METRICS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    total_deps = sum(len(deps) for deps in dependencies.values())\n",
    "    coupling_types = {}\n",
    "    rework_efforts = []\n",
    "    \n",
    "    for deps_list in dependencies.values():\n",
    "        for dep in deps_list:\n",
    "            coupling = dep.get('coupling', 'unknown')\n",
    "            coupling_types[coupling] = coupling_types.get(coupling, 0) + 1\n",
    "            \n",
    "            try:\n",
    "                effort = int(dep.get('rework_effort', 3))\n",
    "                rework_efforts.append(effort)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"Dependencies Found: {total_deps}\")\n",
    "    print(f\"Coupling Distribution:\")\n",
    "    for coupling, count in coupling_types.items():\n",
    "        percentage = (count / total_deps) * 100 if total_deps > 0 else 0\n",
    "        print(f\"  ‚Ä¢ {coupling.title()}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    if rework_efforts:\n",
    "        avg_rework = sum(rework_efforts) / len(rework_efforts)\n",
    "        print(f\"Average Rework Effort: {avg_rework:.1f} story points\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Skills quality analysis\n",
    "    print(\"üéØ SKILLS QUALITY METRICS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    all_skills = []\n",
    "    for skill_list in skills.values():\n",
    "        all_skills.extend(skill_list)\n",
    "    \n",
    "    unique_skills = set(all_skills)\n",
    "    skill_frequency = {}\n",
    "    for skill in all_skills:\n",
    "        skill_frequency[skill] = skill_frequency.get(skill, 0) + 1\n",
    "    \n",
    "    print(f\"Total Skills Identified: {len(all_skills)}\")\n",
    "    print(f\"Unique Skills: {len(unique_skills)}\")\n",
    "    print(f\"Average Skills per Task: {len(all_skills) / len(tasks) if tasks else 0:.1f}\")\n",
    "    \n",
    "    # Most common skills\n",
    "    sorted_skills = sorted(skill_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(f\"Most Common Skills:\")\n",
    "    for skill, count in sorted_skills[:5]:\n",
    "        print(f\"  ‚Ä¢ {skill}: {count} tasks\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Few-shot effectiveness indicators\n",
    "    print(\"üìä FEW-SHOT EFFECTIVENESS INDICATORS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    effectiveness_score = 0\n",
    "    max_score = 5\n",
    "    \n",
    "    # Check formatting consistency\n",
    "    if formatting_consistency > 90:\n",
    "        effectiveness_score += 1\n",
    "        print(\"‚úÖ Excellent task formatting consistency (>90%)\")\n",
    "    elif formatting_consistency > 70:\n",
    "        effectiveness_score += 0.5\n",
    "        print(\"‚ö†Ô∏è  Good task formatting consistency (70-90%)\")\n",
    "    else:\n",
    "        print(\"‚ùå Poor task formatting consistency (<70%)\")\n",
    "    \n",
    "    # Check dependency structure\n",
    "    if total_deps > 0 and len(coupling_types) >= 2:\n",
    "        effectiveness_score += 1\n",
    "        print(\"‚úÖ Good dependency analysis with varied coupling types\")\n",
    "    elif total_deps > 0:\n",
    "        effectiveness_score += 0.5\n",
    "        print(\"‚ö†Ô∏è  Basic dependency analysis detected\")\n",
    "    else:\n",
    "        print(\"‚ùå No dependencies detected\")\n",
    "    \n",
    "    # Check skill diversity\n",
    "    skill_diversity = len(unique_skills) / len(all_skills) if all_skills else 0\n",
    "    if skill_diversity > 0.7:\n",
    "        effectiveness_score += 1\n",
    "        print(\"‚úÖ High skill diversity and specificity\")\n",
    "    elif skill_diversity > 0.4:\n",
    "        effectiveness_score += 0.5\n",
    "        print(\"‚ö†Ô∏è  Moderate skill diversity\")\n",
    "    else:\n",
    "        print(\"‚ùå Low skill diversity\")\n",
    "    \n",
    "    # Check rework effort realism\n",
    "    if rework_efforts and 1 <= avg_rework <= 8:\n",
    "        effectiveness_score += 1\n",
    "        print(\"‚úÖ Realistic rework effort estimates\")\n",
    "    elif rework_efforts:\n",
    "        effectiveness_score += 0.5\n",
    "        print(\"‚ö†Ô∏è  Rework effort estimates present\")\n",
    "    else:\n",
    "        print(\"‚ùå No rework effort estimates\")\n",
    "    \n",
    "    # Check overall output quality\n",
    "    if len(tasks) >= len(result.get('user_stories', [])) * 2:\n",
    "        effectiveness_score += 1\n",
    "        print(\"‚úÖ Good task granularity (multiple tasks per story)\")\n",
    "    elif len(tasks) >= len(result.get('user_stories', [])):\n",
    "        effectiveness_score += 0.5\n",
    "        print(\"‚ö†Ô∏è  Basic task granularity\")\n",
    "    else:\n",
    "        print(\"‚ùå Poor task granularity\")\n",
    "    \n",
    "    final_score = (effectiveness_score / max_score) * 100\n",
    "    print(\"\")\n",
    "    print(f\"üèÜ FEW-SHOT EFFECTIVENESS SCORE: {final_score:.1f}%\")\n",
    "    \n",
    "    if final_score >= 80:\n",
    "        print(\"   üåü Excellent - Few-shot examples are highly effective\")\n",
    "    elif final_score >= 60:\n",
    "        print(\"   üëç Good - Few-shot examples provide solid guidance\")\n",
    "    elif final_score >= 40:\n",
    "        print(\"   üìà Fair - Few-shot examples have moderate impact\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  Poor - Few-shot examples need improvement\")\n",
    "\n",
    "\n",
    "few_result = await run_few_shot_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae462c3c-59c6-4d31-b569-5a362e8ddacb",
   "metadata": {},
   "source": [
    "#### 3.4.3 Strategy 3: Chain of Thought\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00443464-9976-4589-8b53-f5953f130d5c",
   "metadata": {},
   "source": [
    "#### 3.4.4 Strategy 4: fewshots-cot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1990d793-fd95-49d1-bb57-1e4ec115f0d8",
   "metadata": {},
   "source": [
    "#### 3.4.5 Strategy 5: Meta Prompting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d81d8-36e0-4b9b-a64e-e2161e126d2f",
   "metadata": {},
   "source": [
    "#### 3.4.6 Strategy 6: Thought-of-tree Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333948cf-e277-46cb-8e68-4ce47aa9c892",
   "metadata": {},
   "source": [
    "#### 3.4.7 Strategy 7: Self-Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdef146-2180-4680-a298-50da2c4f853c",
   "metadata": {},
   "source": [
    "#### 3.4.8 Strategy 8: Reflexion Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2412d3fa-6aaf-4264-ad65-6b7a0f71417c",
   "metadata": {},
   "source": [
    "### 3.4 Prompt Strategy Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4280923-0945-4f77-bd55-ebe0a7087b9e",
   "metadata": {},
   "source": [
    "### 3.5 Fine-tuning with LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9927cd8-9fc0-44b0-9889-7a5e298d3664",
   "metadata": {},
   "source": [
    "#### 3.5.1 Data Structure Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b086e6c6-1eed-4636-848c-2fe4482bc15d",
   "metadata": {},
   "source": [
    "## 4. Output Form & Results\n",
    "\n",
    "### 4.1 Output Structure Design\n",
    "\n",
    "#### 4.1.1 Task Output Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa9dffa-d354-48b1-9c55-16a0fc709714",
   "metadata": {},
   "source": [
    "#### 4.1.2 Dependency Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb2ac0-4d06-4548-bfa7-1d9de67ae953",
   "metadata": {},
   "source": [
    "#### 4.1.3 Skills Extraction Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41264690-17b5-4450-a2f2-60bdb46b5cbb",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Performance Analysis\n",
    "\n",
    "### 5.1 Evaluation Metrics\n",
    "\n",
    "#### 5.1.1 Task Breakdown Accuracy\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afc58819-5f25-4000-bdcb-015ed98da52b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
