{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.6722689075630253,
  "eval_steps": 500,
  "global_step": 150,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.056022408963585436,
      "grad_norm": 0.9154044389724731,
      "learning_rate": 1.2e-05,
      "loss": 13.0846,
      "step": 5
    },
    {
      "epoch": 0.11204481792717087,
      "grad_norm": 0.822297990322113,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 12.7835,
      "step": 10
    },
    {
      "epoch": 0.16806722689075632,
      "grad_norm": 0.7809954285621643,
      "learning_rate": 2.9294117647058824e-05,
      "loss": 13.2213,
      "step": 15
    },
    {
      "epoch": 0.22408963585434175,
      "grad_norm": 0.7767956852912903,
      "learning_rate": 2.8411764705882353e-05,
      "loss": 12.7272,
      "step": 20
    },
    {
      "epoch": 0.2801120448179272,
      "grad_norm": 0.8015632629394531,
      "learning_rate": 2.7529411764705883e-05,
      "loss": 13.0304,
      "step": 25
    },
    {
      "epoch": 0.33613445378151263,
      "grad_norm": 0.8341432213783264,
      "learning_rate": 2.6647058823529412e-05,
      "loss": 12.5852,
      "step": 30
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 1.0072152614593506,
      "learning_rate": 2.576470588235294e-05,
      "loss": 12.6771,
      "step": 35
    },
    {
      "epoch": 0.4481792717086835,
      "grad_norm": 0.8996754884719849,
      "learning_rate": 2.488235294117647e-05,
      "loss": 12.5112,
      "step": 40
    },
    {
      "epoch": 0.5042016806722689,
      "grad_norm": 0.9413580894470215,
      "learning_rate": 2.4e-05,
      "loss": 13.0218,
      "step": 45
    },
    {
      "epoch": 0.5602240896358543,
      "grad_norm": 1.2261238098144531,
      "learning_rate": 2.311764705882353e-05,
      "loss": 13.0349,
      "step": 50
    },
    {
      "epoch": 0.6162464985994398,
      "grad_norm": 0.8389031291007996,
      "learning_rate": 2.223529411764706e-05,
      "loss": 12.4491,
      "step": 55
    },
    {
      "epoch": 0.6722689075630253,
      "grad_norm": 1.1343413591384888,
      "learning_rate": 2.135294117647059e-05,
      "loss": 13.0305,
      "step": 60
    },
    {
      "epoch": 0.7282913165266106,
      "grad_norm": 1.122399091720581,
      "learning_rate": 2.047058823529412e-05,
      "loss": 12.4572,
      "step": 65
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 1.029613733291626,
      "learning_rate": 1.9588235294117648e-05,
      "loss": 12.7573,
      "step": 70
    },
    {
      "epoch": 0.8403361344537815,
      "grad_norm": 1.044525384902954,
      "learning_rate": 1.8705882352941178e-05,
      "loss": 12.7622,
      "step": 75
    },
    {
      "epoch": 0.896358543417367,
      "grad_norm": 1.148385763168335,
      "learning_rate": 1.7823529411764707e-05,
      "loss": 12.5114,
      "step": 80
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 1.1431238651275635,
      "learning_rate": 1.6941176470588237e-05,
      "loss": 12.5865,
      "step": 85
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7391126155853271,
      "learning_rate": 1.6058823529411766e-05,
      "loss": 12.725,
      "step": 90
    },
    {
      "epoch": 1.0560224089635855,
      "grad_norm": 1.1620796918869019,
      "learning_rate": 1.5176470588235294e-05,
      "loss": 12.5285,
      "step": 95
    },
    {
      "epoch": 1.112044817927171,
      "grad_norm": 1.285258173942566,
      "learning_rate": 1.4294117647058823e-05,
      "loss": 12.5499,
      "step": 100
    },
    {
      "epoch": 1.1680672268907564,
      "grad_norm": 1.2302623987197876,
      "learning_rate": 1.3411764705882354e-05,
      "loss": 12.6779,
      "step": 105
    },
    {
      "epoch": 1.2240896358543418,
      "grad_norm": 1.2521880865097046,
      "learning_rate": 1.2529411764705884e-05,
      "loss": 12.666,
      "step": 110
    },
    {
      "epoch": 1.280112044817927,
      "grad_norm": 1.2554875612258911,
      "learning_rate": 1.1647058823529412e-05,
      "loss": 12.5323,
      "step": 115
    },
    {
      "epoch": 1.3361344537815127,
      "grad_norm": 1.2854704856872559,
      "learning_rate": 1.0764705882352941e-05,
      "loss": 12.5951,
      "step": 120
    },
    {
      "epoch": 1.392156862745098,
      "grad_norm": 1.5615578889846802,
      "learning_rate": 9.88235294117647e-06,
      "loss": 12.4178,
      "step": 125
    },
    {
      "epoch": 1.4481792717086834,
      "grad_norm": 1.3338403701782227,
      "learning_rate": 9e-06,
      "loss": 12.9339,
      "step": 130
    },
    {
      "epoch": 1.504201680672269,
      "grad_norm": 1.3801077604293823,
      "learning_rate": 8.11764705882353e-06,
      "loss": 12.436,
      "step": 135
    },
    {
      "epoch": 1.5602240896358543,
      "grad_norm": 1.8281002044677734,
      "learning_rate": 7.235294117647059e-06,
      "loss": 12.859,
      "step": 140
    },
    {
      "epoch": 1.6162464985994398,
      "grad_norm": 1.554406762123108,
      "learning_rate": 6.352941176470589e-06,
      "loss": 12.4387,
      "step": 145
    },
    {
      "epoch": 1.6722689075630253,
      "grad_norm": 1.6463236808776855,
      "learning_rate": 5.470588235294117e-06,
      "loss": 12.6592,
      "step": 150
    }
  ],
  "logging_steps": 5,
  "max_steps": 180,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 78266103496704.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
