====================================================================================================
MULTI-TECHNIQUE TASK DECOMPOSITION EVALUATION REPORT
====================================================================================================

­ЪЊі EVALUATION OVERVIEW:
  Рђб Techniques Evaluated: 1
  Рђб Techniques: zero_shots
  Рђб Test Stories: 73
  Рђб Coverage: 100.0%

==================================================
INDIVIDUAL TECHNIQUE RESULTS
==================================================

­ЪћЇ ZERO_SHOTS:
  ­ЪДа Semantic Similarity:
    Рђб Mean: 0.510
    Рђб Excellent: 0.0%
    Рђб Good: 13.7%
    Рђб Poor: 8.2%
  ­ЪЊЮ Overlap Metrics:
    Рђб BLEU: 0.023
    Рђб ROUGE: 0.388
    Рђб METEOR: 0.209
    Рђб Word Overlap: 0.093
  ­ЪЊі Task Statistics:
    Рђб Expected Tasks (avg): 5.0
    Рђб Predicted Tasks (avg): 10.8
    Рђб Count Ratio: 2.17
    Рђб Exact Predictions: 0
    Рђб Over-predictions: 73
    Рђб Under-predictions: 0

==================================================
RECOMMENDATIONS
==================================================

­ЪњА RECOMMENDATIONS:
  Рђб For semantic quality: Use zero_shots
    (Semantic similarity: 0.510)
  Рђб For task count accuracy: Use zero_shots
    (Count ratio: 2.170, deviation from ideal: 1.170)

====================================================================================================
EVALUATION COMPLETED
====================================================================================================